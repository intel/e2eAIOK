# IntelÂ® End-to-End AI Optimization Kit for MiniGO


[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/e2eAIOK/blob/main/demo/builtin/minigo/MiniGo_DEMO.ipynb)&emsp;&emsp;  <img width="20" height="20" src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png"> [View source on GitHub](https://github.com/intel/e2eAIOK/blob/main/demo/builtin/minigo/MiniGo_DEMO.ipynb)
---

## Original source disclose
* Since MiniGo is a reinforcement learning model, it generates training dataset in each iteration during train loop and doesn't need dataset. We evaluate winrate with target model(based on MLPerf submission) and final winrate>=0.5, and all our optimizations guarantee that target metric.

* public reference on AlphaGo Zero: https://arxiv.org/abs/1712.01815

* public reference on MiniGo: https://openreview.net/forum?id=H1eerhIpLV

---

# Quick Start

## Data Processing
Get processed target model and bootstrap checkpoint (See the freeze target model section and convert selfplay data format section). Reference https://github.com/mlcommons/training_results_v1.0/tree/master/Intel/benchmarks/minigo/8-nodes-64s-8376H-tensorflow/ml_perf#steps-to-run-minigo


## Enviroment Setup
* Firstly, ensure that intel oneapi-hpckit and minigo conda runtime installed on server.
* Secondly, enter AIOK repo directory.
* Thirdly, start the jupyter notebook service.

``` bash
source /opt/intel/oneapi/setvars.sh --force
conda activate minigo
cd e2eAIOK
```

## Training
```
python run_e2eaiok.py --data_path /root/dataset/minigo --model_name minigo --conf conf/e2eaiok_defaults_minigo_example.conf
```
