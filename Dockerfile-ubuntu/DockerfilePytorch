# For v0.1 workload: DLRM
FROM ubuntu:18.04

WORKDIR /root/
RUN apt-get update -y && apt-get install -y openjdk-8-jre build-essential cmake wget git libunwind-dev openssh-server sshpass
RUN wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-py37_4.12.0-Linux-x86_64.sh -O ~/miniconda.sh && /bin/bash ~/miniconda.sh -b -p /opt/intel/oneapi/intelpython/latest
ENV PATH /opt/intel/oneapi/intelpython/latest/condabin:$PATH
RUN yes | conda create -n pytorch_mlperf python=3.7
SHELL ["conda", "run", "-n", "pytorch_mlperf", "/bin/bash", "-c"]
RUN conda install gxx_linux-64==8.4.0
RUN cp /opt/intel/oneapi/intelpython/latest/lib/python3.7/_sysconfigdata_x86_64_conda_cos6_linux_gnu.py /opt/intel/oneapi/intelpython/latest/lib/python3.7/_sysconfigdata_x86_64_conda_linux_gnu.py
RUN cp /opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/lib/python3.7/_sysconfigdata_x86_64_conda_cos6_linux_gnu.py /opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/lib/python3.7/_sysconfigdata_x86_64_conda_linux_gnu.py
RUN cp -r /opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/lib/* /opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/x86_64-conda-linux-gnu/sysroot/usr/lib64/
# install dependencies
RUN python -m pip install onnx tqdm lark-parser pyyaml
RUN conda install ninja cffi typing --no-update-deps
RUN conda install intel-openmp mkl mkl-include -c intel --no-update-deps
RUN conda install -c conda-forge gperftools
RUN python -m pip install numpy==1.18.5
# git clone pytorch v1.5.0-rc3
RUN git clone https://github.com/pytorch/pytorch.git && cd pytorch && git checkout tags/v1.5.0-rc3 -b v1.5-rc3 && git submodule sync && git submodule update --init --recursive
# git clone ipex v0.2
RUN git clone https://github.com/intel/intel-extension-for-pytorch.git && cd intel-extension-for-pytorch && git checkout tags/v0.2 -b v0.2 && git submodule sync && git submodule update --init --recursive
# apply ipex patch to pytorch and install
RUN cd intel-extension-for-pytorch && cp torch_patches/0001-enable-Intel-Extension-for-CPU-enable-CCL-backend.patch ../pytorch/ && cd ../pytorch && patch -p1 < 0001-enable-Intel-Extension-for-CPU-enable-CCL-backend.patch
RUN cp -r /opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/lib/* /opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/x86_64-conda-linux-gnu/sysroot/usr/lib64/
RUN cd pytorch && python setup.py install
RUN cd intel-extension-for-pytorch && python setup.py install
# git clone oneCCL and install
RUN git clone https://github.com/oneapi-src/oneCCL.git && cd oneCCL && git checkout 2021.1-beta07-1 && mkdir build && cd build && cmake .. -DCMAKE_INSTALL_PREFIX=/opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/.local && make install -j
# git clone torchCCL and install
RUN git clone https://github.com/intel/torch-ccl.git && cd torch-ccl && git checkout 2021.1-beta07-1
RUN source /opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/.local/env/setvars.sh && cd torch-ccl && python setup.py install
# install dependencies
RUN python -m pip install --no-cache-dir --ignore-installed sigopt pandas pytest prefetch_generator tensorboardX psutil
RUN python -m pip install "git+https://github.com/mlperf/logging.git@1.0.0"
RUN python -m pip install lightgbm transformers xgboost jupyterlab

SHELL ["conda", "run", "-n", "base", "/bin/bash", "-c"]
RUN python -m pip install --no-cache-dir --ignore-installed sigopt pandas pytest
RUN python -m pip install pyrecdp pyarrow notebook
RUN python -m pip install e2eAIOK --pre
RUN python -m pip install e2eAIOK-sda --pre --no-deps --ignore-installed

SHELL ["/bin/bash", "-c"]
RUN sed -i 's/#Port 22/Port 12346/g' /etc/ssh/sshd_config
RUN sed -i 's/#   Port 22/    Port 12346/g' /etc/ssh/ssh_config
RUN echo 'PermitRootLogin yes' >> /etc/ssh/sshd_config
RUN wget -qO- https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz | tar xvz -C /home/
ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
ENV SPARK_HOME /home/spark-3.2.1-bin-hadoop3.2
ENV PYTHONPATH $SPARK_HOME/python/:$PYTHONPATH
ENV PYTHONPATH $SPARK_HOME/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH
ADD spark/spark-defaults.conf /home/spark-3.2.1-bin-hadoop3.2/conf/spark-defaults.conf
ADD spark/start_spark_service.sh /home/start_spark_service.sh
RUN chmod +x /home/start_spark_service.sh
ADD spark/spark-env.sh /home/spark-env.sh
RUN echo "if [ -z \$SPARK_HOME ]; then source /home/spark-env.sh; fi" >> /etc/bash.bashrc
RUN mkdir -p /home/vmagent/app/e2eaiok/spark_data_processing/spark_local_dir
RUN mkdir -p /home/mnt/applicationHistory
RUN conda init bash
RUN echo "source /opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/.local/env/setvars.sh" >> /root/.bashrc
RUN echo "export LD_LIBRARY_PATH=\$LD_LIBRARY_PATH:/opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/lib/python3.7/site-packages/torch_ipex-0.1-py3.7-linux-x86_64.egg/" >> /root/.bashrc
RUN echo "export LD_LIBRARY_PATH=\$LD_LIBRARY_PATH:/opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/lib/python3.7/site-packages/torch/lib/" >> /root/.bashrc
RUN echo "KMP_BLOCKTIME=1" >> /root/.bashrc
RUN echo "KMP_AFFINITY=\"granularity=fine,compact,1,0\"" >> /root/.bashrc
RUN echo "root:docker" | chpasswd
ENTRYPOINT [""]

RUN echo "source activate pytorch_mlperf" >> /root/.bashrc
ENV PATH /opt/intel/oneapi/intelpython/latest/envs/pytorch_mlperf/bin:$PATH
ADD ./notebook/start-notebook.sh /root
RUN chmod a+x /root/start-notebook.sh