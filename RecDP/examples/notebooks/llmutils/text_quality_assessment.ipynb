{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install pyrecdp from github"
      ],
      "metadata": {
        "id": "hNOO3-I-Tgzd"
      },
      "id": "hNOO3-I-Tgzd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "736fb211-dbe6-4ca9-a1b1-db2cff2d287a",
      "metadata": {
        "id": "736fb211-dbe6-4ca9-a1b1-db2cff2d287a"
      },
      "outputs": [],
      "source": [
        "!pip install 'git+https://github.com/intel/e2eAIOK.git#egg=pyrecdp&subdirectory=RecDP'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install jdk for pyspark running"
      ],
      "metadata": {
        "id": "Jba8TLMvTn-G"
      },
      "id": "Jba8TLMvTn-G"
    },
    {
      "cell_type": "code",
      "source": [
        "!DEBIAN_FRONTEND=noninteractive apt-get install -y openjdk-8-jre"
      ],
      "metadata": {
        "id": "2aCojHZ6TQJE"
      },
      "id": "2aCojHZ6TQJE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare test data"
      ],
      "metadata": {
        "id": "3UMkbvwwT2Vc"
      },
      "id": "3UMkbvwwT2Vc"
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p /content/test_data\n",
        "%cd /content/test_data\n",
        "!wget https://raw.githubusercontent.com/intel/e2eAIOK/main/RecDP/tests/data/llm_data/arxiv_sample_100.jsonl"
      ],
      "metadata": {
        "id": "d6fX0InLTTXt"
      },
      "id": "d6fX0InLTTXt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import quality classifier function"
      ],
      "metadata": {
        "id": "yAscO0gQWBKa"
      },
      "id": "yAscO0gQWBKa"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyrecdp.primitives.llmutils import quality_classifier_spark, quality_classifier\n",
        "from pyrecdp.core import SparkDataProcessor"
      ],
      "metadata": {
        "id": "QU2vJ3pWWIaF"
      },
      "id": "QU2vJ3pWWIaF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specify variables"
      ],
      "metadata": {
        "id": "Y248QUCGWUeL"
      },
      "id": "Y248QUCGWUeL"
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = '/content/test_data/arxiv_sample_100.jsonl'\n",
        "save_path = '/content/test_data/output/quality_classifier'"
      ],
      "metadata": {
        "id": "Oe9BDy0xWiVz"
      },
      "id": "Oe9BDy0xWiVz",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4FFWPIiFjqmO"
      },
      "id": "4FFWPIiFjqmO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "UBhY9MxDYFN3"
      },
      "id": "UBhY9MxDYFN3"
    },
    {
      "cell_type": "code",
      "source": [
        "rdp = SparkDataProcessor()\n",
        "spark = rdp.spark\n",
        "spark_df = spark.read.json(data_file)\n",
        "spark_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_lfGGQOYD3F",
        "outputId": "55aeaacd-4afc-4af5-d1df-1fed965a5339"
      },
      "id": "C_lfGGQOYD3F",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will assign 1 cores and 10386 M memory for spark\n",
            "per core memory size is 10.143 GB and shuffle_disk maximum capacity is 8589934592.000 GB\n",
            "+--------------------+--------------------+\n",
            "|                meta|                text|\n",
            "+--------------------+--------------------+\n",
            "|{2203.15369, en, ...|\\section{Introduc...|\n",
            "|{math/9807097, en...|\\section{Introduc...|\n",
            "|{2008.06948, en, ...|\\section{Introduc...|\n",
            "|{cond-mat/9807071...|\\section{Introduc...|\n",
            "|{2210.10650, en, ...|\\section{\\label{s...|\n",
            "|{astro-ph/9807119...|\\section{Introduc...|\n",
            "|{2111.03152, en, ...|\\section{Introduc...|\n",
            "|{1606.04992, en, ...|\\n\\n\\section{Intr...|\n",
            "|{1608.03404, en, ...|\\section{introduc...|\n",
            "|{1904.10101, en, ...|\\section{Introduc...|\n",
            "|{cond-mat/9807275...|\\section{Introduc...|\n",
            "|{2109.05334, en, ...|\\section{Introduc...|\n",
            "|{1512.06966, en, ...|\\section{Introduc...|\n",
            "|{2112.04926, en, ...|\\section{Introduc...|\n",
            "|{2202.01000, en, ...|\\section{Introduc...|\n",
            "|{2209.13421, en, ...|\\section{Introduc...|\n",
            "|{1103.5603, en, 2...|\\section{Introduc...|\n",
            "|{1001.3679, en, 2...|\\section{Introduc...|\n",
            "|{1702.08222, en, ...|\\section{Introduc...|\n",
            "|{2201.05495, en, ...|\\section{Introduc...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process the 'text' column and generate doc score which will determine whether the row kept or not(spark dataframe interface)"
      ],
      "metadata": {
        "id": "AQELlnB5WyeX"
      },
      "id": "AQELlnB5WyeX"
    },
    {
      "cell_type": "code",
      "source": [
        "quality_classifier_df = quality_classifier_spark(spark_df)\n",
        "quality_classifier_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgGPeSVZWwzZ",
        "outputId": "162604ec-123b-42c2-821f-4e8efe92f303"
      },
      "id": "EgGPeSVZWwzZ",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-09-27 06:44:18.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.primitives.llmutils.quality_classifier\u001b[0m:\u001b[36mprepare_model\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mPreparing scorer model in [/root/.cache/recdp/models/gpt3_quality_model]...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name is gpt3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-09-27 06:44:29.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.primitives.llmutils.quality_classifier\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mStart scoring dataset...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+-----------+\n",
            "|                meta|                text|           doc_score|should_keep|\n",
            "+--------------------+--------------------+--------------------+-----------+\n",
            "|{2203.15369, en, ...|\\section{Introduc...|  0.9999999999996102|          1|\n",
            "|{math/9807097, en...|\\section{Introduc...|                 1.0|          1|\n",
            "|{2008.06948, en, ...|\\section{Introduc...|  0.9015197498942397|          1|\n",
            "|{cond-mat/9807071...|\\section{Introduc...|    0.99971976667992|          1|\n",
            "|{2210.10650, en, ...|\\section{\\label{s...|                 1.0|          1|\n",
            "|{astro-ph/9807119...|\\section{Introduc...|0.001319136449002...|          0|\n",
            "|{2111.03152, en, ...|\\section{Introduc...|                 0.0|          0|\n",
            "|{1606.04992, en, ...|\\n\\n\\section{Intr...|                 1.0|          1|\n",
            "|{1608.03404, en, ...|\\section{introduc...|                 1.0|          1|\n",
            "|{1904.10101, en, ...|\\section{Introduc...|  0.9999979720467516|          1|\n",
            "|{cond-mat/9807275...|\\section{Introduc...|                 1.0|          1|\n",
            "|{2109.05334, en, ...|\\section{Introduc...|3.005982129877793...|          0|\n",
            "|{1512.06966, en, ...|\\section{Introduc...|  0.9999752338514555|          1|\n",
            "|{2112.04926, en, ...|\\section{Introduc...|  0.9999998492093729|          1|\n",
            "|{2202.01000, en, ...|\\section{Introduc...|                 1.0|          1|\n",
            "|{2209.13421, en, ...|\\section{Introduc...|                 1.0|          1|\n",
            "|{1103.5603, en, 2...|\\section{Introduc...|  0.9999999999995527|          1|\n",
            "|{1001.3679, en, 2...|\\section{Introduc...|                 0.0|          0|\n",
            "|{1702.08222, en, ...|\\section{Introduc...|  0.9999988629258854|          1|\n",
            "|{2201.05495, en, ...|\\section{Introduc...|5.299151714099892E-7|          0|\n",
            "+--------------------+--------------------+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process the 'text' column and generate doc score and save data as parquet format."
      ],
      "metadata": {
        "id": "fa3J-ZV8hQ27"
      },
      "id": "fa3J-ZV8hQ27"
    },
    {
      "cell_type": "code",
      "source": [
        "quality_classifier(data_file, save_path, overall_stats=True, file_system_prefix=\"file://\")\n",
        "!cat /content/test_data/output/quality_classifier/overall.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRzUf0ScYZae",
        "outputId": "c49c5395-ed29-408b-a33c-2b70accd718d"
      },
      "id": "QRzUf0ScYZae",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will assign 1 cores and 10386 M memory for spark\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-09-27 07:28:24.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.primitives.llmutils.quality_classifier\u001b[0m:\u001b[36mprepare_model\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mPreparing scorer model in [/root/.cache/recdp/models/gpt3_quality_model]...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "per core memory size is 10.143 GB and shuffle_disk maximum capacity is 8589934592.000 GB\n",
            "model_name is gpt3\n",
            "real_model_path is /root/.cache/recdp/models/gpt3_quality_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-09-27 07:28:26.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.primitives.llmutils.quality_classifier\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1mLoading dataset from [file:///content/test_data/arxiv_sample_100.jsonl]...\u001b[0m\n",
            "\u001b[32m2023-09-27 07:28:26.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.primitives.llmutils.quality_classifier\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mStart scoring dataset...\u001b[0m\n",
            "\u001b[32m2023-09-27 07:28:27.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.primitives.llmutils.quality_classifier\u001b[0m:\u001b[36mexport_result\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1mExporting predicted result to [file:///content/test_data/output/quality_classifier]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",doc_score\n",
            "count,100.0\n",
            "mean,0.6513982867293335\n",
            "std,0.46534815798978746\n",
            "min,0.0\n",
            "25%,0.0002024913944662643\n",
            "50%,0.9999904161747286\n",
            "75%,1.0\n",
            "max,1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3K2S1Q6zidVf"
      },
      "id": "3K2S1Q6zidVf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}