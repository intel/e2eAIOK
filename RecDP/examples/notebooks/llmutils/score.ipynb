{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "xqO9S27psEaG",
   "metadata": {
    "id": "xqO9S27psEaG"
   },
   "source": [
    "# RecDP LLM - Dataset Score Assessment\n",
    "\n",
    "This notebook shows how to use several tools to evaluate the quality score, diversity, toxicity, perplexity and rouge of a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x19WYyOQsdDq",
   "metadata": {
    "id": "x19WYyOQsdDq"
   },
   "source": [
    "# Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hNOO3-I-Tgzd",
   "metadata": {
    "id": "hNOO3-I-Tgzd"
   },
   "source": [
    "## 1. Install pyrecdp and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b3984-7840-45a2-88db-33ee2fac4930",
   "metadata": {
    "id": "736fb211-dbe6-4ca9-a1b1-db2cff2d287a"
   },
   "outputs": [],
   "source": [
    "! DEBIAN_FRONTEND=noninteractive apt-get install -qq -y openjdk-8-jre\n",
    "! pip install -q pyrecdp --pre\n",
    "# ! pip install 'git+https://github.com/intel/e2eAIOK.git#egg=pyrecdp&subdirectory=RecDP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3UMkbvwwT2Vc",
   "metadata": {
    "id": "3UMkbvwwT2Vc"
   },
   "source": [
    "## 2. Prepare your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fX0InLTTXt",
   "metadata": {
    "id": "d6fX0InLTTXt"
   },
   "outputs": [],
   "source": [
    "%mkdir -p /content/test_data\n",
    "%cd /content/test_data\n",
    "!wget https://raw.githubusercontent.com/intel/e2eAIOK/main/RecDP/tests/data/llm_data/alpaca_sample_10.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G3wjx-yItOkR",
   "metadata": {
    "id": "G3wjx-yItOkR"
   },
   "source": [
    "## 3. Score Assement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41e847f-d8ea-4995-a353-7ce7bb3df5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME is not set, use default value of /usr/lib/jvm/java-8-openjdk-amd64/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyrecdp.LLM import TextPipeline, ResumableTextPipeline\n",
    "from pyrecdp.primitives.operations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yAscO0gQWBKa",
   "metadata": {
    "id": "yAscO0gQWBKa"
   },
   "source": [
    "### 3.1 Process with toxicity and perplexity scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "q65vRbH7uJwC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396,
     "referenced_widgets": [
      "db4260225b4f4c59a65491860c2cfd40",
      "c617382f949f41a899a8891abae6ac05",
      "793adfc9606547dd95e09534c6a8ee9c",
      "53d09e33fd3b4532937a0d383fe28310",
      "2910b4043048423b94958349a212d7b6",
      "0c1a1de47d404194b50c571744337ab2",
      "148574df54a94354a4978cf94be86a76",
      "d67f914b86584956b643e5b017ebf2fd",
      "9756942b4f9b426897fb92b6b353017d",
      "e44de870690644f88c24a0afa74aa54d",
      "cfe7ffb4c8194d88aed5c0564b25eef5"
     ]
    },
    "id": "q65vRbH7uJwC",
    "outputId": "7ca9b420-4f1e-48a1-c539-fd5beb0907e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-13 07:03:27.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mpyrecdp.LLM.TextPipeline\u001b[0m:\u001b[36menable_statistics\u001b[0m:\u001b[36m215\u001b[0m - \u001b[33m\u001b[1mEnabling this option will result in a decrease in execution speed\u001b[0m\n",
      "\u001b[32m2023-11-13 07:03:27.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.core.model_utils\u001b[0m:\u001b[36mprepare_sentencepiece_model\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mLoading sentencepiece model...\u001b[0m\n",
      "\u001b[32m2023-11-13 07:03:27.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.core.model_utils\u001b[0m:\u001b[36mprepare_kenlm_model\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mLoading kenlm language model...\u001b[0m\n",
      "[DatasetReader, PerfileSourcedParquetReader, TextPerplexityScore, TextToxicity, PerfileParquetWriter]\n",
      "init ray with total mem of 324137904537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 07:03:31,837\tWARNING services.py:1889 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67104768 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-11-13 07:03:33,059\tINFO worker.py:1642 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017651081085205078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "(pid=59708) Parquet Files Sample 0",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=59708) Parquet Files Sample 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_get_reader pid=59708)\u001b[0m /opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/datasource/parquet_datasource.py:259: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_reader pid=59708)\u001b[0m   pq_ds.pieces, **prefetch_remote_args\n",
      "\u001b[2m\u001b[36m(_get_reader pid=59708)\u001b[0m /opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/datasource/parquet_datasource.py:269: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_reader pid=59708)\u001b[0m   self._pq_pieces = [_SerializedPiece(p) for p in pq_ds.pieces]\n",
      "\u001b[2m\u001b[36m(_get_reader pid=59708)\u001b[0m /opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/datasource/parquet_datasource.py:270: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_reader pid=59708)\u001b[0m   self._pq_paths = [p.path for p in pq_ds.pieces]\n",
      "2023-11-13 07:03:38,953\tINFO read_api.py:406 -- To satisfy the requested parallelism of 192, each read task output is split into 192 smaller blocks.\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "ResumableTextPipeline, current on alpaca_sample_10.parquet:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A2023-11-13 07:03:38,999\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet->SplitBlocks(192)] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2023-11-13 07:03:39,004\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-11-13 07:03:39,007\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008515596389770508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Running 0",
       "rate": null,
       "total": 36864,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/36864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 07:03:41,105\tINFO dataset.py:2380 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2023-11-13 07:03:41,109\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet->SplitBlocks(192)] -> TaskPoolMapOperator[Map(<lambda>)->Map(<lambda>)] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2023-11-13 07:03:41,112\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-11-13 07:03:41,113\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005072832107543945,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "- Aggregate 1",
       "rate": null,
       "total": 36864,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/36864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004132509231567383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Shuffle Map 2",
       "rate": null,
       "total": 36864,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/36864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0037658214569091797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Shuffle Reduce 3",
       "rate": null,
       "total": 36864,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/36864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004392385482788086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Running 0",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResumableTextPipeline, current on alpaca_sample_10.parquet:   0%|          | 0/1 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m ops \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     ParquetReader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/test_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m     TextPerplexityScore(),\n\u001b[1;32m      6\u001b[0m     TextToxicity(huggingface_config_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/root/.cache/huggingface/hub/models--xlm-roberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m     ParquetWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResumableTextPipeline_output-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m      9\u001b[0m pipeline\u001b[38;5;241m.\u001b[39madd_operations(ops)\n\u001b[0;32m---> 10\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m pipeline\n",
      "File \u001b[0;32m/home/vmagent/app/work/LLM_datapre/e2eAIOK/RecDP/pyrecdp/LLM/TextPipeline.py:346\u001b[0m, in \u001b[0;36mResumableTextPipeline.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(op_chain):\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 346\u001b[0m         \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_ray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_reader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, PerfileParquetWriter) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, PerfileJsonlWriter):\n\u001b[1;32m    348\u001b[0m         op\u001b[38;5;241m.\u001b[39mexecute_ray(executable_pipeline, source_id)\n",
      "File \u001b[0;32m/home/vmagent/app/work/LLM_datapre/e2eAIOK/RecDP/pyrecdp/primitives/operations/base.py:198\u001b[0m, in \u001b[0;36mBaseLLMOperation.execute_ray\u001b[0;34m(self, pipeline, child_ds)\u001b[0m\n\u001b[1;32m    196\u001b[0m child_output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m child_ds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_rayds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mchildren \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mchildren \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m []\n",
      "File \u001b[0;32m/home/vmagent/app/work/LLM_datapre/e2eAIOK/RecDP/pyrecdp/primitives/operations/base.py:319\u001b[0m, in \u001b[0;36mstatistics_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics\u001b[38;5;241m.\u001b[39mtotal_in \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mcount()\n\u001b[1;32m    318\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 319\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics\u001b[38;5;241m.\u001b[39mtotal_out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mcount()\n\u001b[1;32m    321\u001b[0m elapse \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/home/vmagent/app/work/LLM_datapre/e2eAIOK/RecDP/pyrecdp/primitives/operations/text_perplexity_score.py:40\u001b[0m, in \u001b[0;36mTextPerplexityScore.process_rayds\u001b[0;34m(self, ds)\u001b[0m\n\u001b[1;32m     38\u001b[0m ret \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_row(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_key, new_name, compute_func))\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics_flag:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics\u001b[38;5;241m.\u001b[39mmax \u001b[38;5;241m=\u001b[39m \u001b[43mret\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics\u001b[38;5;241m.\u001b[39mmin \u001b[38;5;241m=\u001b[39m ret\u001b[38;5;241m.\u001b[39mmin(new_name)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics\u001b[38;5;241m.\u001b[39mmean \u001b[38;5;241m=\u001b[39m ret\u001b[38;5;241m.\u001b[39mmean(new_name)\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/dataset.py:2075\u001b[0m, in \u001b[0;36mDataset.max\u001b[0;34m(self, on, ignore_nulls)\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[38;5;129m@ConsumptionAPI\u001b[39m\n\u001b[1;32m   2037\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\n\u001b[1;32m   2038\u001b[0m     \u001b[38;5;28mself\u001b[39m, on: Optional[Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, ignore_nulls: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2039\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Any, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the maximum of one or more columns.\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m \n\u001b[1;32m   2042\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2073\u001b[0m \u001b[38;5;124;03m        ``False`` and any value is null, then the output is ``None``.\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2075\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_on\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_nulls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2076\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_result(ret)\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/dataset.py:5021\u001b[0m, in \u001b[0;36mDataset._aggregate_on\u001b[0;34m(self, agg_cls, on, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5013\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper for aggregating on a particular subset of the dataset.\u001b[39;00m\n\u001b[1;32m   5014\u001b[0m \n\u001b[1;32m   5015\u001b[0m \u001b[38;5;124;03mThis validates the `on` argument, and converts a list of column names\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5018\u001b[0m \u001b[38;5;124;03maggregation on the entire row for a simple Dataset.\u001b[39;00m\n\u001b[1;32m   5019\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5020\u001b[0m aggs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_multicolumn_aggs(agg_cls, on, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maggs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/dataset.py:1949\u001b[0m, in \u001b[0;36mDataset.aggregate\u001b[0;34m(self, *aggs)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;129m@ConsumptionAPI\u001b[39m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39maggs: AggregateFn) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Any, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Aggregate values using one or more functions.\u001b[39;00m\n\u001b[1;32m   1918\u001b[0m \n\u001b[1;32m   1919\u001b[0m \u001b[38;5;124;03m    Use this method to compute metrics like the product of a column.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;124;03m        A ``dict`` where each each value is an aggregation for a given column.\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1949\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maggs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ret) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/dataset.py:2387\u001b[0m, in \u001b[0;36mDataset.take\u001b[0;34m(self, limit)\u001b[0m\n\u001b[1;32m   2384\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2386\u001b[0m limited_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit(limit)\n\u001b[0;32m-> 2387\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m limited_ds\u001b[38;5;241m.\u001b[39miter_rows():\n\u001b[1;32m   2388\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[1;32m   2389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m limit:\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/iterator.py:271\u001b[0m, in \u001b[0;36mDataIterator.iter_rows.<locals>._wrapped_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_iterator\u001b[39m():\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batch_iterable:\n\u001b[1;32m    272\u001b[0m         batch \u001b[38;5;241m=\u001b[39m BlockAccessor\u001b[38;5;241m.\u001b[39mfor_block(BlockAccessor\u001b[38;5;241m.\u001b[39mbatch_to_block(batch))\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39miter_rows(public_row_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/iterator.py:181\u001b[0m, in \u001b[0;36mDataIterator.iter_batches.<locals>._create_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Iterate through the dataset from the start each time\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# _iterator_gen is called.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# This allows multiple iterations of the dataset without\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# needing to explicitly call `iter_batches()` multiple times.\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m block_iterator, stats, blocks_owned_by_consumer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_block_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_legacy:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Legacy iter_batches does not use metadata.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop_metadata\u001b[39m(block_iterator):\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/_internal/iterator/iterator_impl.py:32\u001b[0m, in \u001b[0;36mDataIteratorImpl._to_block_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_block_iterator\u001b[39m(\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m     30\u001b[0m ]:\n\u001b[1;32m     31\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_dataset\n\u001b[0;32m---> 32\u001b[0m     block_iterator, stats, executor \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_to_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     ds\u001b[38;5;241m.\u001b[39m_current_executor \u001b[38;5;241m=\u001b[39m executor\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m block_iterator, stats, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/_internal/plan.py:538\u001b[0m, in \u001b[0;36mExecutionPlan.execute_to_iterator\u001b[0;34m(self, allow_clear_input_blocks, force_read)\u001b[0m\n\u001b[1;32m    536\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(block_iter)\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 538\u001b[0m     block_iter \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain([\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m], gen)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/_internal/execution/legacy_compat.py:54\u001b[0m, in \u001b[0;36mexecute_to_legacy_block_iterator\u001b[0;34m(executor, plan, allow_clear_input_blocks, dataset_uuid)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Same as execute_to_legacy_bundle_iterator but returning blocks and metadata.\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m bundle_iter \u001b[38;5;241m=\u001b[39m execute_to_legacy_bundle_iterator(\n\u001b[1;32m     52\u001b[0m     executor, plan, allow_clear_input_blocks, dataset_uuid\n\u001b[1;32m     53\u001b[0m )\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bundle \u001b[38;5;129;01min\u001b[39;00m bundle_iter:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block, metadata \u001b[38;5;129;01min\u001b[39;00m bundle\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m block, metadata\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/_internal/execution/interfaces/executor.py:37\u001b[0m, in \u001b[0;36mOutputIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RefBundle:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/_internal/execution/streaming_executor.py:118\u001b[0m, in \u001b[0;36mStreamingExecutor.execute.<locals>.StreamIterator.get_next\u001b[0;34m(self, output_split_idx)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_next\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_split_idx: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RefBundle:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_split_idx\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;66;03m# Translate the special sentinel values for MaybeRefBundle into\u001b[39;00m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;66;03m# exceptions.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/llm_data/lib/python3.9/site-packages/ray/data/_internal/execution/streaming_executor_state.py:230\u001b[0m, in \u001b[0;36mOpState.get_output_blocking\u001b[0;34m(self, output_split_idx)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = ResumableTextPipeline()\n",
    "pipeline.enable_statistics()\n",
    "ops = [\n",
    "    ParquetReader(\"/content/test_data/\"),\n",
    "    TextPerplexityScore(),\n",
    "    TextToxicity(huggingface_config_path=\"/root/.cache/huggingface/hub/models--xlm-roberta-base\"),\n",
    "    ParquetWriter(\"ResumableTextPipeline_output-1\")\n",
    "]\n",
    "pipeline.add_operations(ops)\n",
    "ret = pipeline.execute()\n",
    "del pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b1bfef-8d1f-4e7d-80d7-1d8906f9db61",
   "metadata": {},
   "source": [
    "### 3.2 Process with QualityScorer, Diversity and Rouge scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7904f51-9aca-4b79-8a0d-75cf3de91762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-13 07:18:08.316\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mpyrecdp.LLM.TextPipeline\u001b[0m:\u001b[36menable_statistics\u001b[0m:\u001b[36m215\u001b[0m - \u001b[33m\u001b[1mEnabling this option will result in a decrease in execution speed\u001b[0m\n",
      "[DatasetReader, PerfileSourcedParquetReader, TextDiversityIndicate, TextQualityScorer, RougeScoreDedup, PerfileParquetWriter]\n",
      "Will assign 48 cores and 412162 M memory for spark\n",
      "per core memory size is 8.385 GB and shuffle_disk maximum capacity is 8589934592.000 GB\n",
      "execute with spark for global tasks started ...\n",
      "DatasetReader\n",
      "\u001b[32m2023-11-13 07:18:08.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.LLM.TextPipeline\u001b[0m:\u001b[36mop_summary\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mDatasetReader: A total of 0 rows of data were processed, using 0 seconds, with 0 rows modified or removed, 0 rows of data remaining.\u001b[0m\n",
      "execute with spark for global tasks took 0.003243283019401133 sec\n",
      "PerfileSourcedParquetReader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResumableTextPipeline, current on alpaca_sample_10.parquet:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpaca_sample_10.parquet\n",
      "TextDiversityIndicate\n",
      "statistics_decorator spark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextQualityScorer\n",
      "statistics_decorator spark\n",
      "model_name is gpt3\n",
      "\u001b[32m2023-11-13 07:18:18.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.primitives.operations.text_qualityscorer\u001b[0m:\u001b[36mprepare_model\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mPreparing scorer model in [/root/.cache/recdp/models/gpt3_quality_model]...\u001b[0m\n",
      "real_model_path is /root/.cache/recdp/models/gpt3_quality_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-13 07:18:20.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.primitives.operations.text_qualityscorer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mStart scoring dataset...\u001b[0m\n",
      "RougeScoreDedup\n",
      "statistics_decorator spark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:==========================================>          (162 + 38) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-13 07:18:26.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.primitives.operations.text_compare_dedup\u001b[0m:\u001b[36mprocess_spark\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mRound 0: total processing num_samples is 45, detected high score num_samples is 0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \n",
      "100%|██████████| 1/1 [00:06<00:00,  6.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 took 6.029559508984676 sec\n",
      "generate_connected_components => duplicates started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_connected_components => duplicates took 0.017523382004583254 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-13 07:18:27.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.LLM.TextPipeline\u001b[0m:\u001b[36mop_summary\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mTextDiversityIndicate: A total of 10 rows of data were processed, using 9.549101114273071 seconds, Get max diversity types 10, Get average diversity types 1.9,Get the std of diversity types 2.8460498941515415\u001b[0m\n",
      "\u001b[32m2023-11-13 07:18:27.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.LLM.TextPipeline\u001b[0m:\u001b[36mop_summary\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mTextQualityScorer: A total of 10 rows of data were processed, using 2.182723045349121 seconds, Get average quality score 0.9541670706928078\u001b[0m\n",
      "\u001b[32m2023-11-13 07:18:27.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.LLM.TextPipeline\u001b[0m:\u001b[36mop_summary\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mRougeScoreDedup: A total of 10 rows of data were processed, using 6.3509862422943115 seconds, A duplication list containing 0 found, around 0.0% of total data, Sampled, duplication preview: Empty DataFrame\n",
      "Columns: [id_1, id_2, id_pair, similarity_left, similarity_right, score]\n",
      "Index: []\u001b[0m\n",
      "\u001b[32m2023-11-13 07:18:27.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.LLM.TextPipeline\u001b[0m:\u001b[36mop_summary\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mPerfileParquetWriter: A total of 0 rows of data were processed, using 0 seconds, with 0 rows modified or removed, 0 rows of data remaining.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResumableTextPipeline, current on alpaca_sample_10.parquet: 100%|██████████| 1/1 [00:18<00:00, 18.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-13 07:18:27.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyrecdp.LLM.TextPipeline\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m421\u001b[0m - \u001b[1mCompleted! ResumableTextPipeline will not return dataset, please check ResumableTextPipeline_output-2 for verification.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = ResumableTextPipeline()\n",
    "pipeline.enable_statistics()\n",
    "out_dir = \"ResumableTextPipeline_output-2\"\n",
    "ops = [\n",
    "    ParquetReader(\"/content/test_data/alpaca_sample_10.parquet\"),\n",
    "    TextDiversityIndicate(out_dir=out_dir, language=\"en\", first_sent=False),\n",
    "    TextQualityScorer(text_key=\"text\", model=\"gpt3\"),\n",
    "    RougeScoreDedup(max_ratio=0.7, batch_size=10,score_store_path=os.path.join(out_dir,'RougeScorefiltered.parquet')),\n",
    "    ParquetWriter(out_dir)\n",
    "]\n",
    "pipeline.add_operations(ops)\n",
    "ret = pipeline.execute()\n",
    "del pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddbf3d1-a3f3-4aff-8faf-ab46fad4eb08",
   "metadata": {},
   "source": [
    "### 3.3 View score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4544d94-2792-4711-a7de-6a990087c60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality scores:  {'mean': 0.9541670706928078}\n",
      "Diversity scores:  {'max': nan, 'mean': nan, 'std': nan}\n",
      "Rouge scores:  {'dup_num': 0, 'dup_ratio': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# ppl_score = json.load(open(\"ResumableTextPipeline_output-2/TextPerplexityScore-statistics\", \"r\"))\n",
    "# toxicity_score = json.load(open(\"ResumableTextPipeline_output-2/TextToxicity-statistics\", \"r\"))\n",
    "quality_score = json.load(open(\"ResumableTextPipeline_output-2/TextQualityScorer-statistics\", \"r\"))\n",
    "diversity_score = json.load(open(\"ResumableTextPipeline_output-2/TextDiversityIndicate-statistics\", \"r\"))\n",
    "rouge_score = json.load(open(\"ResumableTextPipeline_output-2/RougeScoreDedup-statistics\", \"r\"))\n",
    "\n",
    "print(\"Perplexity scores: \", ppl_score)\n",
    "print(\"Toxicity scores: \", toxicity_score)\n",
    "print(\"Quality scores: \", quality_score)\n",
    "print(\"Diversity scores: \", diversity_score)\n",
    "print(\"Rouge scores: \", rouge_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c1a1de47d404194b50c571744337ab2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "148574df54a94354a4978cf94be86a76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2910b4043048423b94958349a212d7b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53d09e33fd3b4532937a0d383fe28310": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e44de870690644f88c24a0afa74aa54d",
      "placeholder": "​",
      "style": "IPY_MODEL_cfe7ffb4c8194d88aed5c0564b25eef5",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "793adfc9606547dd95e09534c6a8ee9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d67f914b86584956b643e5b017ebf2fd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9756942b4f9b426897fb92b6b353017d",
      "value": 0
     }
    },
    "9756942b4f9b426897fb92b6b353017d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c617382f949f41a899a8891abae6ac05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c1a1de47d404194b50c571744337ab2",
      "placeholder": "​",
      "style": "IPY_MODEL_148574df54a94354a4978cf94be86a76",
      "value": ""
     }
    },
    "cfe7ffb4c8194d88aed5c0564b25eef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d67f914b86584956b643e5b017ebf2fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "db4260225b4f4c59a65491860c2cfd40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c617382f949f41a899a8891abae6ac05",
       "IPY_MODEL_793adfc9606547dd95e09534c6a8ee9c",
       "IPY_MODEL_53d09e33fd3b4532937a0d383fe28310"
      ],
      "layout": "IPY_MODEL_2910b4043048423b94958349a212d7b6"
     }
    },
    "e44de870690644f88c24a0afa74aa54d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
