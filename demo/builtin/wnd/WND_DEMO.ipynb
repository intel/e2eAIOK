{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ded5a89",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/e2eAIOK/blob/main/demo/builtin/wnd/WND_DEMO.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b8b2b",
   "metadata": {},
   "source": [
    "# WnD Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e611394e",
   "metadata": {},
   "source": [
    "Recommendation systems drive engagement on many of the most popular online platforms. As the volume of data available to power these systems grows exponentially, users are increasingly turning from more traditional machine learning methods to highly expressive deep learning models to improve the quality of recommendations. Google's Wide and Deep recommender system is a popular model for recommendation problems for its robustness to signal sparsity.\n",
    "This notebook contains step by step guide on how to optimize WnD model with IntelÂ® End-to-End AI Optimization Kit, and detailed performance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a783f5e",
   "metadata": {},
   "source": [
    "# Content\n",
    "* [Model Architecture](#Model-Architecture)\n",
    "* [Optimizations](#Optimizations)\n",
    "* [Performance Overview](#Performance-Overview)\n",
    "* [DEMO](#DEMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df0609",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "<img src=\"./img/wnd.png\" width=\"800\"/>\n",
    "\n",
    "Wide and Deep model was published by Google at 2016. It jointly train wide linear models and deep neural networks, combined the benefits of memorization and generalization for recommender system. It's the first time to introduce neural network to CTR model.\n",
    "\n",
    "The wide component is a generalized linear model. The feature set includes raw input features and transformed features\n",
    "The deep component is a feed-forward neural network. The sparse, high-dimensional categorical features are first converted into an embedding vector and fed into the hidden layers of a neural network in the forward pass\n",
    "The wide component and deep component are combined using a weighted sum of their output log odds as the prediction and fed to logistic loss function for joint training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b1f075",
   "metadata": {},
   "source": [
    "## Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ad100f",
   "metadata": {},
   "source": [
    "### Distributed Training\n",
    "\n",
    "Use horovod for distributed training and mpirun to launch training script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18b1d8",
   "metadata": {},
   "source": [
    "### Model Optimization\n",
    "\n",
    "Long idle time per training step for horovod communication, horovod paramter sync consume much time during distributed training, causing poor scaling performance. The overhead mainly caused by large embedding table.\n",
    "\n",
    "<img src=\"./img/wnd_profile.png\" width=\"600\"/><figure>Distributed training profiling</figure>\n",
    "\n",
    "Replace custom layer (contains embedding layer) with TensorFlow dense layer help to reduce embedding parameter size, thus reduce parameter size needed to sync by horovod, fix horovod poor scaling issue. Per step training time reduced from 5.16s to 2.71s, got about 1.9x speedup.\n",
    "\n",
    "<img src=\"./img/wnd_traintime_custom_emd.png\" width=\"600\"/><figure>custom layer</figure>\n",
    "<img src=\"./img/wnd_traintime_tf_emd.png\" width=\"600\"/><figure>TensorFlow build-in layer</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd19cd46",
   "metadata": {},
   "source": [
    "### Horovod Optimization With OneCCL\n",
    "\n",
    "Deep part embedding table cost long time hovorod communication, and Allgather is the most time-consuming operation. Enable Intel OneCCL in horovod helps to reduce Allgather time consumption, which delivers 1.2x speedup.\n",
    "\n",
    "<img src=\"./img/wnd_woccl.png\" width=\"600\"/><figure>horovod timeline profiling w/o OneCCL</figure>\n",
    "<img src=\"./img/wnd_wccl.png\" width=\"600\"/><figure>horovod timeline profiling w/ OneCCL</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1aaac4",
   "metadata": {},
   "source": [
    "### Framework Related Optimization\n",
    "\n",
    "set CCL affinity, horovod thread affinity, MPI socket binding, KMP affinity, OMP_NUM_THREADS\n",
    "\n",
    "```bash\n",
    "export CCL_WORKER_COUNT=2 # set CCL thread number\n",
    "export CCL_WORKER_AFFINITY=\"16,17,34,35\" # set CCL thread affinity\n",
    "export HOROVOD_THREAD_AFFINITY=\"53,71\" # set horovod thread affinity\n",
    "export I_MPI_PIN_DOMAIN=socket # set socket binding for MPI\n",
    "export I_MPI_PIN_PROCESSOR_EXCLUDE_LIST=\"16,17,34,35,52,53,70,71\" # exclude CCL threads\n",
    "\n",
    "mpirun -genv OMP_NUM_THREADS=16 -map-by socket -n 2 -ppn 2 -hosts localhost -genv I_MPI_PIN_DOMAIN=socket -genv OMP_PROC_BIND=true -genv KMP_BLOCKTIME=1 -genv KMP_AFFINITY=granularity=fine,compact,1,0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90924745",
   "metadata": {},
   "source": [
    "### Early Stop\n",
    "\n",
    "Training baseline MAP stopped at 0.6553, with optimizations on training process, model converge faster and achieve 0.6553 MAP at 1.5K steps, no need to training to 9K steps. Enable early stop at 0.6553 MAP.\n",
    "\n",
    "<img src=\"./img/wnd_map_GPU.png\"/><figure>baseline metric curv</figure>\n",
    "<img src=\"./img/wnd_early_stop_cpu.png\"/><figure>optimized metric curv</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b7082",
   "metadata": {},
   "source": [
    "### Input Pipeline Optimization\n",
    "\n",
    "Training needs more system resources while input pipeline not, the resources preemption between input pipeline and training caused performance overhead. By reducing system resources allocated for input pipeline to free more resources for training, input pipeline time consuming reduced from 8.2% to 3.2% among entire training time.\n",
    "\n",
    "<img src=\"./img/wnd_input_pipeline_orig.png\" width=\"600\"/><figure>original profiling</figure>\n",
    "<img src=\"./img/wnd_input_pipeline_opt.png\" width=\"600\"/><figure>optimized profiling</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e3f6a",
   "metadata": {},
   "source": [
    "### HPO With SDA (Smart Democratization Advisor)\n",
    "\n",
    "SDA config\n",
    "\n",
    "```\n",
    "Parameters for SDA auto optimization:\n",
    "- dnn_hidden_unit1: [64, 128, 256, 512] #layer width of dnn_hidden_unit1\n",
    "- dnn_hidden_unit2: [64, 128, 256, 512] #layer width of dnn_hidden_unit2\n",
    "- dnn_hidden_unit3: [64, 128, 256, 512] #layer width of dnn_hidden_unit3\n",
    "- deep_learning_rate: 0.0001~0.1 #deep part learning rate\n",
    "- linear_learning_rate: 0.01~1.0 #linear part learning rate\n",
    "- deep_warmup_epochs: 1~8 #deep part warmup epochs\n",
    "- deep_dropout: 0~0.5 #deep part dropout\n",
    "metrics:\n",
    "- name: training_time # training time threshold\n",
    "  objective: minimize\n",
    "  threshold: 1800\n",
    "- name: MAP # training metric threshold\n",
    "  objective: maximize\n",
    "  threshold: 0.6553\n",
    "metric:\n",
    "- name: MAP\n",
    "  threshold: 0.6553\n",
    "```\n",
    "\n",
    "request suggestions from SDA\n",
    "\n",
    "```python\n",
    "suggestion = self.conn.experiments(self.experiment.id).suggestions().create()\n",
    "```\n",
    "\n",
    "<img src=\"./img/wnd_sda.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50f0c0c",
   "metadata": {},
   "source": [
    "## Performance Overview\n",
    "\n",
    "<img src=\"./img/wnd_perf.png\" width=\"900\"/>\n",
    "\n",
    "* Intel optimized TensorFlow: apply OpenMP and KMP optimizations (AFFINITY, NUM_THREADS etc.) for CPU\n",
    "* Distributed training: horovod scaling delivered 1.93x speedup from 1 node to 4 nodes, got poor scaling performance\n",
    "* Model optimization: reducing sparse embedding size helped to reduce horovod communication data size, delivered better scaling performance, 4 nodes training delivered 2.7x speed up over 1 node\n",
    "* Lighter model: reducing deep hidden unit from [1024, 1024, 1024, 1024, 1024] to [1024, 512, 256] delivered 1.14x speedup\n",
    "* Early stop: stop training when MAP@12 reached pre-defined value (0.6553) , training took 904 steps delivered 4.14x speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca9c741",
   "metadata": {},
   "source": [
    "# DEMO\n",
    "* [Environment Setup](#Environment-Setup)\n",
    "* [Data Process](#Data-Process)\n",
    "* [Launch Training](#Launch-Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca039366",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "### Option 1 Setup Environment with Docker\n",
    "``` bash\n",
    "# Setup ENV\n",
    "git clone https://github.com/intel/e2eAIOK.git\n",
    "cd e2eAIOK\n",
    "git submodule update --init --recursive\n",
    "python3 scripts/start_e2eaiok_docker.py -b tensorflow -w ${host0} ${host1} ${host2} ${host3} --proxy \"\"\n",
    "# Enter Docker\n",
    "sshpass -p docker ssh ${host0} -p 12344\n",
    "```\n",
    "\n",
    "### Option 2 Setup Environment with Pip\n",
    "pre-work: move e2eAIOK source code to /home/vmagent/app/e2eaiok. Install spark and start spark services for data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e820c8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sigopt in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (8.7.0)\n",
      "Collecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "     âââââââââââââââââââââââââââââââââââââ 840.9/840.9 kB 915.7 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from sigopt) (8.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from sigopt) (2.28.2)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.5 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from sigopt) (1.26.15)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from sigopt) (23.0)\n",
      "Requirement already satisfied: PyYAML<6.0.0,>=5.4.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from sigopt) (5.4.1)\n",
      "Requirement already satisfied: pypng>=0.0.20 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from sigopt) (0.20220715.0)\n",
      "Requirement already satisfied: backoff<2.0.0,>=1.10.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from sigopt) (1.11.1)\n",
      "Requirement already satisfied: GitPython>=2.0.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from sigopt) (3.1.31)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from GitPython>=2.0.0->sigopt) (4.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.25.0->sigopt) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.25.0->sigopt) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.25.0->sigopt) (2022.6.15)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.0->sigopt) (5.0.0)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492037 sha256=dff9dbcc21d8ff03f2fbe858fdd1e49765179f77b9395151c14498dc3363e5a2\n",
      "  Stored in directory: /root/.cache/pip/wheels/bf/5d/6a/2e53874f7ec4e2bede522385439531fafec8fafe005b5c3d1b\n",
      "Successfully built future\n",
      "Installing collected packages: future\n",
      "Successfully installed future-0.18.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: intel-tensorflow==2.10 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (2.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (0.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (3.19.6)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (3.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (1.15.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (4.5.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (2.10.1)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (1.24.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (1.51.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (23.3.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (15.0.6.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (0.4.0)\n",
      "Requirement already satisfied: packaging in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (23.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (0.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (58.0.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from intel-tensorflow==2.10) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from astunparse>=1.6.0->intel-tensorflow==2.10) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (2.16.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (0.4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (6.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (1.26.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (0.4.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: horovod in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (0.27.0)\n",
      "Requirement already satisfied: pyyaml in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from horovod) (5.4.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from horovod) (2.2.1)\n",
      "Requirement already satisfied: packaging in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from horovod) (23.0)\n",
      "Requirement already satisfied: psutil in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (from horovod) (5.9.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-transform==0.24.1 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (0.24.1)\n",
      "Requirement already satisfied: tensorflow-metadata==0.14.0 in /opt/intel/oneapi/intelpython/python3.9/envs/tensorflow/lib/python3.9/site-packages (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/mlperf/logging.git@1.0.0\n",
      "  Cloning https://github.com/mlperf/logging.git (to revision 1.0.0) to /tmp/pip-req-build-qg0smzo6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/mlperf/logging.git /tmp/pip-req-build-qg0smzo6\n",
      "  Running command git checkout -q 982b15a62604491f23b7afdfacda57829d174f36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Resolved https://github.com/mlperf/logging.git to commit 982b15a62604491f23b7afdfacda57829d174f36\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting e2eAIOK-sda\n",
      "  Using cached e2eAIOK_sda-1.0.1b2023031702-py3-none-any.whl (91 kB)\n",
      "Installing collected packages: e2eAIOK-sda\n",
      "Successfully installed e2eAIOK-sda-1.0.1b2023031702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install sigopt future pydot dill\n",
    "pip install --no-cache-dir intel-tensorflow==2.10\n",
    "HOROVOD_WITHOUT_MPI=1 HOROVOD_CPU_OPERATIONS=CCL \\\n",
    "    HOROVOD_WITHOUT_MXNET=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITH_TENSORFLOW=1 \\\n",
    "    pip install --no-cache-dir horovod\n",
    "pip install --no-cache-dir --no-deps tensorflow-transform==0.24.1 tensorflow-metadata==0.14.0\n",
    "pip install \"git+https://github.com/mlperf/logging.git@1.0.0\"\n",
    "pip install e2eAIOK-sda --pre --no-deps --ignore-installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd9a8f5",
   "metadata": {},
   "source": [
    "## Workflow Prepare\n",
    "\n",
    "``` bash\n",
    "# prepare model codes\n",
    "cd /home/vmagent/app/e2eaiok/modelzoo/WnD/TensorFlow2\n",
    "bash patch_wnd.patch\n",
    "\n",
    "# Download Dataset\n",
    "# download and unzip dataset from https://www.kaggle.com/c/outbrain-click-prediction/data to /home/vmagent/app/dataset/outbrain/orig\n",
    "\n",
    "# source spark env\n",
    "source /home/spark-env.sh\n",
    "\n",
    "# Start services\n",
    "# only if there is no spark service running, may check ${localhost}:8080 to confirm\n",
    "/home/start_spark_service.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47448679",
   "metadata": {},
   "source": [
    "## Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0215585f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 22:02:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/31 22:02:30 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "Drop rows with empty \"geo_location\"...\n",
      "Drop rows with empty \"platform\"...\n",
      "valid_set_df time: 38.694966077804565                                           ]\n",
      "train_set_df time: 42.35809636116028                                            1]\n",
      "train/test dataset generation time: 95.60888910293579\n",
      "22/10/31 22:04:18 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "test_set_enriched_df time: 67.92218327522278                                    0]]0]\n",
      "train_set_enriched_df time: 83.92503476142883                                   \n",
      "WARNING:tensorflow:From /home/vmagent/app/e2eaiok/modelzoo/WnD/TensorFlow2/data/outbrain/spark/preproc.py:654: from_feature_spec (from tensorflow_transform.tf_metadata.dataset_schema) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "from_feature_spec is a deprecated, use schema_utils.schema_from_feature_spec\n",
      "2022-10-31 22:09:16.917781\tComputing min and max\n",
      "[Row(min(ad_views)=0, max(ad_views)=144659, min(doc_views)=0, max(doc_views)=556631, min(doc_event_days_since_published)=0.0, max(doc_event_days_since_published)=3650.0, min(doc_ad_days_since_published)=0.0, max(doc_ad_days_since_published)=3648.0)]\n",
      "feature engineering time: 328.1621606349945                                     \n",
      "data convert time: 178.53657913208008                                           \n"
     ]
    }
   ],
   "source": [
    "!cd /home/vmagent/app/e2eaiok/modelzoo/WnD/TensorFlow2; sh scripts/spark_preproc.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d6539",
   "metadata": {},
   "source": [
    "## Launch Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369c36c2",
   "metadata": {},
   "source": [
    "edit conf/e2eaiok_defaults_wnd_example.conf\n",
    "\n",
    "```\n",
    "### GLOBAL SETTINGS ###\n",
    "observation_budget: 1\n",
    "save_path: /home/vmagent/app/e2eaiok/result/\n",
    "ppn: 2\n",
    "ccl_worker_num: 2\n",
    "global_batch_size: 524288\n",
    "num_epochs: 20\n",
    "cores: 104\n",
    "iface: lo\n",
    "hosts:\n",
    "- localhost\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "569bf322",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 03:26:10,854 - E2EAIOK - INFO - Above info is history record of this model\n",
      "2023-03-20 03:26:10,854 - E2EAIOK.SDA - INFO - ### Ready to submit current task  ###\n",
      "2023-03-20 03:26:10,855 - E2EAIOK.SDA - INFO - Model Advisor created\n",
      "2023-03-20 03:26:10,855 - E2EAIOK.SDA - INFO - model parameter initialized\n",
      "2023-03-20 03:26:10,855 - E2EAIOK.SDA - INFO - start to launch training\n",
      "2023-03-20 03:26:10,855 - sigopt - INFO - training launch command: mpirun -genv OMP_NUM_THREADS=24 -map-by socket -n 2 -ppn 2 -hosts localhost -print-rank-map -genv I_MPI_PIN_DOMAIN=socket -genv OMP_PROC_BIND=true -genv KMP_BLOCKTIME=1 -genv KMP_AFFINITY=granularity=fine,compact,1,0 /opt/intel/oneapi/intelpython/latest/envs/tensorflow/bin/python -u /home/vmagent/app/e2eaiok/modelzoo/WnD/TensorFlow2/main.py --results_dir /home/vmagent/app/e2eaiok/result --model_dir /home/vmagent/app/e2eaiok/result/6c37b08d7939bb0d5de5f1e4c4303884f82b1c47d3d61173d1caf86893e9a845 --train_data_pattern '/home/vmagent/app/dataset/outbrain/train/part*' --eval_data_pattern '/home/vmagent/app/dataset/outbrain/valid/part*' --dataset_meta_file /home/vmagent/app/dataset/outbrain/outbrain_meta.yaml --global_batch_size 524288 --eval_batch_size 524288 --num_epochs 20 --metric MAP --metric_threshold 0.6553 --linear_learning_rate 0.8 --deep_learning_rate 0.00048 --deep_warmup_epochs 6 --deep_hidden_units 1024 512 256 --deep_dropout 0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(localhost:0,1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 03:26:11.070944: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-20 03:26:11.074648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:command line arguments: {\"train_data_pattern\": \"/home/vmagent/app/dataset/outbrain/train/part*\", \"eval_data_pattern\": \"/home/vmagent/app/dataset/outbrain/valid/part*\", \"dataset_meta_file\": \"/home/vmagent/app/dataset/outbrain/outbrain_meta.yaml\", \"model_dir\": \"/home/vmagent/app/e2eaiok/result/6c37b08d7939bb0d5de5f1e4c4303884f82b1c47d3d61173d1caf86893e9a845\", \"results_dir\": \"/home/vmagent/app/e2eaiok/result\", \"global_batch_size\": 524288, \"eval_batch_size\": 524288, \"num_epochs\": 20, \"amp\": false, \"xla\": false, \"linear_learning_rate\": 0.8, \"deep_learning_rate\": 0.00048, \"deep_warmup_epochs\": 6.0, \"metric\": \"MAP\", \"metric_threshold\": 0.6553, \"deep_hidden_units\": [1024, 512, 256], \"deep_dropout\": 0.1, \"evaluate\": false, \"use_checkpoint\": false, \"benchmark\": false, \"benchmark_warmup_steps\": 500, \"benchmark_steps\": 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All feature columns: ['doc_event_days_since_published_log_01scaled', 'doc_ad_days_since_published_log_01scaled', 'doc_event_doc_ad_sim_categories', 'doc_event_doc_ad_sim_topics', 'doc_event_doc_ad_sim_entities', 'pop_document_id', 'pop_publisher_id', 'pop_source_id', 'pop_ad_id', 'pop_advertiser_id', 'pop_campain_id', 'doc_views_log_01scaled', 'ad_views_log_01scaled', 'ad_id', 'campaign_id', 'doc_event_id', 'event_platform', 'doc_id', 'ad_advertiser', 'doc_event_source_id', 'doc_event_publisher_id', 'doc_ad_source_id', 'doc_ad_publisher_id', 'event_geo_location', 'event_country', 'event_country_state', 'display_id']\n",
      "rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:command line arguments: {\"train_data_pattern\": \"/home/vmagent/app/dataset/outbrain/train/part*\", \"eval_data_pattern\": \"/home/vmagent/app/dataset/outbrain/valid/part*\", \"dataset_meta_file\": \"/home/vmagent/app/dataset/outbrain/outbrain_meta.yaml\", \"model_dir\": \"/home/vmagent/app/e2eaiok/result/6c37b08d7939bb0d5de5f1e4c4303884f82b1c47d3d61173d1caf86893e9a845\", \"results_dir\": \"/home/vmagent/app/e2eaiok/result\", \"global_batch_size\": 524288, \"eval_batch_size\": 524288, \"num_epochs\": 20, \"amp\": false, \"xla\": false, \"linear_learning_rate\": 0.8, \"deep_learning_rate\": 0.00048, \"deep_warmup_epochs\": 6.0, \"metric\": \"MAP\", \"metric_threshold\": 0.6553, \"deep_hidden_units\": [1024, 512, 256], \"deep_dropout\": 0.1, \"evaluate\": false, \"use_checkpoint\": false, \"benchmark\": false, \"benchmark_warmup_steps\": 500, \"benchmark_steps\": 1000}\n",
      "2023-03-20 03:26:12.584224: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All feature columns: ['doc_event_days_since_published_log_01scaled', 'doc_ad_days_since_published_log_01scaled', 'doc_event_doc_ad_sim_categories', 'doc_event_doc_ad_sim_topics', 'doc_event_doc_ad_sim_entities', 'pop_document_id', 'pop_publisher_id', 'pop_source_id', 'pop_ad_id', 'pop_advertiser_id', 'pop_campain_id', 'doc_views_log_01scaled', 'ad_views_log_01scaled', 'ad_id', 'campaign_id', 'doc_event_id', 'event_platform', 'doc_id', 'ad_advertiser', 'doc_event_source_id', 'doc_event_publisher_id', 'doc_ad_source_id', 'doc_ad_publisher_id', 'event_geo_location', 'event_country', 'event_country_state', 'display_id']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 03:26:12.603580: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:deep columns: 26\n",
      "WARNING:tensorflow:wide columns: 26\n",
      "WARNING:tensorflow:wide&deep intersection: 13\n",
      "WARNING:tensorflow:deep columns: 26\n",
      "WARNING:tensorflow:wide columns: 26\n",
      "WARNING:tensorflow:wide&deep intersection: 13\n",
      "INFO:tensorflow:Steps per epoch: 113\n",
      "INFO:tensorflow:Steps per epoch: 113\n",
      "/opt/intel/oneapi/intelpython/latest/envs/tensorflow/lib/python3.9/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['display_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/intel/oneapi/intelpython/latest/envs/tensorflow/lib/python3.9/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['display_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "OMP: Warning #182: OMP_PROC_BIND: ignored because KMP_AFFINITY has been defined\n",
      "OMP: Warning #182: OMP_PROC_BIND: ignored because KMP_AFFINITY has been defined\n",
      "INFO:tensorflow:step: 0, {'binary_accuracy': '0.5847', 'auc': '0.4993', 'loss': '0.7599', 'time': '22.7443'}\n",
      "INFO:tensorflow:step: 0, {'binary_accuracy': '0.5017', 'auc': '0.4784', 'loss': '0.9201', 'time': '22.9567'}\n",
      "INFO:tensorflow:step: 4, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.51236695, 'loss_val': 0.50151324, 'map_val': 0.47512450125897143}\n",
      "INFO:tensorflow:step: 4, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.48926234, 'loss_val': 0.50583273, 'map_val': 0.4768476171950088}\n",
      "INFO:tensorflow:step: 8, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.5868751, 'loss_val': 0.4917338, 'map_val': 0.5429098255787144}\n",
      "INFO:tensorflow:step: 8, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.5657964, 'loss_val': 0.4931752, 'map_val': 0.5567070799701234}\n",
      "INFO:tensorflow:step: 10, {'binary_accuracy': '0.7549', 'auc': '0.5469', 'loss': '0.5888', 'time': '92.7734'}\n",
      "INFO:tensorflow:step: 10, {'binary_accuracy': '0.7345', 'auc': '0.5268', 'loss': '0.6339', 'time': '93.5691'}\n",
      "INFO:tensorflow:step: 12, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.6232515, 'loss_val': 0.48956797, 'map_val': 0.5738884586051617}\n",
      "INFO:tensorflow:step: 12, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.6056773, 'loss_val': 0.48772588, 'map_val': 0.586893420001355}\n",
      "INFO:tensorflow:step: 16, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.6486573, 'loss_val': 0.48309276, 'map_val': 0.5932171760783478}\n",
      "INFO:tensorflow:step: 16, {'binary_accuracy_val': 0.80656815, 'auc_val': 0.6297939, 'loss_val': 0.4814657, 'map_val': 0.6024248131477974}\n",
      "INFO:tensorflow:step: 20, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.6611216, 'loss_val': 0.48290002, 'map_val': 0.601835485940088}\n",
      "INFO:tensorflow:step: 20, {'binary_accuracy_val': 0.80657196, 'auc_val': 0.6454518, 'loss_val': 0.47466362, 'map_val': 0.6118453559999517}\n",
      "INFO:tensorflow:step: 20, {'binary_accuracy': '0.7792', 'auc': '0.5841', 'loss': '0.5430', 'time': '83.6147'}\n",
      "INFO:tensorflow:step: 20, {'binary_accuracy': '0.7774', 'auc': '0.5509', 'loss': '0.5781', 'time': '84.6817'}\n",
      "INFO:tensorflow:step: 24, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.6707722, 'loss_val': 0.4794454, 'map_val': 0.6087569436787487}\n",
      "INFO:tensorflow:step: 24, {'binary_accuracy_val': 0.8065891, 'auc_val': 0.65199375, 'loss_val': 0.47420955, 'map_val': 0.6157590792605535}\n",
      "INFO:tensorflow:step: 28, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.6762669, 'loss_val': 0.4787018, 'map_val': 0.6129967338562391}\n",
      "INFO:tensorflow:step: 28, {'binary_accuracy_val': 0.8066044, 'auc_val': 0.65870243, 'loss_val': 0.47082117, 'map_val': 0.6197217298646603}\n",
      "INFO:tensorflow:step: 30, {'binary_accuracy': '0.7766', 'auc': '0.6109', 'loss': '0.5397', 'time': '80.7990'}\n",
      "INFO:tensorflow:step: 30, {'binary_accuracy': '0.7685', 'auc': '0.5956', 'loss': '0.5594', 'time': '81.9725'}\n",
      "INFO:tensorflow:step: 32, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.6798262, 'loss_val': 0.47818717, 'map_val': 0.6160163680129069}\n",
      "INFO:tensorflow:step: 32, {'binary_accuracy_val': 0.80669403, 'auc_val': 0.66466856, 'loss_val': 0.4666531, 'map_val': 0.6229368752570906}\n",
      "INFO:tensorflow:step: 36, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.68234336, 'loss_val': 0.47886482, 'map_val': 0.6179788328294931}\n",
      "INFO:tensorflow:step: 36, {'binary_accuracy_val': 0.80675316, 'auc_val': 0.6660633, 'loss_val': 0.46688533, 'map_val': 0.6240121299600855}\n",
      "INFO:tensorflow:step: 40, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.68479276, 'loss_val': 0.47779387, 'map_val': 0.6197000986451058}\n",
      "INFO:tensorflow:step: 40, {'binary_accuracy_val': 0.8069401, 'auc_val': 0.6680549, 'loss_val': 0.4656569, 'map_val': 0.6252515377627543}\n",
      "INFO:tensorflow:step: 40, {'binary_accuracy': '0.7924', 'auc': '0.6331', 'loss': '0.5066', 'time': '83.6997'}\n",
      "INFO:tensorflow:step: 40, {'binary_accuracy': '0.7886', 'auc': '0.6222', 'loss': '0.5214', 'time': '84.5368'}\n",
      "INFO:tensorflow:step: 44, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.6869848, 'loss_val': 0.4764827, 'map_val': 0.6214133037553112}\n",
      "INFO:tensorflow:step: 44, {'binary_accuracy_val': 0.8071251, 'auc_val': 0.67019385, 'loss_val': 0.46416906, 'map_val': 0.6263434542212906}\n",
      "INFO:tensorflow:step: 48, {'binary_accuracy_val': 0.80656815, 'auc_val': 0.6895565, 'loss_val': 0.4734072, 'map_val': 0.623155613490186}\n",
      "INFO:tensorflow:step: 48, {'binary_accuracy_val': 0.80717087, 'auc_val': 0.671778, 'loss_val': 0.46305853, 'map_val': 0.6270793144527282}\n",
      "INFO:tensorflow:step: 50, {'binary_accuracy': '0.7828', 'auc': '0.6394', 'loss': '0.5168', 'time': '81.0390'}\n",
      "INFO:tensorflow:step: 50, {'binary_accuracy': '0.7849', 'auc': '0.6626', 'loss': '0.5112', 'time': '81.7457'}\n",
      "INFO:tensorflow:step: 52, {'binary_accuracy_val': 0.80656815, 'auc_val': 0.69013023, 'loss_val': 0.47459745, 'map_val': 0.6235829642732605}\n",
      "INFO:tensorflow:step: 52, {'binary_accuracy_val': 0.8072128, 'auc_val': 0.67308176, 'loss_val': 0.46212026, 'map_val': 0.6277487482108685}\n",
      "INFO:tensorflow:step: 56, {'binary_accuracy_val': 0.80656815, 'auc_val': 0.69085085, 'loss_val': 0.47558376, 'map_val': 0.6240111677267172}\n",
      "INFO:tensorflow:step: 56, {'binary_accuracy_val': 0.8072376, 'auc_val': 0.67456186, 'loss_val': 0.46114266, 'map_val': 0.6283366866721566}\n",
      "INFO:tensorflow:step: 60, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.6928512, 'loss_val': 0.4724648, 'map_val': 0.6253232783966024}\n",
      "INFO:tensorflow:step: 60, {'binary_accuracy_val': 0.807251, 'auc_val': 0.6751385, 'loss_val': 0.46087614, 'map_val': 0.6286683025274231}\n",
      "INFO:tensorflow:step: 60, {'binary_accuracy': '0.7963', 'auc': '0.6657', 'loss': '0.4846', 'time': '83.8232'}\n",
      "INFO:tensorflow:step: 60, {'binary_accuracy': '0.7992', 'auc': '0.6614', 'loss': '0.4879', 'time': '85.0643'}\n",
      "INFO:tensorflow:step: 64, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.69322425, 'loss_val': 0.4736255, 'map_val': 0.6255947989539837}\n",
      "INFO:tensorflow:step: 64, {'binary_accuracy_val': 0.80739594, 'auc_val': 0.67744637, 'loss_val': 0.45919728, 'map_val': 0.6294126809253076}\n",
      "INFO:tensorflow:step: 68, {'binary_accuracy_val': 0.80657005, 'auc_val': 0.69406104, 'loss_val': 0.4732104, 'map_val': 0.626014479972306}\n",
      "INFO:tensorflow:step: 68, {'binary_accuracy_val': 0.8073921, 'auc_val': 0.67764467, 'loss_val': 0.45910335, 'map_val': 0.6296286882654015}\n",
      "INFO:tensorflow:step: 70, {'binary_accuracy': '0.7853', 'auc': '0.6651', 'loss': '0.5008', 'time': '80.8199'}\n",
      "INFO:tensorflow:step: 70, {'binary_accuracy': '0.7939', 'auc': '0.6653', 'loss': '0.4895', 'time': '81.7217'}\n",
      "INFO:tensorflow:step: 72, {'binary_accuracy_val': 0.80657196, 'auc_val': 0.695836, 'loss_val': 0.4700833, 'map_val': 0.6271318577304991}\n",
      "INFO:tensorflow:step: 72, {'binary_accuracy_val': 0.8075962, 'auc_val': 0.67904913, 'loss_val': 0.45836234, 'map_val': 0.6300931727191181}\n",
      "INFO:tensorflow:step: 76, {'binary_accuracy_val': 0.80657196, 'auc_val': 0.69613516, 'loss_val': 0.47120035, 'map_val': 0.6273574087892766}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step: 76, {'binary_accuracy_val': 0.807745, 'auc_val': 0.6799588, 'loss_val': 0.4579533, 'map_val': 0.6306602237796957}\n",
      "INFO:tensorflow:step: 80, {'binary_accuracy_val': 0.8065758, 'auc_val': 0.69763887, 'loss_val': 0.468185, 'map_val': 0.6284368706397934}\n",
      "/opt/intel/oneapi/intelpython/latest/envs/tensorflow/lib/python3.9/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['display_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/intel/oneapi/intelpython/latest/envs/tensorflow/lib/python3.9/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['display_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "INFO:tensorflow:step: 80, {'binary_accuracy_val': 0.80775833, 'auc_val': 0.6805829, 'loss_val': 0.45774108, 'map_val': 0.6307005742622972}\n",
      "/opt/intel/oneapi/intelpython/latest/envs/tensorflow/lib/python3.9/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['display_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "INFO:tensorflow:Assets written to: /home/vmagent/app/e2eaiok/result/6c37b08d7939bb0d5de5f1e4c4303884f82b1c47d3d61173d1caf86893e9a845/assets\n",
      "/opt/intel/oneapi/intelpython/latest/envs/tensorflow/lib/python3.9/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['display_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "INFO:tensorflow:Final eval result: {'binary_accuracy_val': 0.8065758, 'auc_val': 0.69763887, 'loss_val': 0.468185, 'map_val': 0.6284368706397934}\n",
      "/opt/intel/oneapi/intelpython/latest/envs/tensorflow/lib/python3.9/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['display_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/intel/oneapi/intelpython/latest/envs/tensorflow/lib/python3.9/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['display_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "INFO:tensorflow:Assets written to: /home/vmagent/app/e2eaiok/result/6c37b08d7939bb0d5de5f1e4c4303884f82b1c47d3d61173d1caf86893e9a845/assets\n",
      "INFO:tensorflow:Final eval result: {'binary_accuracy_val': 0.80775833, 'auc_val': 0.6805829, 'loss_val': 0.45774108, 'map_val': 0.6307005742622972}\n",
      "2023-03-20 03:37:59,368 - sigopt - INFO - Training completed based in sigopt suggestion, took 708.5124206542969 secs\n",
      "2023-03-20 03:37:59,368 - E2EAIOK.SDA - INFO - training script completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data format is tfrecords\n",
      "\n",
      "===============================================\n",
      "***    Best Trained Model    ***\n",
      "===============================================\n",
      "  Model Type: wnd\n",
      "  Model Saved Path: \n",
      "  Sigopt Experiment id is None\n",
      "  === Result Metrics ===\n",
      "===============================================\n",
      "\n",
      "We found the best model! Here is the model explaination\n",
      "\n",
      "===============================================\n",
      "***    Best Trained Model    ***\n",
      "===============================================\n",
      "  Model Type: wnd\n",
      "  Model Saved Path: /home/vmagent/app/e2eaiok/result/6c37b08d7939bb0d5de5f1e4c4303884f82b1c47d3d61173d1caf86893e9a845\n",
      "  Sigopt Experiment id is None\n",
      "  === Result Metrics ===\n",
      "    MAP: 0.6307005742622972\n",
      "    training_time: 708.5124206542969\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/vmagent/app/e2eaiok\n",
    "python run_e2eaiok.py --data_path /home/vmagent/app/dataset/outbrain/ --model_name wnd --conf tests/cicd/conf/e2eaiok_defaults_wnd_example.conf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f9fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
