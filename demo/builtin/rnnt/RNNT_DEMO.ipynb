{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/e2eAIOK/blob/main/demo/builtin/rnnt/RNNT_DEMO.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN-T Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic speech recognition (ASR) systems convert audio into text representation. RNN-T is an end-to-end rnn based ASR model that directly output word transcripts given the input audio. This notebook contains step by step guide on how to optimize RNN-T model with IntelÂ® End-to-End AI Optimization Kit, and detailed performance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "* [Model Architecture](#Model-Architecture)\n",
    "* [Optimizations](#Optimizations)\n",
    "* [DEMO](#DEMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASR\n",
    "<img src=\"./img/asr.png\" width=\"800\"/>\n",
    "\n",
    "* The traditional ASR system (top picture) contains acoustic, phonetic and language components that work together as in a pipeline system\n",
    "* The end-to-end ASR system is a single neural network that receives raw audio signal as input and provides a sequence of words at output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "<img src=\"./img/rnnt_structure.png\"/>\n",
    "\n",
    "RNN-T is an end-to-end ASR model that directly converts audio into text representation.\n",
    "\n",
    "The encoder network is a RNN which maps input acoustic frames into a higher-level representation.\n",
    "The prediction network is a RNN that is explicitly conditioned on the history of previous non-blank targets predicted by the model.\n",
    "The joint network is a feed-forward network that combines the outputs of the prediction network and the encoder to produce logits followed by a softmax layer to produce a distribution over the next output symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture Intro\n",
    "\n",
    "For RNN-T model democratization, we enabled distributed training with pytorch DDP to scale out model training on multi nodes, added time stack layer and increased time stack factor to reduce input sequence lengh, added layer and batch normalization to speedup training converge, decreased layer size to get a lighter model.\n",
    "\n",
    "<img src=\"./img/model_base.png\" width=\"600\"/><figure>base model</figure>\n",
    "<img src=\"./img/model_opt.png\" width=\"600\"/><figure>democratized model</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed training\n",
    "\n",
    "``` python\n",
    "# data parallel\n",
    "if world_size > 1:\n",
    "    model = DDP(model, find_unused_parameters=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add time stack layer\n",
    "\n",
    "For ASR systems, the number of time frames for an audio input sequence is significantly higher than the number of output text labels. LSTM is sequential model which leads to much time cost in process long sequence data like audio data. The StackTime layer stacks audio frames to reduce sequence length and form a higher dimension input, which helps to speedup training process.\n",
    "\n",
    "```python\n",
    "class StackTime(nn.Module):\n",
    "    def __init__(self, factor):\n",
    "        super().__init__()\n",
    "        self.factor = int(factor)\n",
    "\n",
    "    def stack(self, x):\n",
    "        x = x.transpose(0, 1)\n",
    "        T = x.size(1)\n",
    "        padded = torch.nn.functional.pad(x, (0, 0, 0, (self.factor - (T % self.factor)) % self.factor))\n",
    "        B, T, H = padded.size()\n",
    "        x = padded.reshape(B, T // self.factor, -1)\n",
    "        x = x.transpose(0, 1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, x_lens):\n",
    "        if type(x) is not list:\n",
    "            x = self.stack(x)\n",
    "            x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
    "            return x, x_lens\n",
    "        else:\n",
    "            if len(x) != 2:\n",
    "                raise NotImplementedError(\"Only number of seq segments equal to 2 is supported\")\n",
    "            assert x[0].size(1) % self.factor == 0, \"The length of the 1st seq segment should be multiple of stack factor\"\n",
    "            y0 = self.stack(x[0])\n",
    "            y1 = self.stack(x[1])\n",
    "            x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
    "            return [y0, y1], x_lens\n",
    "```\n",
    "\n",
    "About 4x speedup after increase time stack factor from 2 to 8.\n",
    "\n",
    "<img src=\"./img/time_stack_2.PNG\" width=\"600\"/><figure>time_stack = 2</figure>\n",
    "<img src=\"./img/time_stack_8.PNG\" width=\"600\"/><figure>time_stack = 8</figure>\n",
    "\n",
    "Profiling data proves that less time cost on forward/backward since input sequence reduced with time stack layer\n",
    "\n",
    "<img src=\"./img/stack_profile_base.png\" width=\"600\"/><figure>base model profiling</figure>\n",
    "<img src=\"./img/stack_profile_democratize.png\" width=\"600\"/><figure>democratized model profiling</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add layer normalization and batch normalization\n",
    "\n",
    "Layer normalization for LSTM is important to the success of RNN-T modeling. Add layer normalization for LSTM and batch normalization for input feature help to speedup training converge. It takes 52 epochs to converge without normalization, while only 49 epochs needed with normalization. \n",
    "\n",
    "```python\n",
    "enc_mod[\"batch_norm\"] = nn.BatchNorm1d(pre_rnn_input_size)\n",
    "```\n",
    "\n",
    "```python\n",
    "self.layer_norm = torch.nn.LayerNorm(hidden_size)\n",
    "```\n",
    "\n",
    "<img src=\"./img/no_norm.PNG\" width=\"600\"/><figure>without normalization</figure>\n",
    "<img src=\"./img/norm.PNG\" width=\"600\"/><figure>with normalization</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO with SDA (Smart Democratization Advisor)\n",
    "\n",
    "SDA config\n",
    "\n",
    "```\n",
    "Parameters for SDA auto optimization:\n",
    "- learning_rate: 1.0e-3~1.0e-2 #training learning rate\n",
    "- warmup_epochs: 1~10 #epoch to warmup learning rate\n",
    "metrics:\n",
    "- name: training_time # training time threshold\n",
    "  objective: minimize\n",
    "  threshold: 43200\n",
    "- name: WER # training metric threshold\n",
    "  objective: minimize\n",
    "  threshold: 0.25\n",
    " ```\n",
    "\n",
    "request suggestions from SDA\n",
    "\n",
    "```python\n",
    "suggestion = self.conn.experiments(self.experiment.id).suggestions().create()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework related optimization\n",
    "\n",
    "leverage IPEX for distributed training and enable socket binding for training in two socket system\n",
    "\n",
    "```bash\n",
    "# Use IPEX launch to launch training, enable NUMA binding in two socket system.\n",
    "${CONDA_PREFIX}/bin/python -m intel_extension_for_pytorch.cpu.launch --distributed --nproc_per_node=2 --nnodes=4 --hostfile hosts train.py ${ARGS}\n",
    "```\n",
    "\n",
    "<img src=\"./img/no_numa_binding.png\" width=\"600\"/><figure>without numa binding</figure>\n",
    "<img src=\"./img/numa_binding.png\" width=\"600\"/><figure>enable numa binding</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO\n",
    "* [Environment Setup](#Environment-setup)\n",
    "* [Launch training](#Launch-training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "### Option1 Setup Environment with Docker\n",
    "``` bash\n",
    "# Setup ENV\n",
    "git clone https://github.com/intel/e2eAIOK.git\n",
    "cd e2eAIOK\n",
    "git submodule update --init --recursive\n",
    "python3 scripts/start_e2eaiok_docker.py -b pytorch110 -w ${host0} ${host1} ${host2} ${host3} --proxy \"\"\n",
    "# Enter Docker\n",
    "sshpass -p docker ssh ${host0} -p 12345\n",
    "```\n",
    "\n",
    "### Option2 Setup Environment with Pip\n",
    "pre-work: move e2eAIOK source code to /home/vmagent/app/e2eaiok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1112: The handshake operation timed out'))': /whl/cpu/torchaudio/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudio==0.12.1\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchaudio-0.12.1%2Bcpu-cp39-cp39-linux_x86_64.whl (3.5 MB)\n",
      "Collecting torch==1.12.1\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torch-1.12.1%2Bcpu-cp39-cp39-linux_x86_64.whl (189.2 MB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: typing-extensions, torch, torchaudio\n",
      "Successfully installed torch-1.12.1+cpu torchaudio-0.12.1+cpu typing-extensions-4.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://developer.intel.com/ipex-whl-stable\n",
      "Collecting oneccl_bind_pt==1.12.100\n",
      "  Downloading http://intel-optimized-pytorch.s3.cn-north-1.amazonaws.com.cn/wheels/v1.12.100/oneccl_bind_pt-1.12.100%2Bcpu-cp39-cp39-linux_x86_64.whl (39.3 MB)\n",
      "     ââââââââââââââââââââââââââââââââââââââââ 39.3/39.3 MB 16.7 MB/s eta 0:00:00\n",
      "Collecting intel-extension-for-pytorch==1.12.100\n",
      "  Downloading http://intel-optimized-pytorch.s3.cn-north-1.amazonaws.com.cn/wheels/v1.12.100/intel_extension_for_pytorch-1.12.100%2Bcpu-cp39-cp39-linux_x86_64.whl (36.8 MB)\n",
      "     ââââââââââââââââââââââââââââââââââââââââ 36.8/36.8 MB 17.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from intel-extension-for-pytorch==1.12.100) (5.9.4)\n",
      "Installing collected packages: oneccl_bind_pt, intel-extension-for-pytorch\n",
      "Successfully installed intel-extension-for-pytorch-1.12.100+cpu oneccl_bind_pt-1.12.100+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://developer.download.nvidia.com/compute/redist\n",
      "Collecting nvidia-dali-cuda110==1.9.0\n",
      "  Using cached https://developer.download.nvidia.cn/compute/redist/nvidia-dali-cuda110/nvidia_dali_cuda110-1.9.0-3647997-py3-none-manylinux2014_x86_64.whl (680.9 MB)\n",
      "Installing collected packages: nvidia-dali-cuda110\n",
      "Successfully installed nvidia-dali-cuda110-1.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dllogger\n",
      "  Cloning https://github.com/NVIDIA/dllogger to /tmp/pip-install-usu5pi_7/dllogger_95e707ff269b484eb37c3a9d466b7903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/NVIDIA/dllogger /tmp/pip-install-usu5pi_7/dllogger_95e707ff269b484eb37c3a9d466b7903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Resolved https://github.com/NVIDIA/dllogger to commit 0540a43971f4a8a16693a9de9de73c1072020769\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: dllogger\n",
      "  Building wheel for dllogger (setup.py): started\n",
      "  Building wheel for dllogger (setup.py): finished with status 'done'\n",
      "  Created wheel for dllogger: filename=DLLogger-1.0.0-py3-none-any.whl size=5670 sha256=131d96013a5ae501cdae3e8e8c83c3d82ffb987f76e1f0e86530085b7dda0d9c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-l63ryb44/wheels/a8/c5/92/8f746e8bdf74b42fb8ac27010b5a78abefe56ad1964594ae95\n",
      "Successfully built dllogger\n",
      "Installing collected packages: dllogger\n",
      "Successfully installed dllogger-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/mlperf/logging.git@1.0.0\n",
      "  Cloning https://github.com/mlperf/logging.git (to revision 1.0.0) to /tmp/pip-req-build-a11yoev1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/mlperf/logging.git /tmp/pip-req-build-a11yoev1\n",
      "  Running command git checkout -q 982b15a62604491f23b7afdfacda57829d174f36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Resolved https://github.com/mlperf/logging.git to commit 982b15a62604491f23b7afdfacda57829d174f36\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: mlperf-logging\n",
      "  Building wheel for mlperf-logging (setup.py): started\n",
      "  Building wheel for mlperf-logging (setup.py): finished with status 'done'\n",
      "  Created wheel for mlperf-logging: filename=mlperf_logging-1.0.0-py3-none-any.whl size=74955 sha256=90105652c7b9b8b8505502242c53165f5cd920e1d9bbcee517184e887445c647\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yizbom7w/wheels/4f/2e/6b/3e15a32e71e45ac35f4085c8140095429f5567e5f1c4364f0e\n",
      "Successfully built mlperf-logging\n",
      "Installing collected packages: mlperf-logging\n",
      "Successfully installed mlperf-logging-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting unidecode\n",
      "  Using cached Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting inflect\n",
      "  Using cached inflect-6.0.2-py3-none-any.whl (34 kB)\n",
      "Collecting soundfile\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-any.whl (24 kB)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
      "     âââââââââââââââââââââââââââââââââââââ 253.0/253.0 kB 314.9 kB/s eta 0:00:00\n",
      "Collecting sox\n",
      "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "     ââââââââââââââââââââââââââââââââââââââââ 12.2/12.2 MB 8.5 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Using cached grpcio-1.51.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "     âââââââââââââââââââââââââââââââââââââ 233.6/233.6 kB 580.2 kB/s eta 0:00:00\n",
      "Collecting protobuf>=3.19.6\n",
      "  Using cached protobuf-4.22.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from tensorboard) (58.0.4)\n",
      "Collecting numpy>=1.12.0\n",
      "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "     ââââââââââââââââââââââââââââââââââââââââ 17.3/17.3 MB 10.1 MB/s eta 0:00:00\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from tensorboard) (0.37.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "     âââââââââââââââââââââââââââââââââââââââ 62.8/62.8 kB 276.2 kB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "Collecting pydantic>=1.9.1\n",
      "  Using cached pydantic-1.10.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from soundfile) (1.15.1)\n",
      "Collecting joblib>=0.14\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     âââââââââââââââââââââââââââââââââââââ 298.0/298.0 kB 495.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Using cached lazy_loader-0.1-py3-none-any.whl (8.6 kB)\n",
      "Collecting numba>=0.51.0\n",
      "  Using cached numba-0.56.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "Collecting pooch<1.7,>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "     ââââââââââââââââââââââââââââââââââââââââ 56.3/56.3 kB 13.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from librosa) (4.5.0)\n",
      "Collecting msgpack>=1.0\n",
      "  Using cached msgpack-1.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "Collecting scipy>=1.2.0\n",
      "  Downloading scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "     ââââââââââââââââââââââââââââââââââââââââ 34.5/34.5 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting scikit-learn>=0.20.0\n",
      "  Downloading scikit_learn-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "     ââââââââââââââââââââââââââââââââââââââââ 9.6/9.6 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting audioread>=2.1.9\n",
      "  Using cached audioread-3.0.0-py3-none-any.whl\n",
      "Collecting soxr>=0.3.2\n",
      "  Using cached soxr-0.3.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "     âââââââââââââââââââââââââââââââââââââ 499.4/499.4 kB 846.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pycparser in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard) (6.1.0)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Using cached llvmlite-0.39.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "Collecting numpy>=1.12.0\n",
      "  Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "     ââââââââââââââââââââââââââââââââââââââââ 17.1/17.1 MB 4.7 MB/s eta 0:00:00\n",
      "Collecting appdirs>=1.3.0\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from pooch<1.7,>=1.0->librosa) (23.0)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "     ââââââââââââââââââââââââââââââââââââââ 140.9/140.9 kB 27.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.6.15)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "     âââââââââââââââââââââââââââââââââââââ 199.2/199.2 kB 955.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.15.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, sentencepiece, pytz, pyasn1, msgpack, appdirs, werkzeug, urllib3, unidecode, threadpoolctl, tensorboard-data-server, rsa, pydantic, pyasn1-modules, protobuf, oauthlib, numpy, llvmlite, lazy-loader, joblib, grpcio, charset-normalizer, cachetools, audioread, absl-py, soxr, sox, soundfile, scipy, requests, pandas, numba, markdown, inflect, google-auth, scikit-learn, requests-oauthlib, pooch, librosa, google-auth-oauthlib, tensorboard\n",
      "Successfully installed absl-py-1.4.0 appdirs-1.4.4 audioread-3.0.0 cachetools-5.3.0 charset-normalizer-3.1.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 grpcio-1.51.3 inflect-6.0.2 joblib-1.2.0 lazy-loader-0.1 librosa-0.10.0.post2 llvmlite-0.39.1 markdown-3.4.1 msgpack-1.0.5 numba-0.56.4 numpy-1.23.5 oauthlib-3.2.2 pandas-1.5.3 pooch-1.6.0 protobuf-4.22.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pydantic-1.10.6 pytz-2022.7.1 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 scikit-learn-1.2.2 scipy-1.10.1 sentencepiece-0.1.97 soundfile-0.12.1 sox-1.4.1 soxr-0.3.4 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 threadpoolctl-3.1.0 unidecode-1.3.6 urllib3-1.26.15 werkzeug-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Cloning into 'warp-transducer'...\n",
      "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:4 (cmake_minimum_required):\n",
      "  Compatibility with CMake < 2.8.12 will be removed from a future version of\n",
      "  CMake.\n",
      "\n",
      "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
      "  CMake that the project does not need compatibility with older versions.\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 7.5.0\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0mCUDA_TOOLKIT_ROOT_DIR not found or specified\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Could NOT find CUDA (missing: CUDA_TOOLKIT_ROOT_DIR CUDA_NVCC_EXECUTABLE CUDA_INCLUDE_DIRS CUDA_CUDART_LIBRARY) \n",
      "-- cuda found FALSE\n",
      "-- Building shared library with no GPU support\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/vmagent/app/e2eaiok/demo/builtin/rnnt/warp-transducer/build\n",
      "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/warprnnt.dir/src/rnnt_entrypoint.cpp.o\u001b[0m\n",
      "[ 25%] \u001b[32m\u001b[1mLinking CXX shared library libwarprnnt.so\u001b[0m\n",
      "[ 25%] Built target warprnnt\n",
      "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/test_cpu.dir/tests/test_cpu.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/test_cpu.dir/tests/random.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32m\u001b[1mLinking CXX executable test_cpu\u001b[0m\n",
      "[ 62%] Built target test_cpu\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/test_time.dir/tests/test_time.cpp.o\u001b[0m\n",
      "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/test_time.dir/tests/random.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable test_time\u001b[0m\n",
      "[100%] Built target test_time\n",
      "Torch was not built with CUDA support, not building GPU extensions.\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating warprnnt_pytorch.egg-info\n",
      "writing warprnnt_pytorch.egg-info/PKG-INFO\n",
      "writing dependency_links to warprnnt_pytorch.egg-info/dependency_links.txt\n",
      "writing top-level names to warprnnt_pytorch.egg-info/top_level.txt\n",
      "writing manifest file 'warprnnt_pytorch.egg-info/SOURCES.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/utils/cpp_extension.py:411: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading manifest file 'warprnnt_pytorch.egg-info/SOURCES.txt'\n",
      "writing manifest file 'warprnnt_pytorch.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib.linux-x86_64-3.9\n",
      "creating build/lib.linux-x86_64-3.9/warprnnt_pytorch\n",
      "copying warprnnt_pytorch/__init__.py -> build/lib.linux-x86_64-3.9/warprnnt_pytorch\n",
      "running build_ext\n",
      "building 'warprnnt_pytorch.warp_rnnt' extension\n",
      "creating build/temp.linux-x86_64-3.9\n",
      "creating build/temp.linux-x86_64-3.9/src\n",
      "gcc -pthread -B /opt/intel/oneapi/intelpython/latest/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -Wformat -Wformat-security -fstack-protector-all -D_FORTIFY_SOURCE=2 -fpic -fPIC -O2 -Wl,-z,noexecstack,-z,relro,-z,now,-rpath,$ORIGIN/../..,-rpath,$ORIGIN/../../.. -I/opt/intel/oneapi/intelpython/latest/envs/pytorch/include -Wformat -Wformat-security -fstack-protector-all -D_FORTIFY_SOURCE=2 -fpic -fPIC -O2 -Wl,-z,noexecstack,-z,relro,-z,now,-rpath,$ORIGIN/../..,-rpath,$ORIGIN/../../.. -fPIC -I/home/vmagent/app/e2eaiok/demo/builtin/rnnt/warp-transducer/include -I/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include -I/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/TH -I/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/THC -I/opt/intel/oneapi/intelpython/latest/envs/pytorch/include/python3.9 -c src/binding.cpp -o build/temp.linux-x86_64-3.9/src/binding.o -fPIC -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=warp_rnnt -D_GLIBCXX_USE_CXX11_ABI=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src/binding.cpp: In function âint cpu_rnnt(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int)â:\n",
      "src/binding.cpp:46:23: warning: âat::DeprecatedTypeProperties& at::Tensor::type() constâ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     switch (acts.type().scalarType()) {\n",
      "                       ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:213:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "src/binding.cpp:53:44: warning: âT* at::Tensor::data() const [with T = float]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "         compute_rnnt_loss(acts.data<float>(), grads.data<float>(),\n",
      "                                            ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "src/binding.cpp:53:65: warning: âT* at::Tensor::data() const [with T = float]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "         compute_rnnt_loss(acts.data<float>(), grads.data<float>(),\n",
      "                                                                 ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "src/binding.cpp:54:43: warning: âT* at::Tensor::data() const [with T = int]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "                          labels.data<int>(), label_lengths.data<int>(),\n",
      "                                           ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "src/binding.cpp:54:70: warning: âT* at::Tensor::data() const [with T = int]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "                          labels.data<int>(), label_lengths.data<int>(),\n",
      "                                                                      ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "src/binding.cpp:55:50: warning: âT* at::Tensor::data() const [with T = int]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "                          input_lengths.data<int>(), alphabet_size,\n",
      "                                                  ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "src/binding.cpp:56:60: warning: âT* at::Tensor::data() const [with T = float]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "                          minibatch_size, costs.data<float>(),\n",
      "                                                            ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "src/binding.cpp:69:50: warning: âT* at::Tensor::data() const [with T = double]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "         compute_rnnt_loss_fp64(acts.data<double>(), grads.data<double>(),\n",
      "                                                  ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "src/binding.cpp:69:72: warning: âT* at::Tensor::data() const [with T = double]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "         compute_rnnt_loss_fp64(acts.data<double>(), grads.data<double>(),\n",
      "                                                                        ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "src/binding.cpp:70:43: warning: âT* at::Tensor::data() const [with T = int]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "                          labels.data<int>(), label_lengths.data<int>(),\n",
      "                                           ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "src/binding.cpp:70:70: warning: âT* at::Tensor::data() const [with T = int]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "                          labels.data<int>(), label_lengths.data<int>(),\n",
      "                                                                      ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "src/binding.cpp:71:50: warning: âT* at::Tensor::data() const [with T = int]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "                          input_lengths.data<int>(), alphabet_size,\n",
      "                                                  ^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "src/binding.cpp:72:61: warning: âT* at::Tensor::data() const [with T = double]â is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "                          minibatch_size, costs.data<double>(),\n",
      "                                                             ^\n",
      "In file included from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from src/binding.cpp:4:\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:235:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g++ -pthread -B /opt/intel/oneapi/intelpython/latest/envs/pytorch/compiler_compat -shared -L/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib -Wl,-z,noexecstack,-z,relro,-z,now,-rpath,$ORIGIN/../..,-rpath,$ORIGIN/../../.. -L/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib -L/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib -Wl,-z,noexecstack,-z,relro,-z,now,-rpath,$ORIGIN/../..,-rpath,$ORIGIN/../../.. build/temp.linux-x86_64-3.9/src/binding.o -L/home/vmagent/app/e2eaiok/demo/builtin/rnnt/warp-transducer/build -L/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/lib -lwarprnnt -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/warprnnt_pytorch/warp_rnnt.cpython-39-x86_64-linux-gnu.so -Wl,-rpath,/home/vmagent/app/e2eaiok/demo/builtin/rnnt/warp-transducer/build\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: warning: /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010001\n",
      "/usr/bin/ld: warning: /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010002\n",
      "/usr/bin/ld: warning: /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010001\n",
      "/usr/bin/ld: warning: /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/warprnnt_pytorch\n",
      "copying build/lib.linux-x86_64-3.9/warprnnt_pytorch/__init__.py -> build/bdist.linux-x86_64/egg/warprnnt_pytorch\n",
      "copying build/lib.linux-x86_64-3.9/warprnnt_pytorch/warp_rnnt.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/warprnnt_pytorch\n",
      "byte-compiling build/bdist.linux-x86_64/egg/warprnnt_pytorch/__init__.py to __init__.cpython-39.pyc\n",
      "creating stub loader for warprnnt_pytorch/warp_rnnt.cpython-39-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/warprnnt_pytorch/warp_rnnt.py to warp_rnnt.cpython-39.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying warprnnt_pytorch.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying warprnnt_pytorch.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying warprnnt_pytorch.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying warprnnt_pytorch.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "zip_safe flag not set; analyzing archive contents...\n",
      "warprnnt_pytorch.__pycache__.warp_rnnt.cpython-39: module references __file__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating dist\n",
      "creating 'dist/warprnnt_pytorch-0.1-py3.9-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing warprnnt_pytorch-0.1-py3.9-linux-x86_64.egg\n",
      "creating /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages/warprnnt_pytorch-0.1-py3.9-linux-x86_64.egg\n",
      "Extracting warprnnt_pytorch-0.1-py3.9-linux-x86_64.egg to /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages\n",
      "Adding warprnnt-pytorch 0.1 to easy-install.pth file\n",
      "\n",
      "Installed /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages/warprnnt_pytorch-0.1-py3.9-linux-x86_64.egg\n",
      "Processing dependencies for warprnnt-pytorch==0.1\n",
      "Finished processing dependencies for warprnnt-pytorch==0.1\n",
      "Collecting e2eAIOK-sda\n",
      "  Downloading e2eAIOK_sda-1.0.1b2023031702-py3-none-any.whl (91 kB)\n",
      "     âââââââââââââââââââââââââââââââââââââââ 91.7/91.7 kB 214.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from e2eAIOK-sda) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from e2eAIOK-sda) (1.2.2)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.4-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
      "     âââââââââââââââââââââââââââââââââââââââ 193.6/193.6 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting sigopt\n",
      "  Downloading sigopt-8.7.0-py2.py3-none-any.whl (211 kB)\n",
      "     âââââââââââââââââââââââââââââââââââââ 211.3/211.3 kB 538.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from scikit-learn->e2eAIOK-sda) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from scikit-learn->e2eAIOK-sda) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from scikit-learn->e2eAIOK-sda) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from scikit-learn->e2eAIOK-sda) (1.10.1)\n",
      "Collecting backoff<2.0.0,>=1.10.0\n",
      "  Downloading backoff-1.11.1-py2.py3-none-any.whl (13 kB)\n",
      "Collecting PyYAML<6.0.0,>=5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
      "     âââââââââââââââââââââââââââââââââââââââ 630.1/630.1 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting click>=8.0.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ââââââââââââââââââââââââââââââââââââââââ 96.6/96.6 kB 21.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.5 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from sigopt->e2eAIOK-sda) (1.26.15)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from sigopt->e2eAIOK-sda) (23.0)\n",
      "Collecting GitPython>=2.0.0\n",
      "  Using cached GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "Collecting pypng>=0.0.20\n",
      "  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
      "     ââââââââââââââââââââââââââââââââââââââââ 58.1/58.1 kB 14.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from sigopt->e2eAIOK-sda) (2.28.2)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from requests<3.0.0,>=2.25.0->sigopt->e2eAIOK-sda) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from requests<3.0.0,>=2.25.0->sigopt->e2eAIOK-sda) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/envs/pytorch/lib/python3.9/site-packages (from requests<3.0.0,>=2.25.0->sigopt->e2eAIOK-sda) (3.1.0)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pypng, smmap, PyYAML, click, backoff, xgboost, gitdb, GitPython, sigopt, e2eAIOK-sda\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "Successfully installed GitPython-3.1.31 PyYAML-5.4.1 backoff-1.11.1 click-8.1.3 e2eAIOK-sda-1.0.1b2023031702 gitdb-4.0.10 pypng-0.20220715.0 sigopt-8.7.0 smmap-5.0.0 xgboost-1.7.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "numactl is already the newest version (2.0.11-2.1ubuntu0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install torchaudio==0.12.1 torch==1.12.1 --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "pip install oneccl_bind_pt==1.12.100 intel-extension-for-pytorch==1.12.100 -f https://developer.intel.com/ipex-whl-stable\n",
    "pip install --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-cuda110==1.9.0\n",
    "pip install git+https://github.com/NVIDIA/dllogger#egg=dllogger\n",
    "pip install \"git+https://github.com/mlperf/logging.git@1.0.0\"\n",
    "pip install sentencepiece unidecode tensorboard inflect soundfile librosa sox pandas\n",
    "git clone https://github.com/HawkAaron/warp-transducer && cd warp-transducer \\\n",
    "    && mkdir build && cd build \\\n",
    "    && cmake .. && make && cd ../pytorch_binding \\\n",
    "    && python setup.py install\n",
    "pip install e2eAIOK-sda --pre\n",
    "apt install -y numactl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Prepare\n",
    "\n",
    "``` bash\n",
    "# prepare model codes\n",
    "cd /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch\n",
    "bash patch_rnnt.sh\n",
    "\n",
    "# Download Dataset\n",
    "# Download and unzip dataset from https://www.openslr.org/12 to /home/vmagent/app/dataset/LibriSpeech\n",
    "\n",
    "# Generate tokenizer and tokenize text\n",
    "cd /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch\n",
    "bash scripts/preprocess_librispeech.sh\n",
    "```\n",
    "\n",
    "Notes: RNN-T training is based on LibriSpeech train-clean-100 and evaluated on dev-clean, we evaluated WER with stock model (based on MLPerf submission) at train-clean-100 dataset, and final WER is 0.25, all the following optimization guarantee 0.25 WER. MLPerf submission took 38.7min with 8x A100 on LibriSpeech train-960h dataset.\n",
    "\n",
    "public reference on train-clean-100: https://arxiv.org/pdf/1807.10893.pdf, https://arxiv.org/pdf/1811.00787.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edit conf/e2eaiok_defaults_rnnt_example.conf\n",
    "\n",
    "```\n",
    "### GLOBAL SETTINGS ###\n",
    "observation_budget: 1\n",
    "save_path: /home/vmagent/app/e2eaiok/result/\n",
    "ppn: 2\n",
    "train_batch_size: 8\n",
    "eval_batch_size: 8\n",
    "iface: lo\n",
    "hosts:\n",
    "- localhost\n",
    "epochs: 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 02:41:47,824 - E2EAIOK - INFO - Above info is history record of this model\n",
      "2023-03-20 02:41:47,824 - E2EAIOK.SDA - INFO - ### Ready to submit current task  ###\n",
      "2023-03-20 02:41:47,825 - E2EAIOK.SDA - INFO - Model Advisor created\n",
      "2023-03-20 02:41:47,825 - E2EAIOK.SDA - INFO - model parameter initialized\n",
      "2023-03-20 02:41:47,825 - E2EAIOK.SDA - INFO - start to launch training\n",
      "2023-03-20 02:41:47,825 - sigopt - INFO - training launch command: /opt/intel/oneapi/intelpython/latest/envs/pytorch/bin/python -m intel_extension_for_pytorch.cpu.launch --distributed --nproc_per_node=2 --nnodes=1 --hostfile hosts /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py --output_dir /home/vmagent/app/e2eaiok/result/357dc3f8a3dfe894b3a3fcdd15fd1129f95f71cf887c8475679b1ff5b50674d8 --dist --dist_backend gloo --batch_size 8 --val_batch_size 8 --lr 0.007 --warmup_epochs 6 --beta1 0.9 --beta2 0.999 --max_duration 16.7 --target 0.25 --min_lr 1e-05 --lr_exp_gamma 0.939 --epochs 2 --epochs_this_job 0 --ema 0.999 --model_config modelzoo/rnnt/pytorch/configs/baseline_v3-1023sp.yaml --train_dataset_dir /home/vmagent/app/dataset/LibriSpeech/train --valid_dataset_dir /home/vmagent/app/dataset/LibriSpeech/valid --dali_device cpu --weight_decay 0.001 --grad_accumulation_steps 1 --weights_init_scale 0.5 --seed 2021 --train_manifests /home/vmagent/app/dataset/LibriSpeech/metadata/train-test.json --val_manifests /home/vmagent/app/dataset/LibriSpeech/metadata/dev-test.json --vectorized_sa --vectorized_sampler --multilayer_lstm --enable_prefetch --tokenized_transcript --dist_sampler --pre_sort_for_seq_split --jit_tensor_formation --max_symbol_per_sample 300 --data_cpu_threads 4 --min_seq_split_len 20 --log_frequency 1 --val_frequency 1 --prediction_frequency 1000000 --training_time_threshold 43200 --enc_n_hid 1024 --enc_pre_rnn_layers 2 --enc_stack_time_factor 8 --enc_post_rnn_layers 2 --pred_n_hid 512 --joint_n_hid 512 --fuse_relu_dropout --multi_tensor_ema --apex_transducer_loss fp16 --apex_transducer_joint pack             --buffer_pre_alloc --ema_update_type fp16 --apex_mlp --save_at_the_end \n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/runpy.py:127: RuntimeWarning: 'intel_extension_for_pytorch.cpu.launch' found in sys.modules after import of package 'intel_extension_for_pytorch.cpu', but prior to execution of 'intel_extension_for_pytorch.cpu.launch'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2023-03-20 02:41:48,717 - __main__ - INFO - MASTER_ADDR=127.0.0.1\n",
      "2023-03-20 02:41:48,718 - __main__ - INFO - MASTER_PORT=29500\n",
      "2023-03-20 02:41:48,718 - __main__ - INFO - I_MPI_PIN_DOMAIN=[0x3fff0,0xfffc00000,]\n",
      "2023-03-20 02:41:48,719 - __main__ - WARNING - Neither TCMalloc nor JeMalloc is found in $CONDA_PREFIX/lib or $VIRTUAL_ENV/lib or /.local/lib/ or /usr/local/lib/ or /usr/local/lib64/ or /usr/lib or /usr/lib64 or /root/.local/lib/ so the LD_PRELOAD environment variable will not be set. This may drop the performance\n",
      "2023-03-20 02:41:48,719 - __main__ - INFO - OMP_NUM_THREADS=14\n",
      "2023-03-20 02:41:48,719 - __main__ - WARNING - Unable to find the iomp library file libiomp5.so in $CONDA_PREFIX/lib or $VIRTUAL_ENV/lib or /.local/lib/ or /usr/local/lib/ or /usr/local/lib64/ or /usr/lib or /usr/lib64 or /root/.local/lib/ so the LD_PRELOAD environment variable will not be set.you can use 'conda install intel-openm' to install intel openMP\n",
      "2023-03-20 02:41:48,719 - __main__ - INFO - CCL_WORKER_COUNT=4\n",
      "2023-03-20 02:41:48,719 - __main__ - INFO - CCL_WORKER_AFFINITY=0,1,2,3,18,19,20,21\n",
      "2023-03-20 02:41:48,719 - __main__ - INFO - mpiexec.hydra -l -np 2 -ppn 2 -genv I_MPI_PIN_DOMAIN=[0x3fff0,0xfffc00000,] -genv OMP_NUM_THREADS=14 /opt/intel/oneapi/intelpython/latest/envs/pytorch/bin/python -u /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py --output_dir /home/vmagent/app/e2eaiok/result/357dc3f8a3dfe894b3a3fcdd15fd1129f95f71cf887c8475679b1ff5b50674d8 --dist --dist_backend gloo --batch_size 8 --val_batch_size 8 --lr 0.007 --warmup_epochs 6 --beta1 0.9 --beta2 0.999 --max_duration 16.7 --target 0.25 --min_lr 1e-05 --lr_exp_gamma 0.939 --epochs 2 --epochs_this_job 0 --ema 0.999 --model_config modelzoo/rnnt/pytorch/configs/baseline_v3-1023sp.yaml --train_dataset_dir /home/vmagent/app/dataset/LibriSpeech/train --valid_dataset_dir /home/vmagent/app/dataset/LibriSpeech/valid --dali_device cpu --weight_decay 0.001 --grad_accumulation_steps 1 --weights_init_scale 0.5 --seed 2021 --train_manifests /home/vmagent/app/dataset/LibriSpeech/metadata/train-test.json --val_manifests /home/vmagent/app/dataset/LibriSpeech/metadata/dev-test.json --vectorized_sa --vectorized_sampler --multilayer_lstm --enable_prefetch --tokenized_transcript --dist_sampler --pre_sort_for_seq_split --jit_tensor_formation --max_symbol_per_sample 300 --data_cpu_threads 4 --min_seq_split_len 20 --log_frequency 1 --val_frequency 1 --prediction_frequency 1000000 --training_time_threshold 43200 --enc_n_hid 1024 --enc_pre_rnn_layers 2 --enc_stack_time_factor 8 --enc_post_rnn_layers 2 --pred_n_hid 512 --joint_n_hid 512 --fuse_relu_dropout --multi_tensor_ema --apex_transducer_loss fp16 --apex_transducer_joint pack --buffer_pre_alloc --ema_update_type fp16 --apex_mlp --save_at_the_end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] No module named 'torch_ccl'\n",
      "[1] No module named 'torch_ccl'\n",
      "[0] world_size:2,rank:0\n",
      "[1] world_size:2,rank:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] 2023-03-20 02:41:49,890 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "[1] 2023-03-20 02:41:49,890 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "[0] 2023-03-20 02:41:49,890 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[1] 2023-03-20 02:41:49,890 - torch.distributed.distributed_c10d - INFO - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280109904, \"event_type\": \"INTERVAL_START\", \"key\": \"init_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 357}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110003, \"event_type\": \"POINT_IN_TIME\", \"key\": \"seed\", \"value\": 2021, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 362}}\n",
      "[0] DLL 2023-03-20 02:41:50.006883 - PARAMETER | epochs :  2\n",
      "[0] DLL 2023-03-20 02:41:50.006950 - PARAMETER | warmup_epochs :  6\n",
      "[0] DLL 2023-03-20 02:41:50.007040 - PARAMETER | hold_epochs :  40\n",
      "[0] DLL 2023-03-20 02:41:50.007164 - PARAMETER | epochs_this_job :  0\n",
      "[0] DLL 2023-03-20 02:41:50.007195 - PARAMETER | cudnn_benchmark :  True\n",
      "[0] DLL 2023-03-20 02:41:50.007238 - PARAMETER | amp_level :  1\n",
      "[0] DLL 2023-03-20 02:41:50.007282 - PARAMETER | seed :  2021\n",
      "[0] DLL 2023-03-20 02:41:50.007326 - PARAMETER | local_rank :  0\n",
      "[0] DLL 2023-03-20 02:41:50.007371 - PARAMETER | target :  0.25\n",
      "[0] DLL 2023-03-20 02:41:50.007428 - PARAMETER | apex_transducer_loss :  fp16\n",
      "[0] DLL 2023-03-20 02:41:50.007476 - PARAMETER | fuse_relu_dropout :  True\n",
      "[0] DLL 2023-03-20 02:41:50.007509 - PARAMETER | weights_init_scale :  0.5\n",
      "[0] DLL 2023-03-20 02:41:50.007641 - PARAMETER | hidden_hidden_bias_scale : \n",
      "[0] DLL 2023-03-20 02:41:50.007683 - PARAMETER | batch_eval_mode : \n",
      "[0] DLL 2023-03-20 02:41:50.007714 - PARAMETER | cg_unroll_factor :  4\n",
      "[0] DLL 2023-03-20 02:41:50.007736 - PARAMETER | apex_transducer_joint :  pack\n",
      "[0] DLL 2023-03-20 02:41:50.007772 - PARAMETER | buffer_pre_alloc :  True\n",
      "[0] DLL 2023-03-20 02:41:50.007816 - PARAMETER | multilayer_lstm :  True\n",
      "[0] DLL 2023-03-20 02:41:50.007866 - PARAMETER | batch_split_factor :  1\n",
      "[0] DLL 2023-03-20 02:41:50.007895 - PARAMETER | apex_mlp :  True\n",
      "[0] DLL 2023-03-20 02:41:50.007918 - PARAMETER | num_cg :  0\n",
      "[0] DLL 2023-03-20 02:41:50.007971 - PARAMETER | min_seq_split_len :  20\n",
      "[0] DLL 2023-03-20 02:41:50.008015 - PARAMETER | pre_sort_for_seq_split :  True\n",
      "[0] DLL 2023-03-20 02:41:50.008086 - PARAMETER | dist :  True\n",
      "[0] DLL 2023-03-20 02:41:50.008116 - PARAMETER | dist_backend :  gloo\n",
      "[0] DLL 2023-03-20 02:41:50.008136 - PARAMETER | use_ipex :  False\n",
      "[0] DLL 2023-03-20 02:41:50.008155 - PARAMETER | batch_size :  8\n",
      "[0] DLL 2023-03-20 02:41:50.008177 - PARAMETER | val_batch_size :  8\n",
      "[0] DLL 2023-03-20 02:41:50.008229 - PARAMETER | lr :  0.007\n",
      "[0] DLL 2023-03-20 02:41:50.008251 - PARAMETER | min_lr :  1e-05\n",
      "[0] DLL 2023-03-20 02:41:50.008275 - PARAMETER | lr_exp_gamma :  0.939\n",
      "[0] DLL 2023-03-20 02:41:50.008367 - PARAMETER | weight_decay :  0.001\n",
      "[0] DLL 2023-03-20 02:41:50.008388 - PARAMETER | grad_accumulation_steps :  1\n",
      "[0] DLL 2023-03-20 02:41:50.008408 - PARAMETER | clip_norm :  1\n",
      "[0] DLL 2023-03-20 02:41:50.008429 - PARAMETER | beta1 :  0.9\n",
      "[0] DLL 2023-03-20 02:41:50.008459 - PARAMETER | beta2 :  0.999\n",
      "[0] DLL 2023-03-20 02:41:50.008482 - PARAMETER | ema :  0.999\n",
      "[0] DLL 2023-03-20 02:41:50.008501 - PARAMETER | multi_tensor_ema :  True\n",
      "[0] DLL 2023-03-20 02:41:50.008519 - PARAMETER | dist_lamb :  False\n",
      "[0] DLL 2023-03-20 02:41:50.008547 - PARAMETER | ema_update_type :  fp16\n",
      "[0] DLL 2023-03-20 02:41:50.008568 - PARAMETER | dwu_group_size :  8\n",
      "[0] DLL 2023-03-20 02:41:50.008589 - PARAMETER | dali_device :  cpu\n",
      "[0] DLL 2023-03-20 02:41:50.008608 - PARAMETER | resume :  False\n",
      "[0] DLL 2023-03-20 02:41:50.008636 - PARAMETER | ckpt : \n",
      "[0] DLL 2023-03-20 02:41:50.008656 - PARAMETER | save_at_the_end :  True\n",
      "[0] DLL 2023-03-20 02:41:50.008676 - PARAMETER | save_frequency : \n",
      "[0] DLL 2023-03-20 02:41:50.008699 - PARAMETER | keep_milestones :  []\n",
      "[0] DLL 2023-03-20 02:41:50.008730 - PARAMETER | save_best_from :  200\n",
      "[0] DLL 2023-03-20 02:41:50.008750 - PARAMETER | val_frequency :  1\n",
      "[0] DLL 2023-03-20 02:41:50.008771 - PARAMETER | log_frequency :  1\n",
      "[0] DLL 2023-03-20 02:41:50.008790 - PARAMETER | prediction_frequency :  1000000\n",
      "[0] DLL 2023-03-20 02:41:50.008819 - PARAMETER | model_config :  modelzoo/rnnt/pytorch/configs/baseline_v3-1023sp.yaml\n",
      "[0] DLL 2023-03-20 02:41:50.008840 - PARAMETER | num_buckets :  6\n",
      "[0] DLL 2023-03-20 02:41:50.008871 - PARAMETER | vectorized_sampler :  True\n",
      "[0] DLL 2023-03-20 02:41:50.008891 - PARAMETER | dist_sampler :  True\n",
      "[0] DLL 2023-03-20 02:41:50.008919 - PARAMETER | train_manifests :  ['/home/vmagent/app/dataset/LibriSpeech/metadata/train-test.json']\n",
      "[0] DLL 2023-03-20 02:41:50.008946 - PARAMETER | val_manifests :  ['/home/vmagent/app/dataset/LibriSpeech/metadata/dev-test.json']\n",
      "[0] DLL 2023-03-20 02:41:50.008969 - PARAMETER | max_duration :  16.7\n",
      "[0] DLL 2023-03-20 02:41:50.008997 - PARAMETER | max_txt_len :  125\n",
      "[0] DLL 2023-03-20 02:41:50.009017 - PARAMETER | max_eval_sample_duration :  32.7\n",
      "[0] DLL 2023-03-20 02:41:50.009044 - PARAMETER | train_dataset_dir :  /home/vmagent/app/dataset/LibriSpeech/train\n",
      "[0] DLL 2023-03-20 02:41:50.009076 - PARAMETER | valid_dataset_dir :  /home/vmagent/app/dataset/LibriSpeech/valid\n",
      "[0] DLL 2023-03-20 02:41:50.009096 - PARAMETER | output_dir :  /home/vmagent/app/e2eaiok/result/357dc3f8a3dfe894b3a3fcdd15fd1129f95f71cf887c8475679b1ff5b50674d8\n",
      "[0] DLL 2023-03-20 02:41:50.009129 - PARAMETER | log_file : \n",
      "[0] DLL 2023-03-20 02:41:50.009161 - PARAMETER | max_symbol_per_sample :  300\n",
      "[0] DLL 2023-03-20 02:41:50.009183 - PARAMETER | data_cpu_threads :  4\n",
      "[0] DLL 2023-03-20 02:41:50.009204 - PARAMETER | synthetic_audio_seq_len : \n",
      "[0] DLL 2023-03-20 02:41:50.009223 - PARAMETER | synthetic_text_seq_len : \n",
      "[0] DLL 2023-03-20 02:41:50.009253 - PARAMETER | enable_seq_len_stats :  False\n",
      "[0] DLL 2023-03-20 02:41:50.009273 - PARAMETER | vectorized_sa :  True\n",
      "[0] DLL 2023-03-20 02:41:50.009295 - PARAMETER | in_mem_file_list :  False\n",
      "[0] DLL 2023-03-20 02:41:50.009313 - PARAMETER | enable_prefetch :  True\n",
      "[0] DLL 2023-03-20 02:41:50.009356 - PARAMETER | tokenized_transcript :  True\n",
      "[0] DLL 2023-03-20 02:41:50.009376 - PARAMETER | jit_tensor_formation :  True\n",
      "[0] DLL 2023-03-20 02:41:50.009395 - PARAMETER | dali_dont_use_mmap :  False\n",
      "[0] DLL 2023-03-20 02:41:50.009423 - PARAMETER | training_time_threshold :  43200\n",
      "[0] DLL 2023-03-20 02:41:50.009443 - PARAMETER | enc_n_hid :  1024\n",
      "[0] DLL 2023-03-20 02:41:50.009463 - PARAMETER | enc_pre_rnn_layers :  2\n",
      "[0] DLL 2023-03-20 02:41:50.009481 - PARAMETER | enc_stack_time_factor :  8\n",
      "[0] DLL 2023-03-20 02:41:50.009510 - PARAMETER | enc_post_rnn_layers :  2\n",
      "[0] DLL 2023-03-20 02:41:50.009531 - PARAMETER | enc_dropout :  0.1\n",
      "[0] DLL 2023-03-20 02:41:50.009551 - PARAMETER | pred_n_hid :  512\n",
      "[0] DLL 2023-03-20 02:41:50.009575 - PARAMETER | pred_rnn_layers :  2\n",
      "[0] DLL 2023-03-20 02:41:50.009603 - PARAMETER | pred_dropout :  0.3\n",
      "[0] DLL 2023-03-20 02:41:50.009624 - PARAMETER | joint_n_hid :  512\n",
      "[0] DLL 2023-03-20 02:41:50.009648 - PARAMETER | joint_dropout :  0.3\n",
      "[0] DLL 2023-03-20 02:41:50.009666 - PARAMETER | rnn_type :  lstm\n",
      "[0] DLL 2023-03-20 02:41:50.009694 - PARAMETER | normalization :  False\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110029, \"event_type\": \"POINT_IN_TIME\", \"key\": \"gradient_accumulation_steps\", \"value\": 1, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 380}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110029, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_benchmark\", \"value\": \"rnnt\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 386}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110029, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_org\", \"value\": \"Intel\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 387}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110029, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_division\", \"value\": \"closed\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 388}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110029, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_status\", \"value\": \"onprem\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 389}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110029, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_platform\", \"value\": \"CPU\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 390}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110031, \"event_type\": \"POINT_IN_TIME\", \"key\": \"model_weights_initialization_scale\", \"value\": 0.5, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 397}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110115, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/rnn.py\", \"lineno\": 89, \"tensor\": \"pre_rnn\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110371, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/rnn.py\", \"lineno\": 89, \"tensor\": \"post_rnn\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110375, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 159, \"tensor\": \"pred_embed\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110402, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/rnn.py\", \"lineno\": 89, \"tensor\": \"dec_rnn\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110405, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 181, \"tensor\": \"joint_pred\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110409, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 186, \"tensor\": \"joint_enc\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110413, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 195, \"tensor\": \"joint_net\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110413, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_max_prediction_symbols\", \"value\": 300, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 418}}\n",
      "[0] Model size: 65.8M params\n",
      "[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280110434, \"event_type\": \"POINT_IN_TIME\", \"key\": \"model_eval_ema_factor\", \"value\": 0.999, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 432}}\n",
      "[0] Starting with LRs: 0.007\n",
      "[0] DistributedDataParallel(\n",
      "[0]   (module): RNNT(\n",
      "[0]     (encoder): ModuleDict(\n",
      "[0]       (pre_rnn): LSTM(\n",
      "[0]         (lstm): LSTM(256, 1024, num_layers=2, dropout=0.1)\n",
      "[0]         (dropout): Dropout(p=0.1, inplace=False)\n",
      "[0]       )\n",
      "[0]       (stack_time): StackTime()\n",
      "[0]       (post_rnn): LSTM(\n",
      "[0]         (lstm): LSTM(8192, 1024, num_layers=2, dropout=0.1)\n",
      "[0]         (dropout): Dropout(p=0.1, inplace=False)\n",
      "[0]       )\n",
      "[0]     )\n",
      "[0]     (prediction): ModuleDict(\n",
      "[0]       (embed): Embedding(1023, 512)\n",
      "[0]       (dec_rnn): LSTM(\n",
      "[0]         (lstm): LSTM(512, 512, num_layers=2, dropout=0.3)\n",
      "[0]         (dropout): Dropout(p=0.3, inplace=False)\n",
      "[0]       )\n",
      "[0]     )\n",
      "[0]     (joint_pred): Linear(in_features=512, out_features=512, bias=True)\n",
      "[0]     (joint_enc): Linear(in_features=1024, out_features=512, bias=True)\n",
      "[0]     (joint_net): Sequential(\n",
      "[0]       (0): FusedReluDropout()\n",
      "[0]       (1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "[0]     )\n",
      "[0]   )\n",
      "[0] )\n",
      "[0] Setting up datasets...\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111010, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_train_max_duration\", \"value\": 16.7, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 472}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111011, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_speed_perturbaton_max\", \"value\": 1.15, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 474}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111011, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_speed_perturbaton_min\", \"value\": 0.85, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 476}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111011, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_freq_n\", \"value\": 2, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 478}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111011, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_freq_min\", \"value\": 0, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 480}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111011, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_freq_max\", \"value\": 20, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 482}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111011, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_time_n\", \"value\": 10, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 484}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111011, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_time_min\", \"value\": 0, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 486}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111012, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_time_max\", \"value\": 0.03, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 488}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111012, \"event_type\": \"POINT_IN_TIME\", \"key\": \"global_batch_size\", \"value\": 16, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 490}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111012, \"event_type\": \"INTERVAL_END\", \"key\": \"init_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 560}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111013, \"event_type\": \"INTERVAL_START\", \"key\": \"run_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 563}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111013, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_train_num_buckets\", \"value\": 6, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 569}}\n",
      "[0] Launching vectorized bucketing sampler\n",
      "[0] Launching simple sampler\n",
      "[0] Dataset read by DALI. Number of samples: 96\n",
      "[0] Initializing DALI with parameters:\n",
      "[0] \t           __class__ : <class 'common.data.dali.pipeline.DaliPipeline'>\n",
      "[0] \t          batch_size : 8\n",
      "[0] \t           device_id : None\n",
      "[0] \t        dither_coeff : 1e-05\n",
      "[0] \t       dont_use_mmap : False\n",
      "[0] \t           file_root : /home/vmagent/app/dataset/LibriSpeech/train\n",
      "[0] \t    in_mem_file_list : False\n",
      "[0] \t        max_duration : 16.7\n",
      "[0] \t           nfeatures : 80[0] \n",
      "[0] \t                nfft : 512\n",
      "[0] \t         num_threads : 4[0] \n",
      "[0] \t       pipeline_type : train\n",
      "[0] \t            pre_sort : True\n",
      "[0] \t       preemph_coeff : 0.97[0] \n",
      "[0] \tpreprocessing_device : cpu\n",
      "[0] \t      resample_range : [0.85, 1.15]\n",
      "[0] \t         sample_rate : 16000\n",
      "[0] \t             sampler : <common.data.dali.sampler.VectorizedBucketingSampler object at 0x7fd12130af40>\n",
      "[0] \t                seed : 2021[0] \n",
      "[0] \t                self : <common.data.dali.pipeline.DaliPipeline object at 0x7fd12130af70>[0] \n",
      "[0] \t   silence_threshold : -60\n",
      "[0] \t   synthetic_seq_len : None\n",
      "[0] \t         window_size : 0.02[0] \n",
      "[0] \t       window_stride : 0.01[0] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1] /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/nvidia/dali/plugin/base_iterator.py:163: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.\n",
      "[1]   _iterator_deprecation_warning()\n",
      "[0] /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/nvidia/dali/plugin/base_iterator.py:163: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.\n",
      "[0]   _iterator_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Dataset read by DALI. Number of samples: 73\n",
      "[0] Initializing DALI with parameters:\n",
      "[0] \t           __class__ : <class 'common.data.dali.pipeline.DaliPipeline'>\n",
      "[0] \t          batch_size : 8[0] \n",
      "[0] \t           device_id : None[0] \n",
      "[0] \t        dither_coeff : 1e-05\n",
      "[0] \t       dont_use_mmap : False\n",
      "[0] \t           file_root : /home/vmagent/app/dataset/LibriSpeech/valid\n",
      "[0] \t    in_mem_file_list : False[0] \n",
      "[0] \t        max_duration : inf[0] \n",
      "[0] \t           nfeatures : 80\n",
      "[0] \t                nfft : 512\n",
      "[0] \t         num_threads : 4\n",
      "[0] \t       pipeline_type : val[0] \n",
      "[0] \t            pre_sort : False\n",
      "[0] \t       preemph_coeff : 0.97\n",
      "[0] \tpreprocessing_device : cpu\n",
      "[0] \t      resample_range : None[0] \n",
      "[0] \t         sample_rate : 16000[0] \n",
      "[0] \t             sampler : <common.data.dali.sampler.SimpleSampler object at 0x7fd12130ad00>\n",
      "[0] \t                seed : 2021\n",
      "[0] \t                self : <common.data.dali.pipeline.DaliPipeline object at 0x7fd1213153d0>[0] \n",
      "[0] \t   silence_threshold : -60[0] \n",
      "[0] \t   synthetic_seq_len : None\n",
      "[0] \t         window_size : 0.02[0] \n",
      "[0] \t       window_stride : 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1] /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/profiler/profiler.py:231: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "[1]   warn(\"Profiler won't be using warmup, this can skew profiler results\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111170, \"event_type\": \"POINT_IN_TIME\", \"key\": \"train_samples\", \"value\": 96, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 651}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111170, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_samples\", \"value\": 73, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 652}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111171, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_name\", \"value\": \"lamb\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 654}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111171, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_base_learning_rate\", \"value\": 0.007, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 655}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111171, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_epsilon\", \"value\": 1e-09, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 656}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111171, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_learning_rate_decay_poly_power\", \"value\": 0.939, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 657}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111172, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_learning_rate_warmup_epochs\", \"value\": 6, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 658}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111172, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_learning_rate_hold_epochs\", \"value\": 40, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 659}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111172, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_beta_1\", \"value\": 0.9, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 660}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111172, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_beta_2\", \"value\": 0.999, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 661}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111172, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_gradient_clip_norm\", \"value\": 1, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 662}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111173, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_learning_rate_alt_decay_func\", \"value\": true, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 663}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111173, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_learning_rate_alt_warmup_func\", \"value\": true, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 664}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111173, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_learning_rate_min\", \"value\": 1e-05, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 665}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111173, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_weight_decay\", \"value\": 0.001, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 666}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111176, \"event_type\": \"INTERVAL_START\", \"key\": \"block_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 697, \"first_epoch_num\": 1, \"epoch_count\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280111176, \"event_type\": \"INTERVAL_START\", \"key\": \"epoch_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 700, \"epoch_num\": 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/profiler/profiler.py:231: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "[0]   warn(\"Profiler won't be using warmup, this can skew profiler results\")\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/features.py:201: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   x_lens = (x_lens.int() + stacking - 1) // stacking\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/features.py:201: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   x_lens = (x_lens.int() + stacking - 1) // stacking\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/dali/iterator.py:151: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   pivot_len = (audio_shape_sorted[self.split_batch_size] + stack_factor-1) // stack_factor * stack_factor\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/helpers.py:276: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   batch_offset = torch.cumsum(g_len * ((feat_lens+self.enc_stack_time_factor-1)//self.enc_stack_time_factor), dim=0)\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/dali/iterator.py:151: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   pivot_len = (audio_shape_sorted[self.split_batch_size] + stack_factor-1) // stack_factor * stack_factor\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/helpers.py:276: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   batch_offset = torch.cumsum(g_len * ((feat_lens+self.enc_stack_time_factor-1)//self.enc_stack_time_factor), dim=0)\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:64: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:64: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
      "[0] [W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[1] [W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] DLL 2023-03-20 02:41:55.755945 - epoch    1 | iter    1/6 | loss  958.22 | utts/s     4 | took  4.49 s | lrate 3.78e-04[0] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] [W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation\n",
      "[1] [W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation\n",
      "[1] [W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] DLL 2023-03-20 02:41:59.148334 - epoch    1 | iter    2/6 | loss  906.90 | utts/s     5 | took  3.39 s | lrate 5.68e-04[0] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] [W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] DLL 2023-03-20 02:42:02.231807 - epoch    1 | iter    3/6 | loss  801.17 | utts/s     5 | took  3.08 s | lrate 7.57e-04[0] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] [W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation\n",
      "[1] [W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] DLL 2023-03-20 02:42:04.772209 - epoch    1 | iter    4/6 | loss  535.04 | utts/s     6 | took  2.54 s | lrate 9.46e-04[0] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] [W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation\n",
      "[1] [W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] DLL 2023-03-20 02:42:08.976775 - epoch    1 | iter    5/6 | loss 1013.65 | utts/s     4 | took  4.20 s | lrate 1.14e-03[0] \n",
      "[0] DLL 2023-03-20 02:42:14.720571 - epoch    1 | iter    6/6 | loss  896.75 | utts/s     3 | took  5.74 s | lrate 1.32e-03[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280134720, \"event_type\": \"INTERVAL_END\", \"key\": \"epoch_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 786, \"epoch_num\": 1}}\n",
      "[0] DLL 2023-03-20 02:42:14.721592 - epoch    1 | avg train utts/s     4 | took 23.54 s\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280134721, \"event_type\": \"POINT_IN_TIME\", \"key\": \"throughput\", \"value\": 4.077337338816833, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 793}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280134721, \"event_type\": \"INTERVAL_START\", \"key\": \"eval_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 239, \"epoch_num\": 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:53: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:53: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280146604, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_accuracy\", \"value\": 20.484347826086957, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 260, \"epoch_num\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280146604, \"event_type\": \"INTERVAL_END\", \"key\": \"eval_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 261, \"epoch_num\": 1}}\n",
      "[0] DLL 2023-03-20 02:42:26.605304 - epoch    1 |   dev ema wer 2048.43 | took 11.88 s\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280146605, \"event_type\": \"INTERVAL_END\", \"key\": \"block_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 811, \"first_epoch_num\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280146605, \"event_type\": \"INTERVAL_START\", \"key\": \"block_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 697, \"first_epoch_num\": 2, \"epoch_count\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280146605, \"event_type\": \"INTERVAL_START\", \"key\": \"epoch_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 700, \"epoch_num\": 2}}\n",
      "[0] DLL 2023-03-20 02:42:31.493855 - epoch    2 | iter    1/6 | loss  962.37 | utts/s     3 | took  4.84 s | lrate 1.51e-03[0] \n",
      "[0] DLL 2023-03-20 02:44:17.617730 - epoch    2 | iter    2/6 | loss  512.79 | utts/s     0 | took 106.12 s | lrate 1.70e-03[0] \n",
      "[0] DLL 2023-03-20 02:44:20.919920 - epoch    2 | iter    3/6 | loss  841.06 | utts/s     5 | took  3.30 s | lrate 1.89e-03[0] \n",
      "[0] DLL 2023-03-20 02:44:24.541019 - epoch    2 | iter    4/6 | loss  894.31 | utts/s     4 | took  3.62 s | lrate 2.08e-03[0] \n",
      "[0] DLL 2023-03-20 02:44:28.652774 - epoch    2 | iter    5/6 | loss 1000.28 | utts/s     4 | took  4.11 s | lrate 2.27e-03[0] \n",
      "[0] DLL 2023-03-20 02:44:32.192334 - epoch    2 | iter    6/6 | loss  926.91 | utts/s     5 | took  3.54 s | lrate 2.46e-03[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280272192, \"event_type\": \"INTERVAL_END\", \"key\": \"epoch_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 786, \"epoch_num\": 2}}\n",
      "[0] DLL 2023-03-20 02:44:32.193076 - epoch    2 | avg train utts/s     1 | took 125.59 s\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280272193, \"event_type\": \"POINT_IN_TIME\", \"key\": \"throughput\", \"value\": 0.7644103239399725, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 793}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280272193, \"event_type\": \"INTERVAL_START\", \"key\": \"eval_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 239, \"epoch_num\": 2}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280281958, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_accuracy\", \"value\": 20.484347826086957, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 260, \"epoch_num\": 2}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280281959, \"event_type\": \"INTERVAL_END\", \"key\": \"eval_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 261, \"epoch_num\": 2}}\n",
      "[0] DLL 2023-03-20 02:44:41.959885 - epoch    2 |   dev ema wer 2048.43 | took  9.77 s[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280281960, \"event_type\": \"INTERVAL_END\", \"key\": \"block_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 811, \"first_epoch_num\": 2}}\n",
      "[0] -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "[0]                                                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "[0] -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "[0]                                             aten::addmm        17.33%        3.902s        20.67%        4.654s      60.637us         76753  \n",
      "[0]                                                aten::mm        16.34%        3.678s        16.35%        3.680s     594.962us          6186  \n",
      "[0]                                           ProfilerStep*        16.22%        3.652s       100.00%       22.516s       11.258s             2  \n",
      "[0]                                               aten::add        14.53%        3.272s        14.53%        3.272s     136.406us         23990  \n",
      "[0]                                             aten::copy_         4.00%     901.653ms         4.00%     901.653ms       8.932us        100946  \n",
      "[0]                                               aten::mul         3.54%     796.033ms         3.62%     816.077ms       7.450us        109536  \n",
      "[0]                                          aten::sigmoid_         3.21%     721.958ms         3.21%     721.958ms       7.947us         90852  \n",
      "[0]                                              aten::lstm         2.28%     514.019ms        35.32%        7.953s     683.842us         11630  \n",
      "[0]                                              aten::add_         2.25%     505.946ms         2.25%     505.946ms       8.316us         60838  \n",
      "[0]                                       fallback_function         1.86%     418.371ms         2.05%     461.570ms     230.785ms             2  \n",
      "[0]                                               aten::cat         1.58%     356.190ms         1.88%     424.286ms       8.551us         49616  \n",
      "[0]                                        aten::as_strided         0.91%     205.998ms         0.91%     205.998ms       0.405us        508552  \n",
      "[0]                                             aten::tanh_         0.86%     194.153ms         0.86%     194.153ms       6.411us         30284  \n",
      "[0]                                            aten::linear         0.84%     188.264ms        23.66%        5.328s      69.391us         76775  \n",
      "[0]                                              aten::view         0.80%     180.177ms         0.80%     180.177ms       1.169us        154182  \n",
      "[0]                                                 aten::t         0.74%     167.099ms         1.30%     291.961ms       3.276us         89119  \n",
      "[0]                                             aten::slice         0.74%     166.181ms         1.05%     236.458ms       1.312us        180218  \n",
      "[0]                                              aten::tanh         0.73%     164.936ms         0.73%     164.936ms       5.446us         30284  \n",
      "[0]                                         aten::transpose         0.58%     131.660ms         0.84%     190.162ms       1.692us        112396  \n",
      "[0]                                              aten::norm         0.54%     120.783ms         0.54%     120.958ms     643.394us           188  \n",
      "[0]                                               aten::max         0.50%     113.082ms         0.68%     154.164ms      13.268us         11619  \n",
      "[0]                                            aten::select         0.49%     110.049ms         0.66%     148.108ms       1.283us        115434  \n",
      "[0]                                      aten::unsafe_split         0.48%     108.762ms         1.38%     310.254ms      10.245us         30284  \n",
      "[0]                                             aten::empty         0.48%     107.491ms         0.48%     107.491ms       1.408us         76325  \n",
      "[0]                                            aten::unbind         0.45%     102.272ms         0.83%     186.542ms       4.007us         46558  \n",
      "[0]                                             aten::stack         0.43%      95.707ms         1.97%     443.626ms       9.530us         46550  \n",
      "[0]                                               aten::sum         0.42%      95.129ms         0.53%     119.711ms      38.666us          3096  \n",
      "[0]                                             aten::fill_         0.41%      92.601ms         0.41%      92.601ms       6.235us         14852  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]                                            aten::narrow         0.35%      79.656ms         1.00%     225.783ms       1.700us        132830  \n",
      "[0]                                               aten::div         0.32%      71.734ms         0.32%      72.809ms     271.675us           268  \n",
      "[0]                                            aten::expand         0.28%      62.077ms         0.40%      90.029ms       1.173us         76774  \n",
      "[0]                                  aten::sigmoid_backward         0.27%      61.088ms         0.27%      61.088ms       6.646us          9192  \n",
      "[0]                                   aten::constant_pad_nd         0.25%      57.246ms         0.84%     190.251ms      16.336us         11646  \n",
      "[0]     autograd::engine::evaluate_function: AddmmBackward0         0.24%      53.343ms        16.44%        3.702s       1.203ms          3078  \n",
      "[0]                                              aten::mul_         0.23%      52.620ms         0.26%      57.917ms     304.826us           190  \n",
      "[0]                                      aten::index_select         0.22%      50.024ms         0.27%      61.287ms       5.294us         11576  \n",
      "[0]                                         aten::embedding         0.22%      49.120ms         0.62%     139.482ms      12.049us         11576  \n",
      "[0]                                         aten::clamp_min         0.21%      47.012ms         0.21%      47.012ms       4.049us         11612  \n",
      "[0]       autograd::engine::evaluate_function: MulBackward0         0.20%      45.372ms         1.22%     274.235ms      29.769us          9212  \n",
      "[0]                                     aten::tanh_backward         0.20%      44.377ms         0.20%      44.377ms       7.242us          6128  \n",
      "[0]                                         aten::unsqueeze         0.17%      38.224ms         0.22%      49.151ms       2.072us         23723  \n",
      "[0]                                            MulBackward0         0.16%      36.172ms         1.02%     228.863ms      24.844us          9212  \n",
      "[0]                                          AddmmBackward0         0.16%      35.418ms        15.41%        3.469s       1.127ms          3078  \n",
      "[0]                                          aten::_to_copy         0.15%      34.800ms         0.51%     115.818ms       9.433us         12278  \n",
      "[0]                        aten::_log_softmax_backward_data         0.14%      32.193ms         0.14%      32.193ms      16.096ms             2  \n",
      "[0]                                      aten::_log_softmax         0.13%      29.717ms         0.13%      29.717ms      14.858ms             2  \n",
      "[0]                                      aten::unsafe_chunk         0.13%      29.699ms         1.51%     339.953ms      11.225us         30284  \n",
      "[0]       autograd::engine::evaluate_function: AddBackward0         0.12%      26.514ms         0.17%      38.769ms       6.312us          6142  \n",
      "[0]         autograd::engine::evaluate_function: TBackward0         0.11%      24.504ms        13.77%        3.099s       1.003ms          3090  \n",
      "[0]                                              aten::sqrt         0.11%      24.083ms         0.11%      24.083ms     388.435us            62  \n",
      "[0]                                              aten::relu         0.10%      23.531ms         0.31%      70.543ms       6.075us         11612  \n",
      "[0]                                        aten::bernoulli_         0.10%      22.444ms         0.10%      22.515ms       1.023ms            22  \n",
      "[0]                                           TanhBackward0         0.09%      20.399ms         0.29%      64.776ms      10.570us          6128  \n",
      "[0]      autograd::engine::evaluate_function: TanhBackward0         0.09%      20.358ms         0.49%     109.436ms      17.858us          6128  \n",
      "[0]                                                aten::to         0.09%      19.190ms         0.60%     135.008ms       5.573us         24224  \n",
      "[0]                                        SigmoidBackward0         0.09%      19.145ms         0.36%      80.233ms       8.729us          9192  \n",
      "[0]                                      aten::masked_fill_         0.08%      19.032ms         0.08%      19.032ms       2.115ms             9  \n",
      "[0]                                     aten::empty_strided         0.08%      18.579ms         0.08%      18.579ms       1.510us         12302  \n",
      "[0]                                               aten::pad         0.08%      18.522ms         0.92%     206.657ms      17.757us         11638  \n",
      "[0] autograd::engine::evaluate_function: SigmoidBackward...         0.08%      18.105ms         0.44%      98.338ms      10.698us          9192  \n",
      "[0]                                      aten::resolve_conj         0.08%      17.024ms         0.08%      17.024ms       0.104us        164071  \n",
      "[0]                                        aten::unsqueeze_         0.07%      16.870ms         0.10%      22.541ms       0.971us         23222  \n",
      "[0]                                          aten::squeeze_         0.06%      14.386ms         0.08%      18.449ms       0.795us         23220  \n",
      "[0]                                           aten::reshape         0.06%      14.050ms         0.21%      47.632ms       4.085us         11659  \n",
      "[0]                                                aten::gt         0.06%      13.875ms         0.06%      13.923ms       6.962ms             2  \n",
      "[0]                                          aten::addcmul_         0.06%      13.690ms         0.06%      13.690ms     220.806us            62  \n",
      "[0] torch.distributed.ddp.reducer::search_unused_paramet...         0.06%      13.161ms         0.06%      13.161ms       6.580ms             2  \n",
      "[0]                                Optimizer.step#Lamb.step         0.06%      13.075ms         1.28%     287.613ms     143.806ms             2  \n",
      "[0]                                                aten::le         0.06%      12.742ms         0.06%      12.742ms       3.186ms             4  \n",
      "[0]                                                   _RNNT         0.05%      12.241ms         0.17%      37.994ms      18.997ms             2  \n",
      "[0]                                              aten::div_         0.05%      11.163ms         0.05%      11.509ms     442.654us            26  \n",
      "[0]                                              aten::item         0.05%      11.049ms         0.09%      19.941ms       1.685us         11831  \n",
      "[0] autograd::engine::evaluate_function: UnsafeSplitBack...         0.05%      10.974ms         0.53%     118.817ms      38.778us          3064  \n",
      "[0]                                               aten::any         0.04%      10.113ms         0.05%      10.138ms       1.690ms             6  \n",
      "[0]                                       aten::as_strided_         0.04%       9.734ms         0.04%       9.734ms       0.210us         46433  \n",
      "[0]                               aten::_local_scalar_dense         0.04%       8.892ms         0.04%       8.892ms       0.752us         11831  \n",
      "[0]                                    aten::_reshape_alias         0.04%       8.475ms         0.04%       8.475ms       0.727us         11656  \n",
      "[0]                                    UnsafeSplitBackward0         0.03%       7.547ms         0.48%     107.843ms      35.197us          3064  \n",
      "[0]                         DistributedDataParallel.forward         0.03%       6.965ms         6.03%        1.357s     678.504ms             2  \n",
      "[0]                                           aten::dropout         0.03%       6.511ms         0.07%      15.917ms       1.367us         11640  \n",
      "[0]                               aten::cudnn_is_acceptable         0.02%       5.581ms         0.02%       5.581ms       0.480us         11630  \n",
      "[0]                                              TBackward0         0.02%       3.800ms         0.06%      14.345ms       4.642us          3090  \n",
      "[0]                                            AddBackward0         0.01%       2.928ms         0.01%       2.928ms       0.477us          6142  \n",
      "[0]                                                aten::ge         0.01%       2.832ms         0.01%       2.858ms     219.846us            13  \n",
      "[0] autograd::engine::evaluate_function: UnbindBackward0...         0.01%       2.597ms         0.08%      18.152ms     648.286us            28  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] autograd::engine::evaluate_function: torch::autograd...         0.01%       2.367ms         0.20%      44.614ms     719.581us            62  \n",
      "[0]     autograd::engine::evaluate_function: StackBackward0         0.01%       2.090ms         0.04%       8.795ms     314.107us            28  \n",
      "[0]                                           <backward op>         0.01%       1.373ms         2.22%     499.017ms     249.508ms             2  \n",
      "[0] autograd::engine::evaluate_function: LogSoftmaxBackw...         0.01%       1.328ms         0.15%      33.563ms      16.782ms             2  \n",
      "[0]                                          StackBackward0         0.01%       1.265ms         0.03%       6.572ms     234.714us            28  \n",
      "[0] autograd::engine::evaluate_function: torch::jit::(an...         0.00%     971.000us         2.22%     500.044ms     250.022ms             2  \n",
      "[0]                                             aten::zero_         0.00%     967.000us         0.12%      28.103ms     121.134us           232  \n",
      "[0]                           aten::native_dropout_backward         0.00%     957.000us         0.16%      36.074ms      18.037ms             2  \n",
      "[0]                                                _DDPSink         0.00%     664.000us         0.10%      22.832ms      11.416ms             2  \n",
      "[0]                          aten::embedding_dense_backward         0.00%     475.000us         0.00%     661.000us     330.500us             2  \n",
      "[0]                                             aten::zeros         0.00%     466.000us         0.01%       1.703ms      10.137us           168  \n",
      "[0]                                            aten::matmul         0.00%     455.000us         0.69%     155.240ms       7.056ms            22  \n",
      "[0]                                         UnbindBackward0         0.00%     405.000us         0.07%      15.555ms     555.536us            28  \n",
      "[0]                                             aten::clone         0.00%     384.000us         0.49%     109.396ms       1.351ms            81  \n",
      "[0]                                                  detach         0.00%     366.000us         0.00%     366.000us       1.441us           254  \n",
      "[0] -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "[0] Self CPU time total: 22.516s\n",
      "[0] \n",
      "[0] DLL 2023-03-20 02:45:58.076934 -  | avg train utts/s     1\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280358077, \"event_type\": \"INTERVAL_END\", \"key\": \"run_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 832, \"status\": \"aborted\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280358077, \"event_type\": \"INTERVAL_START\", \"key\": \"eval_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 239, \"epoch_num\": 2}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280369005, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_accuracy\", \"value\": 20.484347826086957, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 260, \"epoch_num\": 2}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1679280369006, \"event_type\": \"INTERVAL_END\", \"key\": \"eval_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 261, \"epoch_num\": 2}}\n",
      "[0] DLL 2023-03-20 02:46:09.007396 - epoch    2 |   dev ema wer 2048.43 | took 10.93 s[0] \n",
      "[0] Saving /home/vmagent/app/e2eaiok/result/357dc3f8a3dfe894b3a3fcdd15fd1129f95f71cf887c8475679b1ff5b50674d8/RNN-T_epoch2_checkpoint.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 02:46:21,206 - sigopt - INFO - Training completed based in sigopt suggestion, took 273.3797791004181 secs\n",
      "2023-03-20 02:46:21,206 - E2EAIOK.SDA - INFO - training script completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================\n",
      "***    Best Trained Model    ***\n",
      "===============================================\n",
      "  Model Type: rnnt\n",
      "  Model Saved Path: \n",
      "  Sigopt Experiment id is None\n",
      "  === Result Metrics ===\n",
      "===============================================\n",
      "{'dataset_dir': '/home/vmagent/app/dataset/LibriSpeech', 'train_manifests': ['/home/vmagent/app/dataset/LibriSpeech/metadata/train-test.json'], 'val_manifests': ['/home/vmagent/app/dataset/LibriSpeech/metadata/dev-test.json']}\n",
      "\n",
      "We found the best model! Here is the model explaination\n",
      "\n",
      "===============================================\n",
      "***    Best Trained Model    ***\n",
      "===============================================\n",
      "  Model Type: rnnt\n",
      "  Model Saved Path: /home/vmagent/app/e2eaiok/result/357dc3f8a3dfe894b3a3fcdd15fd1129f95f71cf887c8475679b1ff5b50674d8\n",
      "  Sigopt Experiment id is None\n",
      "  === Result Metrics ===\n",
      "    WER: 20.484347826086957\n",
      "    training_time: 273.3797791004181\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/vmagent/app/e2eaiok\n",
    "# sed -i '/ppn:/ s/:.*/: 1/' tests/cicd/conf/e2eaiok_defaults_rnnt_example.conf\n",
    "python run_e2eaiok.py --data_path /home/vmagent/app/dataset/LibriSpeech --model_name rnnt --conf tests/cicd/conf/e2eaiok_defaults_rnnt_example.conf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
