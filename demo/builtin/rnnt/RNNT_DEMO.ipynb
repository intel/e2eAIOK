{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN-T Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic speech recognition (ASR) systems convert audio into text representation. RNN-T is an end-to-end rnn based ASR model that directly output word transcripts given the input audio. This notebook contains step by step guide on how to optimize RNN-T model with IntelÂ® End-to-End AI Optimization Kit, and detailed performance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "* [Model Architecture](#Model-Architecture)\n",
    "* [Optimizations](#Optimizations)\n",
    "* [DEMO](#DEMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASR\n",
    "<img src=\"./img/asr.png\" width=\"800\"/>\n",
    "\n",
    "* The traditional ASR system (top picture) contains acoustic, phonetic and language components that work together as in a pipeline system\n",
    "* The end-to-end ASR system is a single neural network that receives raw audio signal as input and provides a sequence of words at output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "<img src=\"./img/rnnt_structure.png\"/>\n",
    "\n",
    "RNN-T is an end-to-end ASR model that directly converts audio into text representation.\n",
    "\n",
    "The encoder network is a RNN which maps input acoustic frames into a higher-level representation.\n",
    "The prediction network is a RNN that is explicitly conditioned on the history of previous non-blank targets predicted by the model.\n",
    "The joint network is a feed-forward network that combines the outputs of the prediction network and the encoder to produce logits followed by a softmax layer to produce a distribution over the next output symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture Intro\n",
    "\n",
    "For RNN-T model democratization, we enabled distributed training with pytorch DDP to scale out model training on multi nodes, added time stack layer and increased time stack factor to reduce input sequence lengh, added layer and batch normalization to speedup training converge, decreased layer size to get a lighter model.\n",
    "\n",
    "<img src=\"./img/model_base.png\" width=\"600\"/><figure>base model</figure>\n",
    "<img src=\"./img/model_opt.png\" width=\"600\"/><figure>democratized model</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed training\n",
    "\n",
    "``` python\n",
    "# data parallel\n",
    "if world_size > 1:\n",
    "    model = DDP(model, find_unused_parameters=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add time stack layer\n",
    "\n",
    "For ASR systems, the number of time frames for an audio input sequence is significantly higher than the number of output text labels. LSTM is sequential model which leads to much time cost in process long sequence data like audio data. The StackTime layer stacks audio frames to reduce sequence length and form a higher dimension input, which helps to speedup training process.\n",
    "\n",
    "```python\n",
    "class StackTime(nn.Module):\n",
    "    def __init__(self, factor):\n",
    "        super().__init__()\n",
    "        self.factor = int(factor)\n",
    "\n",
    "    def stack(self, x):\n",
    "        x = x.transpose(0, 1)\n",
    "        T = x.size(1)\n",
    "        padded = torch.nn.functional.pad(x, (0, 0, 0, (self.factor - (T % self.factor)) % self.factor))\n",
    "        B, T, H = padded.size()\n",
    "        x = padded.reshape(B, T // self.factor, -1)\n",
    "        x = x.transpose(0, 1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, x_lens):\n",
    "        if type(x) is not list:\n",
    "            x = self.stack(x)\n",
    "            x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
    "            return x, x_lens\n",
    "        else:\n",
    "            if len(x) != 2:\n",
    "                raise NotImplementedError(\"Only number of seq segments equal to 2 is supported\")\n",
    "            assert x[0].size(1) % self.factor == 0, \"The length of the 1st seq segment should be multiple of stack factor\"\n",
    "            y0 = self.stack(x[0])\n",
    "            y1 = self.stack(x[1])\n",
    "            x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
    "            return [y0, y1], x_lens\n",
    "```\n",
    "\n",
    "About 4x speedup after increase time stack factor from 2 to 8.\n",
    "\n",
    "<img src=\"./img/time_stack_2.PNG\" width=\"600\"/><figure>time_stack = 2</figure>\n",
    "<img src=\"./img/time_stack_8.PNG\" width=\"600\"/><figure>time_stack = 8</figure>\n",
    "\n",
    "Profiling data proves that less time cost on forward/backward since input sequence reduced with time stack layer\n",
    "\n",
    "<img src=\"./img/stack_profile_base.png\" width=\"600\"/><figure>base model profiling</figure>\n",
    "<img src=\"./img/stack_profile_democratize.png\" width=\"600\"/><figure>democratized model profiling</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add layer normalization and batch normalization\n",
    "\n",
    "Layer normalization for LSTM is important to the success of RNN-T modeling. Add layer normalization for LSTM and batch normalization for input feature help to speedup training converge. It takes 52 epochs to converge without normalization, while only 49 epochs needed with normalization. \n",
    "\n",
    "```python\n",
    "enc_mod[\"batch_norm\"] = nn.BatchNorm1d(pre_rnn_input_size)\n",
    "```\n",
    "\n",
    "```python\n",
    "self.layer_norm = torch.nn.LayerNorm(hidden_size)\n",
    "```\n",
    "\n",
    "<img src=\"./img/no_norm.PNG\" width=\"600\"/><figure>without normalization</figure>\n",
    "<img src=\"./img/norm.PNG\" width=\"600\"/><figure>with normalization</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO with SDA (Smart Democratization Advisor)\n",
    "\n",
    "SDA config\n",
    "\n",
    "```\n",
    "Parameters for SDA auto optimization:\n",
    "- learning_rate: 1.0e-3~1.0e-2 #training learning rate\n",
    "- warmup_epochs: 1~10 #epoch to warmup learning rate\n",
    "metrics:\n",
    "- name: training_time # training time threshold\n",
    "  objective: minimize\n",
    "  threshold: 43200\n",
    "- name: WER # training metric threshold\n",
    "  objective: minimize\n",
    "  threshold: 0.25\n",
    " ```\n",
    "\n",
    "request suggestions from SDA\n",
    "\n",
    "```python\n",
    "suggestion = self.conn.experiments(self.experiment.id).suggestions().create()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework related optimization\n",
    "\n",
    "leverage IPEX for distributed training and enable socket binding for training in two socket system\n",
    "\n",
    "```bash\n",
    "# Use IPEX launch to launch training, enable NUMA binding in two socket system.\n",
    "${CONDA_PREFIX}/bin/python -m intel_extension_for_pytorch.cpu.launch --distributed --nproc_per_node=2 --nnodes=4 --hostfile hosts train.py ${ARGS}\n",
    "```\n",
    "\n",
    "<img src=\"./img/no_numa_binding.png\" width=\"600\"/><figure>without numa binding</figure>\n",
    "<img src=\"./img/numa_binding.png\" width=\"600\"/><figure>enable numa binding</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO\n",
    "* [Environment Setup](#Environment-setup)\n",
    "* [Launch training](#Launch-training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "``` bash\n",
    "# Setup ENV\n",
    "git clone https://github.com/intel/e2eAIOK.git\n",
    "cd e2eAIOK\n",
    "git submodule update --init --recursive\n",
    "python3 scripts/start_e2eaiok_docker.py -b pytorch110 -w ${host0} ${host1} ${host2} ${host3} --proxy \"\"\n",
    "```\n",
    "\n",
    "Notes: RNN-T training is based on LibriSpeech train-clean-100 and evaluated on dev-clean, we evaluated WER with stock model (based on MLPerf submission) at train-clean-100 dataset, and final WER is 0.25, all the following optimization guarantee 0.25 WER. MLPerf submission took 38.7min with 8x A100 on LibriSpeech train-960h dataset.\n",
    "\n",
    "public reference on train-clean-100: https://arxiv.org/pdf/1807.10893.pdf, https://arxiv.org/pdf/1811.00787.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter Docker\n",
    "\n",
    "```\n",
    "sshpass -p docker ssh ${host0} -p 12345\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Prepare\n",
    "\n",
    "``` bash\n",
    "# prepare model codes\n",
    "cd /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch\n",
    "bash patch_rnnt.sh\n",
    "\n",
    "# Download Dataset\n",
    "# Download and unzip dataset from https://www.openslr.org/12 to /home/vmagent/app/dataset/LibriSpeech\n",
    "\n",
    "# Generate tokenizer and tokenize text\n",
    "cd /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch\n",
    "bash scripts/preprocess_librispeech.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edit conf/e2eaiok_defaults_rnnt_example.conf\n",
    "\n",
    "```\n",
    "### GLOBAL SETTINGS ###\n",
    "observation_budget: 1\n",
    "save_path: /home/vmagent/app/e2eaiok/result/\n",
    "ppn: 2\n",
    "train_batch_size: 8\n",
    "eval_batch_size: 8\n",
    "iface: lo\n",
    "hosts:\n",
    "- localhost\n",
    "epochs: 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 23:21:36,263 - E2EAIOK.SDA - INFO - ### Ready to submit current task  ###\n",
      "{'dataset_dir': '/home/vmagent/app/dataset/LibriSpeech', 'train_manifests': ['/home/vmagent/app/dataset/LibriSpeech/metadata/train-test.json'], 'val_manifests': ['/home/vmagent/app/dataset/LibriSpeech/metadata/dev-test.json']}\n",
      "2022-10-31 23:21:36,264 - E2EAIOK.SDA - INFO - Model Advisor created\n",
      "2022-10-31 23:21:36,264 - E2EAIOK.SDA - INFO - model parameter initialized\n",
      "2022-10-31 23:21:36,264 - E2EAIOK.SDA - INFO - start to launch training\n",
      "2022-10-31 23:21:36,264 - sigopt - INFO - training launch command: /opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/bin/python -m intel_extension_for_pytorch.cpu.launch --distributed --nproc_per_node=2 --nnodes=1 --hostfile hosts /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py --output_dir /home/vmagent/app/e2eaiok/result/3a43b6cbb0b39444d905130fa1a0b679 --dist --dist_backend ccl --batch_size 8 --val_batch_size 8 --lr 0.007 --warmup_epochs 6 --beta1 0.9 --beta2 0.999 --max_duration 16.7 --target 0.25 --min_lr 1e-05 --lr_exp_gamma 0.939 --epochs 2 --epochs_this_job 0 --ema 0.999 --model_config modelzoo/rnnt/pytorch/configs/baseline_v3-1023sp.yaml --train_dataset_dir /home/vmagent/app/dataset/LibriSpeech/train --valid_dataset_dir /home/vmagent/app/dataset/LibriSpeech/valid --dali_device cpu --weight_decay 0.001 --grad_accumulation_steps 1 --weights_init_scale 0.5 --seed 2021 --train_manifests /home/vmagent/app/dataset/LibriSpeech/metadata/train-test.json --val_manifests /home/vmagent/app/dataset/LibriSpeech/metadata/dev-test.json --vectorized_sa --vectorized_sampler --multilayer_lstm --enable_prefetch --tokenized_transcript --dist_sampler --pre_sort_for_seq_split --jit_tensor_formation --max_symbol_per_sample 300 --data_cpu_threads 4 --min_seq_split_len 20 --log_frequency 1 --val_frequency 1 --prediction_frequency 1000000 --training_time_threshold 43200 --enc_n_hid 1024 --enc_pre_rnn_layers 2 --enc_stack_time_factor 8 --enc_post_rnn_layers 2 --pred_n_hid 512 --joint_n_hid 512 --fuse_relu_dropout --multi_tensor_ema --apex_transducer_loss fp16 --apex_transducer_joint pack             --buffer_pre_alloc --ema_update_type fp16 --apex_mlp --save_at_the_end \n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/runpy.py:127: RuntimeWarning: 'intel_extension_for_pytorch.cpu.launch' found in sys.modules after import of package 'intel_extension_for_pytorch.cpu', but prior to execution of 'intel_extension_for_pytorch.cpu.launch'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2022-10-31 23:21:37,302 - __main__ - INFO - MASTER_ADDR=127.0.0.1\n",
      "2022-10-31 23:21:37,302 - __main__ - INFO - MASTER_PORT=29500\n",
      "2022-10-31 23:21:37,303 - __main__ - INFO - I_MPI_PIN_DOMAIN=[0x3fff0,0xfffc00000,]\n",
      "2022-10-31 23:21:37,303 - __main__ - WARNING - Both TCMalloc and JeMalloc are not found in $CONDA_PREFIX/lib or $VIRTUAL_ENV/lib or /.local/lib/ or /usr/local/lib/ or /usr/local/lib64/ or /usr/lib or /usr/lib64 or /root/.local/lib/ so the LD_PRELOAD environment variable will not be set. This may drop the performance\n",
      "2022-10-31 23:21:37,306 - __main__ - INFO - OMP_NUM_THREADS=14\n",
      "2022-10-31 23:21:37,307 - __main__ - INFO - Using Intel OpenMP\n",
      "2022-10-31 23:21:37,307 - __main__ - INFO - KMP_AFFINITY=granularity=fine,compact,1,0\n",
      "2022-10-31 23:21:37,307 - __main__ - INFO - KMP_BLOCKTIME=1\n",
      "2022-10-31 23:21:37,307 - __main__ - INFO - LD_PRELOAD=/opt/intel/oneapi/intelpython/latest/lib/libiomp5.so\n",
      "2022-10-31 23:21:37,307 - __main__ - INFO - CCL_WORKER_COUNT=4\n",
      "2022-10-31 23:21:37,307 - __main__ - INFO - CCL_WORKER_AFFINITY=0,1,2,3,18,19,20,21\n",
      "2022-10-31 23:21:37,307 - __main__ - INFO - ['mpiexec.hydra', '-l', '-np', '2', '-ppn', '2', '-genv', 'I_MPI_PIN_DOMAIN=[0x3fff0,0xfffc00000,]', '-genv', 'OMP_NUM_THREADS=14', '/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/bin/python', '-u', '/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py', '--output_dir', '/home/vmagent/app/e2eaiok/result/3a43b6cbb0b39444d905130fa1a0b679', '--dist', '--dist_backend', 'ccl', '--batch_size', '8', '--val_batch_size', '8', '--lr', '0.007', '--warmup_epochs', '6', '--beta1', '0.9', '--beta2', '0.999', '--max_duration', '16.7', '--target', '0.25', '--min_lr', '1e-05', '--lr_exp_gamma', '0.939', '--epochs', '2', '--epochs_this_job', '0', '--ema', '0.999', '--model_config', 'modelzoo/rnnt/pytorch/configs/baseline_v3-1023sp.yaml', '--train_dataset_dir', '/home/vmagent/app/dataset/LibriSpeech/train', '--valid_dataset_dir', '/home/vmagent/app/dataset/LibriSpeech/valid', '--dali_device', 'cpu', '--weight_decay', '0.001', '--grad_accumulation_steps', '1', '--weights_init_scale', '0.5', '--seed', '2021', '--train_manifests', '/home/vmagent/app/dataset/LibriSpeech/metadata/train-test.json', '--val_manifests', '/home/vmagent/app/dataset/LibriSpeech/metadata/dev-test.json', '--vectorized_sa', '--vectorized_sampler', '--multilayer_lstm', '--enable_prefetch', '--tokenized_transcript', '--dist_sampler', '--pre_sort_for_seq_split', '--jit_tensor_formation', '--max_symbol_per_sample', '300', '--data_cpu_threads', '4', '--min_seq_split_len', '20', '--log_frequency', '1', '--val_frequency', '1', '--prediction_frequency', '1000000', '--training_time_threshold', '43200', '--enc_n_hid', '1024', '--enc_pre_rnn_layers', '2', '--enc_stack_time_factor', '8', '--enc_post_rnn_layers', '2', '--pred_n_hid', '512', '--joint_n_hid', '512', '--fuse_relu_dropout', '--multi_tensor_ema', '--apex_transducer_loss', 'fp16', '--apex_transducer_joint', 'pack', '--buffer_pre_alloc', '--ema_update_type', 'fp16', '--apex_mlp', '--save_at_the_end']\n",
      "[1] world_size:2,rank:1\n",
      "[0] world_size:2,rank:0\n",
      "[1] 2022-10-31 23:21:41,305 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "[0] 2022-10-31 23:21:41,310 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "[0] 2022-10-31 23:21:41,310 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[0] Using CCL_ATL_TRANSPORT=(default)\n",
      "[0] Using CCL_ATL_SHM=(default)[0] \n",
      "[1] 2022-10-31 23:21:41,319 - torch.distributed.distributed_c10d - INFO - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[1] Using CCL_ATL_TRANSPORT=(default)\n",
      "[1] Using CCL_ATL_SHM=(default)\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501311, \"event_type\": \"INTERVAL_START\", \"key\": \"init_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 355}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501530, \"event_type\": \"POINT_IN_TIME\", \"key\": \"seed\", \"value\": 2021, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 360}}\n",
      "[0] DLL 2022-10-31 23:21:41.532829 - PARAMETER | epochs :  2\n",
      "[0] DLL 2022-10-31 23:21:41.532886 - PARAMETER | warmup_epochs :  6\n",
      "[0] DLL 2022-10-31 23:21:41.532910 - PARAMETER | hold_epochs :  40\n",
      "[0] DLL 2022-10-31 23:21:41.532929 - PARAMETER | epochs_this_job :  0\n",
      "[0] DLL 2022-10-31 23:21:41.532946 - PARAMETER | cudnn_benchmark :  True\n",
      "[0] DLL 2022-10-31 23:21:41.532965 - PARAMETER | amp_level :  1\n",
      "[0] DLL 2022-10-31 23:21:41.532983 - PARAMETER | seed :  2021\n",
      "[0] DLL 2022-10-31 23:21:41.533024 - PARAMETER | local_rank :  0\n",
      "[0] DLL 2022-10-31 23:21:41.533040 - PARAMETER | target :  0.25\n",
      "[0] DLL 2022-10-31 23:21:41.533075 - PARAMETER | apex_transducer_loss :  fp16\n",
      "[0] DLL 2022-10-31 23:21:41.533090 - PARAMETER | fuse_relu_dropout :  True\n",
      "[0] DLL 2022-10-31 23:21:41.533119 - PARAMETER | weights_init_scale :  0.5\n",
      "[0] DLL 2022-10-31 23:21:41.533136 - PARAMETER | hidden_hidden_bias_scale : \n",
      "[0] DLL 2022-10-31 23:21:41.533173 - PARAMETER | batch_eval_mode : \n",
      "[0] DLL 2022-10-31 23:21:41.533187 - PARAMETER | cg_unroll_factor :  4\n",
      "[0] DLL 2022-10-31 23:21:41.533222 - PARAMETER | apex_transducer_joint :  pack\n",
      "[0] DLL 2022-10-31 23:21:41.533238 - PARAMETER | buffer_pre_alloc :  True\n",
      "[0] DLL 2022-10-31 23:21:41.533270 - PARAMETER | multilayer_lstm :  True\n",
      "[0] DLL 2022-10-31 23:21:41.533286 - PARAMETER | batch_split_factor :  1\n",
      "[0] DLL 2022-10-31 23:21:41.533303 - PARAMETER | apex_mlp :  True\n",
      "[0] DLL 2022-10-31 23:21:41.533323 - PARAMETER | num_cg :  0\n",
      "[0] DLL 2022-10-31 23:21:41.533338 - PARAMETER | min_seq_split_len :  20\n",
      "[0] DLL 2022-10-31 23:21:41.533355 - PARAMETER | pre_sort_for_seq_split :  True[0] \n",
      "[0] DLL 2022-10-31 23:21:41.533372 - PARAMETER | dist :  True\n",
      "[0] DLL 2022-10-31 23:21:41.533387 - PARAMETER | dist_backend :  ccl\n",
      "[0] DLL 2022-10-31 23:21:41.533407 - PARAMETER | use_ipex :  False\n",
      "[0] DLL 2022-10-31 23:21:41.533424 - PARAMETER | batch_size :  8\n",
      "[0] DLL 2022-10-31 23:21:41.533441 - PARAMETER | val_batch_size :  8\n",
      "[0] DLL 2022-10-31 23:21:41.533487 - PARAMETER | lr :  0.007\n",
      "[0] DLL 2022-10-31 23:21:41.533504 - PARAMETER | min_lr :  1e-05\n",
      "[0] DLL 2022-10-31 23:21:41.533529 - PARAMETER | lr_exp_gamma :  0.939\n",
      "[0] DLL 2022-10-31 23:21:41.533562 - PARAMETER | weight_decay :  0.001\n",
      "[0] DLL 2022-10-31 23:21:41.533578 - PARAMETER | grad_accumulation_steps :  1\n",
      "[0] DLL 2022-10-31 23:21:41.533595 - PARAMETER | clip_norm :  1\n",
      "[0] DLL 2022-10-31 23:21:41.533610 - PARAMETER | beta1 :  0.9\n",
      "[0] DLL 2022-10-31 23:21:41.533630 - PARAMETER | beta2 :  0.999\n",
      "[0] DLL 2022-10-31 23:21:41.533646 - PARAMETER | ema :  0.999\n",
      "[0] DLL 2022-10-31 23:21:41.533661 - PARAMETER | multi_tensor_ema :  True\n",
      "[0] DLL 2022-10-31 23:21:41.533678 - PARAMETER | dist_lamb :  False\n",
      "[0] DLL 2022-10-31 23:21:41.533692 - PARAMETER | ema_update_type :  fp16\n",
      "[0] DLL 2022-10-31 23:21:41.533708 - PARAMETER | dwu_group_size :  8\n",
      "[0] DLL 2022-10-31 23:21:41.533725 - PARAMETER | dali_device :  cpu\n",
      "[0] DLL 2022-10-31 23:21:41.533740 - PARAMETER | resume :  False\n",
      "[0] DLL 2022-10-31 23:21:41.533758 - PARAMETER | ckpt : \n",
      "[0] DLL 2022-10-31 23:21:41.533773 - PARAMETER | save_at_the_end :  True\n",
      "[0] DLL 2022-10-31 23:21:41.533788 - PARAMETER | save_frequency : \n",
      "[0] DLL 2022-10-31 23:21:41.533804 - PARAMETER | keep_milestones :  []\n",
      "[0] DLL 2022-10-31 23:21:41.533823 - PARAMETER | save_best_from :  200\n",
      "[0] DLL 2022-10-31 23:21:41.533838 - PARAMETER | val_frequency :  1\n",
      "[0] DLL 2022-10-31 23:21:41.533855 - PARAMETER | log_frequency :  1\n",
      "[0] DLL 2022-10-31 23:21:41.533870 - PARAMETER | prediction_frequency :  1000000\n",
      "[0] DLL 2022-10-31 23:21:41.533886 - PARAMETER | model_config :  modelzoo/rnnt/pytorch/configs/baseline_v3-1023sp.yaml\n",
      "[0] DLL 2022-10-31 23:21:41.533903 - PARAMETER | num_buckets :  6\n",
      "[0] DLL 2022-10-31 23:21:41.533918 - PARAMETER | vectorized_sampler :  True\n",
      "[0] DLL 2022-10-31 23:21:41.533935 - PARAMETER | dist_sampler :  True\n",
      "[0] DLL 2022-10-31 23:21:41.533950 - PARAMETER | train_manifests :  ['/home/vmagent/app/dataset/LibriSpeech/metadata/train-test.json']\n",
      "[0] DLL 2022-10-31 23:21:41.533970 - PARAMETER | val_manifests :  ['/home/vmagent/app/dataset/LibriSpeech/metadata/dev-test.json']\n",
      "[0] DLL 2022-10-31 23:21:41.533989 - PARAMETER | max_duration :  16.7\n",
      "[0] DLL 2022-10-31 23:21:41.534007 - PARAMETER | max_txt_len :  125\n",
      "[0] DLL 2022-10-31 23:21:41.534022 - PARAMETER | max_eval_sample_duration :  32.7\n",
      "[0] DLL 2022-10-31 23:21:41.534040 - PARAMETER | train_dataset_dir :  /home/vmagent/app/dataset/LibriSpeech/train\n",
      "[0] DLL 2022-10-31 23:21:41.534055 - PARAMETER | valid_dataset_dir :  /home/vmagent/app/dataset/LibriSpeech/valid\n",
      "[0] DLL 2022-10-31 23:21:41.534069 - PARAMETER | output_dir :  /home/vmagent/app/e2eaiok/result/3a43b6cbb0b39444d905130fa1a0b679\n",
      "[0] DLL 2022-10-31 23:21:41.534089 - PARAMETER | log_file : \n",
      "[0] DLL 2022-10-31 23:21:41.534104 - PARAMETER | max_symbol_per_sample :  300\n",
      "[0] DLL 2022-10-31 23:21:41.534119 - PARAMETER | data_cpu_threads :  4\n",
      "[0] DLL 2022-10-31 23:21:41.534135 - PARAMETER | synthetic_audio_seq_len : \n",
      "[0] DLL 2022-10-31 23:21:41.534150 - PARAMETER | synthetic_text_seq_len : \n",
      "[0] DLL 2022-10-31 23:21:41.534164 - PARAMETER | enable_seq_len_stats :  False\n",
      "[0] DLL 2022-10-31 23:21:41.534181 - PARAMETER | vectorized_sa :  True\n",
      "[0] DLL 2022-10-31 23:21:41.534197 - PARAMETER | in_mem_file_list :  False\n",
      "[0] DLL 2022-10-31 23:21:41.534216 - PARAMETER | enable_prefetch :  True\n",
      "[0] DLL 2022-10-31 23:21:41.534248 - PARAMETER | tokenized_transcript :  True\n",
      "[0] DLL 2022-10-31 23:21:41.534264 - PARAMETER | jit_tensor_formation :  True\n",
      "[0] DLL 2022-10-31 23:21:41.534280 - PARAMETER | dali_dont_use_mmap :  False\n",
      "[0] DLL 2022-10-31 23:21:41.534295 - PARAMETER | training_time_threshold :  43200\n",
      "[0] DLL 2022-10-31 23:21:41.534311 - PARAMETER | enc_n_hid :  1024\n",
      "[0] DLL 2022-10-31 23:21:41.534328 - PARAMETER | enc_pre_rnn_layers :  2\n",
      "[0] DLL 2022-10-31 23:21:41.534342 - PARAMETER | enc_stack_time_factor :  8\n",
      "[0] DLL 2022-10-31 23:21:41.534356 - PARAMETER | enc_post_rnn_layers :  2\n",
      "[0] DLL 2022-10-31 23:21:41.534373 - PARAMETER | enc_dropout :  0.1\n",
      "[0] DLL 2022-10-31 23:21:41.534388 - PARAMETER | pred_n_hid :  512\n",
      "[0] DLL 2022-10-31 23:21:41.534405 - PARAMETER | pred_rnn_layers :  2\n",
      "[0] DLL 2022-10-31 23:21:41.534420 - PARAMETER | pred_dropout :  0.3\n",
      "[0] DLL 2022-10-31 23:21:41.534437 - PARAMETER | joint_n_hid :  512\n",
      "[0] DLL 2022-10-31 23:21:41.534452 - PARAMETER | joint_dropout :  0.3\n",
      "[0] DLL 2022-10-31 23:21:41.534469 - PARAMETER | rnn_type :  lstm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501551, \"event_type\": \"POINT_IN_TIME\", \"key\": \"gradient_accumulation_steps\", \"value\": 1, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 378}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501551, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_benchmark\", \"value\": \"rnnt\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 384}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501551, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_org\", \"value\": \"Intel\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 385}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501551, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_division\", \"value\": \"closed\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 386}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501551, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_status\", \"value\": \"onprem\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 387}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501552, \"event_type\": \"POINT_IN_TIME\", \"key\": \"submission_platform\", \"value\": \"CPU\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 388}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501554, \"event_type\": \"POINT_IN_TIME\", \"key\": \"model_weights_initialization_scale\", \"value\": 0.5, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 395}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501633, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/rnn.py\", \"lineno\": 87, \"tensor\": \"pre_rnn\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501895, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/rnn.py\", \"lineno\": 87, \"tensor\": \"post_rnn\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501900, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 155, \"tensor\": \"pred_embed\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501926, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/rnn.py\", \"lineno\": 87, \"tensor\": \"dec_rnn\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501928, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 176, \"tensor\": \"joint_pred\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501931, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 181, \"tensor\": \"joint_enc\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501935, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py\", \"lineno\": 190, \"tensor\": \"joint_net\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501935, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_max_prediction_symbols\", \"value\": 300, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 416}}\n",
      "[0] Model size: 65.8M params\n",
      "[0] \n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258501959, \"event_type\": \"POINT_IN_TIME\", \"key\": \"model_eval_ema_factor\", \"value\": 0.999, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 430}}\n",
      "[0] Starting with LRs: 0.007\n",
      "[0] DistributedDataParallel(\n",
      "[0]   (module): RNNT(\n",
      "[0]     (encoder): ModuleDict(\n",
      "[0]       (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "[0]       (pre_rnn): LSTM(\n",
      "[0]         (lstm): LSTM(256, 1024, num_layers=2, dropout=0.1)\n",
      "[0]         (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "[0]         (dropout): Dropout(p=0.1, inplace=False)\n",
      "[0]       )\n",
      "[0]       (stack_time): StackTime()\n",
      "[0]       (post_rnn): LSTM(\n",
      "[0]         (lstm): LSTM(8192, 1024, num_layers=2, dropout=0.1)\n",
      "[0]         (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "[0]         (dropout): Dropout(p=0.1, inplace=False)\n",
      "[0]       )\n",
      "[0]     )\n",
      "[0]     (prediction): ModuleDict(\n",
      "[0]       (embed): Embedding(1023, 512)\n",
      "[0]       (dec_rnn): LSTM(\n",
      "[0]         (lstm): LSTM(512, 512, num_layers=2, dropout=0.3)\n",
      "[0]         (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "[0]         (dropout): Dropout(p=0.3, inplace=False)\n",
      "[0]       )\n",
      "[0]     )\n",
      "[0]     (joint_pred): Linear(in_features=512, out_features=512, bias=True)\n",
      "[0]     (joint_enc): Linear(in_features=1024, out_features=512, bias=True)\n",
      "[0]     (joint_net): Sequential(\n",
      "[0]       (0): FusedReluDropout()\n",
      "[0]       (1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "[0]     )\n",
      "[0]   )\n",
      "[0] )\n",
      "[0] Setting up datasets...\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502250, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_train_max_duration\", \"value\": 16.7, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 470}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502250, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_speed_perturbaton_max\", \"value\": 1.15, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 472}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502250, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_speed_perturbaton_min\", \"value\": 0.85, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 474}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502250, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_freq_n\", \"value\": 2, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 476}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502251, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_freq_min\", \"value\": 0, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 478}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502251, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_freq_max\", \"value\": 20, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 480}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502251, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_time_n\", \"value\": 10, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 482}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502251, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_time_min\", \"value\": 0, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 484}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502251, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_spec_augment_time_max\", \"value\": 0.03, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 486}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502251, \"event_type\": \"POINT_IN_TIME\", \"key\": \"global_batch_size\", \"value\": 16, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 488}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502251, \"event_type\": \"INTERVAL_END\", \"key\": \"init_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 558}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502252, \"event_type\": \"INTERVAL_START\", \"key\": \"run_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 561}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502252, \"event_type\": \"POINT_IN_TIME\", \"key\": \"data_train_num_buckets\", \"value\": 6, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 567}}\n",
      "[0] Launching vectorized bucketing sampler\n",
      "[0] Launching simple sampler\n",
      "[0] Dataset read by DALI. Number of samples: 96\n",
      "[0] Initializing DALI with parameters:\n",
      "[0] \t           __class__ : <class 'common.data.dali.pipeline.DaliPipeline'>\n",
      "[0] \t          batch_size : 8\n",
      "[0] \t           device_id : None\n",
      "[0] \t        dither_coeff : 1e-05\n",
      "[0] \t       dont_use_mmap : False\n",
      "[0] \t           file_root : /home/vmagent/app/dataset/LibriSpeech/train\n",
      "[0] \t    in_mem_file_list : False\n",
      "[0] \t        max_duration : 16.7\n",
      "[0] \t           nfeatures : 80\n",
      "[0] \t                nfft : 512\n",
      "[0] \t         num_threads : 4\n",
      "[0] \t       pipeline_type : train\n",
      "[0] \t            pre_sort : True\n",
      "[0] \t       preemph_coeff : 0.97[0] \n",
      "[0] \tpreprocessing_device : cpu\n",
      "[0] \t      resample_range : [0.85, 1.15]\n",
      "[0] \t         sample_rate : 16000\n",
      "[0] \t             sampler : <common.data.dali.sampler.VectorizedBucketingSampler object at 0x7f8da80aa310>\n",
      "[0] \t                seed : 2021\n",
      "[0] \t                self : <common.data.dali.pipeline.DaliPipeline object at 0x7f8da80aa370>\n",
      "[0] \t   silence_threshold : -60\n",
      "[0] \t   synthetic_seq_len : None[0] \n",
      "[0] \t         window_size : 0.02\n",
      "[0] \t       window_stride : 0.01\n",
      "[0] /opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/site-packages/nvidia/dali/plugin/base_iterator.py:163: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.\n",
      "[0]   _iterator_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] /opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/site-packages/nvidia/dali/plugin/base_iterator.py:163: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.\n",
      "[1]   _iterator_deprecation_warning()\n",
      "[0] Dataset read by DALI. Number of samples: 73\n",
      "[0] Initializing DALI with parameters:\n",
      "[0] \t           __class__ : <class 'common.data.dali.pipeline.DaliPipeline'>\n",
      "[0] \t          batch_size : 8\n",
      "[0] \t           device_id : None\n",
      "[0] \t        dither_coeff : 1e-05\n",
      "[0] \t       dont_use_mmap : False\n",
      "[0] \t           file_root : /home/vmagent/app/dataset/LibriSpeech/valid\n",
      "[0] \t    in_mem_file_list : False\n",
      "[0] \t        max_duration : inf\n",
      "[0] \t           nfeatures : 80\n",
      "[0] \t                nfft : 512\n",
      "[0] \t         num_threads : 4\n",
      "[0] \t       pipeline_type : val\n",
      "[0] \t            pre_sort : False\n",
      "[0] \t       preemph_coeff : 0.97\n",
      "[0] \tpreprocessing_device : cpu\n",
      "[0] \t      resample_range : None\n",
      "[0] \t         sample_rate : 16000\n",
      "[0] \t             sampler : <common.data.dali.sampler.SimpleSampler object at 0x7f8da80aa0a0>\n",
      "[0] \t                seed : 2021\n",
      "[0] \t                self : <common.data.dali.pipeline.DaliPipeline object at 0x7f8da01b6910>\n",
      "[0] \t   silence_threshold : -60\n",
      "[0] \t   synthetic_seq_len : None\n",
      "[0] \t         window_size : 0.02\n",
      "[0] \t       window_stride : 0.01\n",
      "[1] /opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/site-packages/torch/profiler/profiler.py:52: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "[1]   warn(\"Profiler won't be using warmup, this can skew profiler results\")\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/features.py:201: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   x_lens = (x_lens.int() + stacking - 1) // stacking\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502691, \"event_type\": \"POINT_IN_TIME\", \"key\": \"train_samples\", \"value\": 96, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 649}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_samples\", \"value\": 73, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 650}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_name\", \"value\": \"lamb\", \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 652}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_base_learning_rate\", \"value\": 0.007, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 653}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_epsilon\", \"value\": 1e-09, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 654}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_learning_rate_decay_poly_power\", \"value\": 0.939, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 655}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_learning_rate_warmup_epochs\", \"value\": 6, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 656}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_learning_rate_hold_epochs\", \"value\": 40, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 657}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_beta_1\", \"value\": 0.9, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 658}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_beta_2\", \"value\": 0.999, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 659}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_gradient_clip_norm\", \"value\": 1, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 660}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_learning_rate_alt_decay_func\", \"value\": true, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 661}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_learning_rate_alt_warmup_func\", \"value\": true, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 662}}\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/dali/iterator.py:151: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   pivot_len = (audio_shape_sorted[self.split_batch_size] + stack_factor-1) // stack_factor * stack_factor\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_lamb_learning_rate_min\", \"value\": 1e-05, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 663}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502692, \"event_type\": \"POINT_IN_TIME\", \"key\": \"opt_weight_decay\", \"value\": 0.001, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 664}}\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/helpers.py:276: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   batch_offset = torch.cumsum(g_len * ((feat_lens+self.enc_stack_time_factor-1)//self.enc_stack_time_factor), dim=0)\n",
      "[0] /opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/site-packages/torch/profiler/profiler.py:52: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "[0]   warn(\"Profiler won't be using warmup, this can skew profiler results\")\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502693, \"event_type\": \"INTERVAL_START\", \"key\": \"block_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 695, \"first_epoch_num\": 1, \"epoch_count\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258502693, \"event_type\": \"INTERVAL_START\", \"key\": \"epoch_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 698, \"epoch_num\": 1}}\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/features.py:201: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   x_lens = (x_lens.int() + stacking - 1) // stacking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/data/dali/iterator.py:151: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   pivot_len = (audio_shape_sorted[self.split_batch_size] + stack_factor-1) // stack_factor * stack_factor\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/common/helpers.py:276: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   batch_offset = torch.cumsum(g_len * ((feat_lens+self.enc_stack_time_factor-1)//self.enc_stack_time_factor), dim=0)\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:64: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:64: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
      "[0] DLL 2022-10-31 23:21:47.870652 - epoch    1 | iter    1/6 | loss  967.40 | utts/s     3 | took  5.13 s | lrate 3.78e-04\n",
      "[0] DLL 2022-10-31 23:21:51.735583 - epoch    1 | iter    2/6 | loss  906.09 | utts/s     4 | took  3.87 s | lrate 5.68e-04\n",
      "[0] DLL 2022-10-31 23:21:55.114815 - epoch    1 | iter    3/6 | loss  788.63 | utts/s     5 | took  3.38 s | lrate 7.57e-04\n",
      "[0] DLL 2022-10-31 23:21:57.761047 - epoch    1 | iter    4/6 | loss  516.45 | utts/s     6 | took  2.65 s | lrate 9.46e-04\n",
      "[0] DLL 2022-10-31 23:22:02.049904 - epoch    1 | iter    5/6 | loss  955.55 | utts/s     4 | took  4.29 s | lrate 1.14e-03\n",
      "[0] DLL 2022-10-31 23:22:08.960167 - epoch    1 | iter    6/6 | loss  822.95 | utts/s     2 | took  6.91 s | lrate 1.32e-03\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258528960, \"event_type\": \"INTERVAL_END\", \"key\": \"epoch_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 784, \"epoch_num\": 1}}\n",
      "[0] DLL 2022-10-31 23:22:08.961320 - epoch    1 | avg train utts/s     4 | took 26.27 s\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258528961, \"event_type\": \"POINT_IN_TIME\", \"key\": \"throughput\", \"value\": 3.65473389676755, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 791}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258528961, \"event_type\": \"INTERVAL_START\", \"key\": \"eval_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 238, \"epoch_num\": 1}}\n",
      "[1] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:53: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[1]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
      "[0] /home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/rnnt/model.py:53: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "[0]   x_lens = (x_lens.int() + self.factor - 1) // self.factor\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258546055, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_accuracy\", \"value\": 20.484347826086957, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 259, \"epoch_num\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258546055, \"event_type\": \"INTERVAL_END\", \"key\": \"eval_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 260, \"epoch_num\": 1}}\n",
      "[0] DLL 2022-10-31 23:22:26.056032 - epoch    1 |   dev ema wer 2048.43 | took 17.09 s\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258546056, \"event_type\": \"INTERVAL_END\", \"key\": \"block_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 809, \"first_epoch_num\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258546056, \"event_type\": \"INTERVAL_START\", \"key\": \"block_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 695, \"first_epoch_num\": 2, \"epoch_count\": 1}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258546056, \"event_type\": \"INTERVAL_START\", \"key\": \"epoch_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 698, \"epoch_num\": 2}}\n",
      "[0] DLL 2022-10-31 23:22:36.628856 - epoch    2 | iter    1/6 | loss  863.43 | utts/s     2 | took 10.52 s | lrate 1.51e-03\n",
      "[0] DLL 2022-10-31 23:24:38.834027 - epoch    2 | iter    2/6 | loss  449.37 | utts/s     0 | took 122.20 s | lrate 1.70e-03\n",
      "[0] DLL 2022-10-31 23:24:42.578406 - epoch    2 | iter    3/6 | loss  719.64 | utts/s     4 | took  3.74 s | lrate 1.89e-03\n",
      "[0] DLL 2022-10-31 23:24:46.629434 - epoch    2 | iter    4/6 | loss  746.94 | utts/s     4 | took  4.05 s | lrate 2.08e-03\n",
      "[0] DLL 2022-10-31 23:24:51.080505 - epoch    2 | iter    5/6 | loss  823.48 | utts/s     4 | took  4.45 s | lrate 2.27e-03\n",
      "[0] DLL 2022-10-31 23:24:54.937695 - epoch    2 | iter    6/6 | loss  751.87 | utts/s     4 | took  3.86 s | lrate 2.46e-03\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258694938, \"event_type\": \"INTERVAL_END\", \"key\": \"epoch_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 784, \"epoch_num\": 2}}\n",
      "[0] DLL 2022-10-31 23:24:54.938781 - epoch    2 | avg train utts/s     1 | took 148.88 s\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258694938, \"event_type\": \"POINT_IN_TIME\", \"key\": \"throughput\", \"value\": 0.6448048954398399, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 791}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258694938, \"event_type\": \"INTERVAL_START\", \"key\": \"eval_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 238, \"epoch_num\": 2}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258705024, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_accuracy\", \"value\": 20.484347826086957, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 259, \"epoch_num\": 2}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258705025, \"event_type\": \"INTERVAL_END\", \"key\": \"eval_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 260, \"epoch_num\": 2}}\n",
      "[0] DLL 2022-10-31 23:25:05.025544 - epoch    2 |   dev ema wer 2048.43 | took 10.09 s\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258705025, \"event_type\": \"INTERVAL_END\", \"key\": \"block_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 809, \"first_epoch_num\": 2}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "[0]                                                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "[0] -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "[0]                                                aten::mm        20.34%        7.033s        20.41%        7.059s     171.976us         41047  \n",
      "[0]                                               aten::add        19.96%        6.902s        19.96%        6.903s     287.130us         24043  \n",
      "[0]                                           ProfilerStep*        12.83%        4.435s       100.00%       34.578s       17.289s             2  \n",
      "[0]                                             aten::addmm        10.13%        3.502s        11.62%        4.020s      95.945us         41896  \n",
      "[0]                                            aten::select         2.82%     974.153ms         2.98%        1.031s       7.436us        138620  \n",
      "[0]                                               aten::mul         2.76%     955.127ms         2.77%     959.025ms       8.750us        109598  \n",
      "[0]                                              aten::lstm         2.73%     942.895ms        31.88%       11.025s     947.983us         11630  \n",
      "[0]                                              aten::add_         2.33%     805.554ms         2.33%     805.554ms       8.414us         95743  \n",
      "[0]                                          aten::sigmoid_         2.08%     717.824ms         2.08%     717.824ms       7.901us         90852  \n",
      "[0]                                              aten::_cat         1.81%     625.849ms         2.25%     777.228ms      15.665us         49616  \n",
      "[0]                                       torch_ipex::copy_         1.25%     432.074ms         1.44%     497.482ms       7.506us         66275  \n",
      "[0]                                    torch_ccl::allreduce         1.20%     413.231ms         1.20%     413.231ms      25.827ms            16  \n",
      "[0]                                             aten::slice         0.90%     311.607ms         1.35%     467.844ms       2.565us        182430  \n",
      "[0]                                        aten::as_strided         0.89%     308.693ms         1.14%     395.434ms       0.683us        579238  \n",
      "[0]                                            aten::linear         0.81%     279.064ms        21.08%        7.289s      94.940us         76775  \n",
      "[0]                                            aten::narrow         0.75%     258.919ms         1.47%     507.941ms       3.761us        135042  \n",
      "[0]                                         aten::transpose         0.73%     252.347ms         0.98%     338.622ms       3.012us        112422  \n",
      "[0]                                                 aten::t         0.67%     232.681ms         1.38%     478.146ms       5.365us         89123  \n",
      "[0]                                         aten::unsqueeze         0.64%     219.708ms         0.81%     279.822ms       2.702us        103545  \n",
      "[0]                                             aten::tanh_         0.61%     211.408ms         0.61%     211.408ms       6.981us         30284  \n",
      "[0]                                            aten::matmul         0.59%     204.273ms         6.57%        2.271s      65.103us         34879  \n",
      "[0]                                               aten::max         0.59%     202.348ms         0.89%     307.650ms      26.478us         11619  \n",
      "[0]                                               aten::div         0.56%     194.525ms         0.57%     196.396ms     613.737us           320  \n",
      "[0]                                              aten::tanh         0.56%     192.049ms         0.56%     192.049ms       6.342us         30284  \n",
      "[0]                                             aten::stack         0.53%     184.405ms         3.20%        1.106s      23.755us         46548  \n",
      "[0]                                              aten::view         0.51%     177.634ms         0.52%     178.442ms       1.657us        107696  \n",
      "[0]                                             aten::fill_         0.51%     177.354ms         0.51%     177.527ms      11.933us         14877  \n",
      "[0]                                      aten::unsafe_split         0.47%     163.604ms         1.75%     605.324ms      19.988us         30284  \n",
      "[0]                                             aten::copy_         0.46%     159.570ms         1.71%     591.644ms       8.927us         66275  \n",
      "[0]                                            aten::unbind         0.46%     159.342ms         0.91%     313.887ms       6.742us         46558  \n",
      "[0]                                Optimizer.step#Lamb.step         0.39%     134.380ms         1.65%     570.221ms     285.111ms             2  \n",
      "[0]                                        aten::bernoulli_         0.37%     128.524ms         0.37%     128.579ms       5.845ms            22  \n",
      "[0]                                               aten::cat         0.37%     128.035ms         2.55%     880.071ms      17.738us         49616  \n",
      "[0]                        aten::_log_softmax_backward_data         0.35%     121.526ms         0.35%     121.526ms      60.763ms             2  \n",
      "[0]         autograd::engine::evaluate_function: TBackward0         0.32%     109.367ms        19.58%        6.770s       2.191ms          3090  \n",
      "[0]                                               aten::sum         0.30%     105.232ms         0.35%     122.228ms      39.378us          3104  \n",
      "[0]                                             aten::empty         0.30%     103.775ms         0.30%     103.779ms       0.959us        108257  \n",
      "[0]                                         aten::clamp_min         0.30%     102.800ms         0.52%     178.128ms       7.670us         23224  \n",
      "[0]                                      aten::index_select         0.29%      98.765ms         0.50%     173.716ms      15.007us         11576  \n",
      "[0]                                              aten::sqrt         0.27%      94.429ms         0.27%      94.429ms       1.195ms            79  \n",
      "[0]     autograd::engine::evaluate_function: AddmmBackward0         0.26%      91.190ms        14.81%        5.121s       1.670ms          3066  \n",
      "[0]                                   aten::constant_pad_nd         0.24%      81.485ms         0.79%     274.323ms      23.555us         11646  \n",
      "[0]                                            aten::expand         0.22%      76.231ms         0.29%     101.665ms       2.425us         41917  \n",
      "[0] autograd::engine::evaluate_function: LogSoftmaxBackw...         0.21%      72.452ms         0.56%     194.028ms      97.014ms             2  \n",
      "[0]                                           aten::resize_         0.21%      70.922ms         0.21%      70.922ms       1.429us         49637  \n",
      "[0]                                         aten::embedding         0.20%      70.233ms         0.85%     295.260ms      25.506us         11576  \n",
      "[0]                                      aten::_unsafe_view         0.20%      70.183ms         0.31%     105.989ms       3.038us         34889  \n",
      "[0]                                      aten::_log_softmax         0.20%      67.639ms         0.20%      67.639ms      33.819ms             2  \n",
      "[0]                                              aten::mul_         0.19%      64.672ms         0.19%      66.552ms     443.680us           150  \n",
      "[0]                                            MulBackward0         0.18%      63.583ms         0.71%     244.140ms      26.502us          9212  \n",
      "[0]                                      aten::unsafe_chunk         0.18%      62.053ms         1.90%     657.683ms      21.717us         30284  \n",
      "[0]                                                aten::ge         0.16%      56.889ms         0.16%      56.935ms       4.380ms            13  \n",
      "[0]                                  aten::sigmoid_backward         0.16%      55.184ms         0.16%      55.184ms       6.003us          9192  \n",
      "[0]       autograd::engine::evaluate_function: MulBackward0         0.15%      51.905ms         0.86%     296.045ms      32.137us          9212  \n",
      "[0]                                          aten::_to_copy         0.14%      48.686ms         0.46%     158.732ms      12.790us         12411  \n",
      "[0]                                      aten::resolve_conj         0.14%      48.588ms         0.14%      48.588ms       0.288us        168814  \n",
      "[0]                                              aten::norm         0.13%      46.600ms         0.14%      46.767ms     315.993us           148  \n",
      "[0]       autograd::engine::evaluate_function: AddBackward0         0.12%      42.246ms         0.20%      70.010ms      11.376us          6154  \n",
      "[0]                                          AddmmBackward0         0.12%      40.393ms        14.07%        4.866s       1.587ms          3066  \n",
      "[0]                                        aten::unsqueeze_         0.11%      39.505ms         0.14%      47.012ms       2.024us         23222  \n",
      "[0]                                     aten::tanh_backward         0.11%      38.494ms         0.11%      38.494ms       6.282us          6128  \n",
      "[0]                                          aten::squeeze_         0.11%      37.881ms         0.12%      39.899ms       1.718us         23220  \n",
      "[0]                                              aten::relu         0.09%      32.167ms         0.42%     146.512ms      12.617us         11612  \n",
      "[0]                                                aten::to         0.09%      30.367ms         0.54%     186.373ms       7.711us         24170  \n",
      "[0]                                     aten::empty_strided         0.09%      29.735ms         0.09%      29.735ms       2.392us         12429  \n",
      "[0]                                        SigmoidBackward0         0.08%      28.074ms         0.24%      83.258ms       9.058us          9192  \n",
      "[0]      autograd::engine::evaluate_function: TanhBackward0         0.08%      26.691ms         0.33%     112.499ms      18.358us          6128  \n",
      "[0]                                           aten::reshape         0.08%      26.482ms         0.13%      46.517ms       3.988us         11663  \n",
      "[0]                                           TanhBackward0         0.07%      25.605ms         0.19%      64.099ms      10.460us          6128  \n",
      "[0] autograd::engine::evaluate_function: SigmoidBackward...         0.07%      25.523ms         0.31%     108.781ms      11.834us          9192  \n",
      "[0]                                              aten::item         0.06%      20.037ms         0.09%      31.323ms       2.640us         11865  \n",
      "[0]                         DistributedDataParallel.forward         0.06%      19.655ms         5.25%        1.815s     907.622ms             2  \n",
      "[0] autograd::engine::evaluate_function: torch::jit::(an...         0.05%      18.685ms         0.38%     130.174ms      65.087ms             2  \n",
      "[0]        autograd::engine::evaluate_function: MmBackward0         0.05%      18.403ms         1.25%     431.293ms      17.971ms            24  \n",
      "[0]                                          aten::addcmul_         0.05%      17.705ms         0.05%      17.705ms     239.257us            74  \n",
      "[0]                                    aten::_reshape_alias         0.04%      15.524ms         0.04%      15.526ms       1.332us         11660  \n",
      "[0]                                              aten::div_         0.04%      15.226ms         0.05%      15.704ms     448.686us            35  \n",
      "[0]                                                   _RNNT         0.04%      15.031ms         0.21%      71.328ms      35.664ms             2  \n",
      "[0]                              torch_ipex::batch_norm_cpu         0.04%      14.105ms         0.05%      15.858ms       1.762ms             9  \n",
      "[0] autograd::engine::evaluate_function: torch::autograd...         0.04%      13.229ms         1.32%     456.215ms       6.165ms            74  \n",
      "[0] torch.distributed.ddp.reducer::search_unused_paramet...         0.04%      12.833ms         0.04%      12.833ms       6.417ms             2  \n",
      "[0] autograd::engine::evaluate_function: UnsafeSplitBack...         0.03%      11.933ms         0.53%     182.113ms      59.436us          3064  \n",
      "[0]                               aten::_local_scalar_dense         0.03%      11.286ms         0.03%      11.647ms       0.982us         11865  \n",
      "[0]                                           <backward op>         0.03%      10.778ms         0.32%     111.414ms      55.707ms             2  \n",
      "[0]                                    UnsafeSplitBackward0         0.03%      10.325ms         0.49%     170.180ms      55.542us          3064  \n",
      "[0]                                       aten::as_strided_         0.03%       9.525ms         0.06%      20.415ms       0.440us         46442  \n",
      "[0]                               aten::cudnn_is_acceptable         0.03%       9.000ms         0.03%       9.000ms       0.774us         11630  \n",
      "[0]                                      aten::masked_fill_         0.02%       7.637ms         0.02%       7.637ms     848.556us             9  \n",
      "[0]                                           aten::dropout         0.02%       7.532ms         0.06%      20.921ms       1.797us         11640  \n",
      "[0]                                                aten::gt         0.02%       7.229ms         0.02%       7.279ms       3.639ms             2  \n",
      "[0]                                              TBackward0         0.02%       6.562ms         0.08%      26.315ms       8.516us          3090  \n",
      "[0]                                            AddBackward0         0.01%       3.572ms         0.01%       3.572ms       0.580us          6154  \n",
      "[0]                                 aten::native_layer_norm         0.01%       2.964ms         0.01%       3.050ms     381.250us             8  \n",
      "[0]     autograd::engine::evaluate_function: StackBackward0         0.01%       2.733ms         0.04%      13.804ms     493.000us            28  \n",
      "[0] autograd::engine::evaluate_function: UnbindBackward0...         0.01%       2.697ms         0.57%     196.165ms       7.006ms            28  \n",
      "[0]                        aten::native_layer_norm_backward         0.01%       2.355ms         0.01%       3.946ms     493.250us             8  \n",
      "[0]                     torch_ipex::batch_norm_backward_cpu         0.00%       1.684ms         0.01%       1.986ms     496.500us             4  \n",
      "[0]                                          StackBackward0         0.00%       1.270ms         0.03%      10.930ms     390.357us            28  \n",
      "[0]                                             aten::zero_         0.00%       1.248ms         0.29%     100.739ms     393.512us           256  \n",
      "[0]                                    torch_ccl::broadcast         0.00%     733.000us         0.00%     733.000us     183.250us             4  \n",
      "[0] -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "[0] Self CPU time total: 34.578s\n",
      "[0] \n",
      "[0] DLL 2022-10-31 23:26:29.914734 -  | avg train utts/s     1\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258789914, \"event_type\": \"INTERVAL_END\", \"key\": \"run_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 830, \"status\": \"aborted\"}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258789915, \"event_type\": \"INTERVAL_START\", \"key\": \"eval_start\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 238, \"epoch_num\": 2}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258808913, \"event_type\": \"POINT_IN_TIME\", \"key\": \"eval_accuracy\", \"value\": 20.484347826086957, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 259, \"epoch_num\": 2}}\n",
      "[0] :::MLLOG {\"namespace\": \"\", \"time_ms\": 1667258808914, \"event_type\": \"INTERVAL_END\", \"key\": \"eval_stop\", \"value\": null, \"metadata\": {\"file\": \"/home/vmagent/app/e2eaiok/modelzoo/rnnt/pytorch/train.py\", \"lineno\": 260, \"epoch_num\": 2}}\n",
      "[0] DLL 2022-10-31 23:26:48.914943 - epoch    2 |   dev ema wer 2048.43 | took 19.00 s\n",
      "[0] Saving /home/vmagent/app/e2eaiok/result/3a43b6cbb0b39444d905130fa1a0b679/RNN-T_epoch2_checkpoint.pt...\n",
      "2022-10-31 23:27:05,976 - sigopt - INFO - Training completed based in sigopt suggestion, took 329.71129155158997 secs\n",
      "2022-10-31 23:27:05,976 - E2EAIOK.SDA - INFO - training script completed\n",
      "\n",
      "We found the best model! Here is the model explaination\n",
      "\n",
      "===============================================\n",
      "***    Best Trained Model    ***\n",
      "===============================================\n",
      "  Model Type: rnnt\n",
      "  Model Saved Path: /home/vmagent/app/e2eaiok/result/3a43b6cbb0b39444d905130fa1a0b679\n",
      "  Sigopt Experiment id is None\n",
      "  === Result Metrics ===\n",
      "    WER: 20.484347826086957\n",
      "    training_time: 329.71129155158997\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "!cd /home/vmagent/app/e2eaiok && python run_e2eaiok.py --data_path /home/vmagent/app/dataset/LibriSpeech --model_name rnnt --conf conf/e2eaiok_defaults_rnnt_example.conf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
