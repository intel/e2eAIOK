{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d1b151",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "\n",
    "# Home Page\n",
    "\n",
    "* Menu\n",
    "    * [Intro](#Architecture)\n",
    "    * [Try it!](#Try-it!)\n",
    "    * [Deep Dive](#Deep-Dive)\n",
    "\n",
    "------\n",
    "\n",
    "# ARCHITECTURE\n",
    "\n",
    "\n",
    "## Intel® End-to-End AI Optimization Kit\n",
    "Intel® End-to-End AI Optimization Kit is a composable toolkits for E2E AI optimization to deliver high performance lightweight networks/models efficiently on commodity HW. It is a pipeline framework that streamlines AI optimization technologies in each stage of E2E AI pipeline, including data processing, feature engineering, training, hyper-parameter tunning, and inference. Intel® End-to-End AI Optimization Kit delivers high performance, lightweight models efficiently on commodity hardware.\n",
    "\n",
    "![Architecture](./img/aiok_workflow.png)\n",
    "\n",
    "# Try it!\n",
    "\n",
    "* Built-in Models\n",
    "    * [DLRM](builtin/dlrm/DLRM_DEMO.ipynb) - recsys, facebook\n",
    "    * [DIEN](builtin/dien/DIEN_DEMO.ipynb) - recsys, alibaba\n",
    "    * [WnD](builtin/wnd/WND_DEMO.ipynb) - recsys, google\n",
    "    * [RNNT](builtin/rnnt/RNNT_DEMO.ipynb) - speech recognition\n",
    "    * [RESNET](builtin/resnet/RESNET_DEMO.ipynb) - computer vision\n",
    "    * [BERT](builtin/bert/BERT_DEMO.ipynb) - Natual Language Processing\n",
    "    * [MiniGO](builtin/minigo/MiniGo_DEMO.ipynb) - minimalist engine modeled after AlphaGo Zero\n",
    "\n",
    "\n",
    "# Deep Dive\n",
    "\n",
    "## The key components are:\n",
    "\n",
    "* RecDP:  A parallel data processing and feature engineering lib on top of Spark, and extensible to other data processing tools. It provides abstraction API to hide Spark programming complexity, delivers optimized performance through adaptive query plan & strategy, supports critical feature engineering functions on Tabular dataset, and can be easily integrated to third party solutions.  \n",
    "\n",
    "* Smart Democratization advisor (SDA): A user-guided tool to facilitate automation of built-in model democratization via parameterized models, it generates yaml files based on user choice, provided build-in intelligence through parameterized models and leverage SigOpt for HPO. SDA converts the manual model tuning and optimization to assisted autoML and autoHPO. SDA provides a list of build-in optimized models ranging from RecSys, CV, NLP, ASR and RL. \n",
    "\n",
    "* Neural network constructor: A neural architecture search technology based on component to build compact neural network models for specific domains directly. It is a multi-model, hardware aware, train-free neural architecture search approach to build models for CV, NLP, ASR directly and leverage transfer learning model adaptor to deploy the models in user’s production environment.\n",
    "\n",
    "## Performance Improvement\n",
    "\n",
    "![Performance](./img/Performance.jpg \"Intel® End-to-End AI Optimization Kit Performance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348b28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
