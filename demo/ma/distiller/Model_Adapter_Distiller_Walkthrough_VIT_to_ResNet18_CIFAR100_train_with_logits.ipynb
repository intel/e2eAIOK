{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhouyu5/e2eAIOK/blob/da-demo/demo/ma/distiller/Model_Adapter_Distiller_Walkthrough_VIT_to_ResNet18_CIFAR100_train_with_logits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "417eb0d3",
      "metadata": {
        "id": "417eb0d3"
      },
      "source": [
        "# Model Adapter Distiller Walkthrough DEMO - train with saved logits\n",
        "Model Adapter is a convenient framework can be used to reduce training and inference time, or data labeling cost by efficiently utilizing public advanced models and datasets. It mainly contains three components served for different cases: Finetuner, Distiller, and Domain Adapter. \n",
        "\n",
        "Distiller is based on knowledge distillation technology, it can transfer knowledge from a heavy model (teacher) to a light one (student) with different structure. However, during the distillation process, teacher forwarding usually takes a lot of time. We can use logits saving function in distiller to save predictions from teacher in adavance, then lots of time can be saved during student training. \n",
        "\n",
        "This demo mainly introduces the training of Distiller with saved logits. In last [save logits demo](./Model_Adapter_Distiller_Walkthrough_VIT_to_ResNet18_on_CIFAR100_save_logits.ipynb) we have show how to save predicting logits from VIT on CIFAR100, and here we will show how to use the saved logits to guide the training of student ResNet18.\n",
        "\n",
        "To use logits saved before for backbone training, we just need to update three steps on [previous pipeline](./Model_Adapter_Distiller_Walkthrough_VIT_to_ResNet18_CIFAR100.ipynb):\n",
        "- Wrap train_dataset with DataWrapper, set save_logits to False\n",
        "- When define Distiller, set use_saved_logits to be True\n",
        "- When epoch changes, call dataset.set_epoch(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3998935e",
      "metadata": {
        "id": "3998935e"
      },
      "source": [
        "# Content\n",
        "\n",
        "* [Model Adapter Distiller Overview](#Model-Adapter-Distller-Overview)\n",
        "* [1. Environment Setup](#1.-Environment-Setup)\n",
        "* [2. Distiller Training with saved logits](#2.-Distiller-Training-with-saved-logits)\n",
        "    * [2.1 Prepare Data](#2.1-Prepare-Data)\n",
        "    * [2.2 Create Transferrable Model](#2.2-Create-Transferrable-Model)\n",
        "    * [2.3 Train and Evaluate](#2.3-Train-and-Evaluate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faf813cc",
      "metadata": {
        "id": "faf813cc"
      },
      "source": [
        "# Model Adapter Distiller Overview\n",
        "Distiller is based on knowledge distillation technology, it can transfer knowledge from a heavy model (teacher) to a light one (student) with different structure. Teacher is a large model pretrained on specific dataset, which contains sufficient knowledge for this task, while the student model has much smaller structure. Distiller trains the student not only on the dataset, but also with the help of teacher’s knowledge. With distiller, we can take use of the knowledge from the existing pretrained large models but use much less training time. It can also significantly improve the converge speed and predicting accuracy of a small model, which is very helpful for inference.\n",
        "\n",
        "<img src=\"https://github.com/zhouyu5/e2eAIOK/blob/da-demo/demo/ma/imgs/distiller.png?raw=1\" width=\"60%\">\n",
        "<center>Model Adapter Distiller Structure</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e89f784a",
      "metadata": {
        "id": "e89f784a"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fa878e9",
      "metadata": {
        "id": "6fa878e9"
      },
      "source": [
        "### (Option 1) Use Pip install - recommend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1619aed",
      "metadata": {
        "id": "d1619aed",
        "outputId": "686c3f2f-c0ea-42bd-bea5-4e32a04cfe8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: e2eAIOK-ModelAdapter in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (1.0.1b2023031702)\n",
            "Requirement already satisfied: thop in /home/xianyang/.local/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: scikit-learn in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.24.2)\n",
            "Requirement already satisfied: easydict in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.10)\n",
            "Requirement already satisfied: torchvision==0.13.1 in /home/xianyang/.local/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.13.1)\n",
            "Requirement already satisfied: intel-extension-for-pytorch==1.12.100 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.12.100)\n",
            "Requirement already satisfied: tensorboard in /home/xianyang/.local/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (2.10.0)\n",
            "Requirement already satisfied: torchsummary in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.5.1)\n",
            "Requirement already satisfied: nnunet in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.7.0)\n",
            "Requirement already satisfied: timm in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.6.12)\n",
            "Requirement already satisfied: tllib==0.4 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.4)\n",
            "Requirement already satisfied: torchaudio==0.12.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.12.1)\n",
            "Requirement already satisfied: transformers in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (4.8.2)\n",
            "Requirement already satisfied: torch in /home/xianyang/.local/lib/python3.8/site-packages (from thop->e2eAIOK-ModelAdapter) (1.12.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /home/xianyang/.local/lib/python3.8/site-packages (from scikit-learn->e2eAIOK-ModelAdapter) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-learn->e2eAIOK-ModelAdapter) (1.6.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-learn->e2eAIOK-ModelAdapter) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-learn->e2eAIOK-ModelAdapter) (2.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from torchvision==0.13.1->e2eAIOK-ModelAdapter) (9.1.0)\n",
            "Requirement already satisfied: typing-extensions in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from torchvision==0.13.1->e2eAIOK-ModelAdapter) (3.10.0.0)\n",
            "Requirement already satisfied: requests in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from torchvision==0.13.1->e2eAIOK-ModelAdapter) (2.28.2)\n",
            "Requirement already satisfied: psutil in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from intel-extension-for-pytorch==1.12.100->e2eAIOK-ModelAdapter) (5.8.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (0.35.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (2.11.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (3.19.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (2.2.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (1.47.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (50.3.1.post20201107)\n",
            "Requirement already satisfied: scikit-image>=0.14 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.19.3)\n",
            "Requirement already satisfied: batchgenerators>=0.23 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.24)\n",
            "Requirement already satisfied: dicom2nifti in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (2.4.7)\n",
            "Requirement already satisfied: SimpleITK in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (2.2.1)\n",
            "Requirement already satisfied: medpy in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.4.0)\n",
            "Requirement already satisfied: nibabel in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (5.0.0)\n",
            "Requirement already satisfied: tifffile in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (2022.10.10)\n",
            "Requirement already satisfied: sklearn in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.0.post1)\n",
            "Requirement already satisfied: pandas in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (4.51.0)\n",
            "Requirement already satisfied: pyyaml in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from timm->e2eAIOK-ModelAdapter) (5.4.1)\n",
            "Requirement already satisfied: huggingface-hub in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from timm->e2eAIOK-ModelAdapter) (0.0.12)\n",
            "Requirement already satisfied: prettytable in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (3.6.0)\n",
            "Requirement already satisfied: numba in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (0.55.2)\n",
            "Requirement already satisfied: opencv-python in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (4.7.0.68)\n",
            "Requirement already satisfied: webcolors in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (1.12)\n",
            "Requirement already satisfied: matplotlib in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (3.5.1)\n",
            "Requirement already satisfied: packaging in /home/xianyang/.local/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (23.0)\n",
            "Requirement already satisfied: filelock in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (2021.7.6)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (0.10.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.1->e2eAIOK-ModelAdapter) (2020.6.20)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.1->e2eAIOK-ModelAdapter) (1.26.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.1->e2eAIOK-ModelAdapter) (3.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.1->e2eAIOK-ModelAdapter) (2.10)\n",
            "Requirement already satisfied: six>=1.9.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->e2eAIOK-ModelAdapter) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/xianyang/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard->e2eAIOK-ModelAdapter) (2.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard->e2eAIOK-ModelAdapter) (4.10.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-image>=0.14->nnunet->e2eAIOK-ModelAdapter) (2.24.0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: networkx>=2.2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-image>=0.14->nnunet->e2eAIOK-ModelAdapter) (3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-image>=0.14->nnunet->e2eAIOK-ModelAdapter) (1.4.1)\n",
            "Requirement already satisfied: unittest2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.1.0)\n",
            "Requirement already satisfied: future in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (0.18.3)\n",
            "Requirement already satisfied: pydicom>=2.2.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from dicom2nifti->nnunet->e2eAIOK-ModelAdapter) (2.3.1)\n",
            "Requirement already satisfied: python-gdcm in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from dicom2nifti->nnunet->e2eAIOK-ModelAdapter) (3.0.20)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from pandas->nnunet->e2eAIOK-ModelAdapter) (2021.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from pandas->nnunet->e2eAIOK-ModelAdapter) (2.8.1)\n",
            "Requirement already satisfied: wcwidth in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from prettytable->tllib==0.4->e2eAIOK-ModelAdapter) (0.2.5)\n",
            "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from numba->tllib==0.4->e2eAIOK-ModelAdapter) (0.38.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (1.4.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (4.32.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (0.11.0)\n",
            "Requirement already satisfied: click in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from sacremoses->transformers->e2eAIOK-ModelAdapter) (8.0.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->e2eAIOK-ModelAdapter) (3.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard->e2eAIOK-ModelAdapter) (3.7.0)\n",
            "Requirement already satisfied: traceback2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from unittest2->batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.4.0)\n",
            "Requirement already satisfied: argparse in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from unittest2->batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.4.0)\n",
            "Requirement already satisfied: linecache2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from traceback2->unittest2->batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install e2eAIOK-ModelAdapter --pre"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "157e3d60",
      "metadata": {
        "id": "157e3d60"
      },
      "source": [
        "### (Option 2) Use Docker \n",
        "\n",
        "Step1. prepare code\n",
        "   ``` bash\n",
        "   git clone https://github.com/intel/e2eAIOK.git\n",
        "   cd e2eAIOK\n",
        "   git submodule update --init –recursive\n",
        "   ```\n",
        "    \n",
        "Step2. build docker image\n",
        "   ``` bash\n",
        "   python3 scripts/start_e2eaiok_docker.py -b pytorch112 --dataset_path ${dataset_path} -w ${host0} ${host1} ${host2} ${host3} --proxy  \"http://addr:ip\"\n",
        "   ```\n",
        "   \n",
        "Step3. run docker and start conda env\n",
        "   ``` bash\n",
        "   sshpass -p docker ssh ${host0} -p 12347\n",
        "   conda activate pytorch-1.12.0\n",
        "   ```\n",
        "  \n",
        "Step4. Start the jupyter notebook and tensorboard service\n",
        "   ``` bash\n",
        "   nohup jupyter notebook --notebook-dir=/home/vmagent/app/e2eaiok --ip=${hostname} --port=8899 --allow-root &\n",
        "   nohup tensorboard --logdir /home/vmagent/app/data/tensorboard --host=${hostname} --port=6006 & \n",
        "   ```\n",
        "   Now you can visit demso in `http://${hostname}:8899/`, and see tensorboad log in ` http://${hostname}:6006`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48507000",
      "metadata": {
        "id": "48507000"
      },
      "source": [
        "# 2. Distiller Training with saved logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d394a5df",
      "metadata": {
        "id": "d394a5df"
      },
      "source": [
        "Import lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f878badd",
      "metadata": {
        "id": "f878badd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms,datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from timm.utils import accuracy\n",
        "import timm\n",
        "import transformers\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbcd339d",
      "metadata": {
        "id": "bbcd339d"
      },
      "source": [
        "## 2.1 Prepare Data\n",
        "### Prepare transformer and dataset\n",
        "For student, we can use original image size 32x32.\n",
        "\n",
        "Note: Data preprocessor for student and teacher can be different, but for all the process with random augmentation, they must keep same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77065ca5",
      "metadata": {
        "id": "77065ca5"
      },
      "outputs": [],
      "source": [
        "IMAGE_MEAN = [0.5, 0.5, 0.5]\n",
        "IMAGE_STD = [0.5, 0.5, 0.5]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(IMAGE_MEAN, IMAGE_STD)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(IMAGE_MEAN, IMAGE_STD)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a49f273d",
      "metadata": {
        "id": "a49f273d",
        "outputId": "b40843cc-edc2-49b9-cf34-f17c2a6fc0e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "data_folder='./data' # dataset location\n",
        "train_set = datasets.CIFAR100(root=data_folder, train=True, download=True, transform=train_transform)\n",
        "test_set = datasets.CIFAR100(root=data_folder, train=False, download=True, transform=test_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "293597d0",
      "metadata": {
        "id": "293597d0"
      },
      "source": [
        "### Warp dataset with DataWrapper\n",
        "Warp train dataset with DataWrapper, which helps to load data augmentation information and corresponding saved logits. Remember set save_logits flag to False.\n",
        "\n",
        "The logits should be saved from last [save logits demo](./Model_Adapter_Distiller_customized_ResNet50_on_CIFAR100_save_logits.ipynb), if not, you can directly download from [here](to-be-added) and put it at `logits_path`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b442080e",
      "metadata": {
        "id": "b442080e"
      },
      "outputs": [],
      "source": [
        "from e2eAIOK.ModelAdapter.engine_core.distiller.utils import logits_wrap_dataset\n",
        "logits_path = \"./data\" # path for saved logits\n",
        "train_set = logits_wrap_dataset(train_set, logits_path=logits_path, num_classes=100, save_logits=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cdeee4e",
      "metadata": {
        "id": "2cdeee4e"
      },
      "source": [
        "### Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4703b31c",
      "metadata": {
        "id": "4703b31c"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_set, batch_size=128, shuffle=True, num_workers=1, drop_last=False)\n",
        "validate_loader = DataLoader(dataset=test_set, batch_size=128, shuffle=True, num_workers=1, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9eeba42",
      "metadata": {
        "id": "f9eeba42"
      },
      "source": [
        "## 2.2 Create Transferrable Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "660678e1",
      "metadata": {
        "id": "660678e1"
      },
      "source": [
        "### Create Backbone model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b8a7d6",
      "metadata": {
        "id": "40b8a7d6"
      },
      "outputs": [],
      "source": [
        "backbone = timm.create_model('resnet18', pretrained=False, num_classes=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "485cd19c",
      "metadata": {
        "id": "485cd19c"
      },
      "source": [
        "(optional & recommend) Optimized weight initilization, can enhance initial learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9714594a",
      "metadata": {
        "id": "9714594a",
        "outputId": "38a5c6f0-4f23-4567-bf52-9b935e4d1b8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act1): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from e2eAIOK.common.trainer.model.model_utils.model_utils import initWeights\n",
        "backbone.apply(initWeights)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91d0a190",
      "metadata": {
        "id": "91d0a190"
      },
      "source": [
        "### Create teacher model\n",
        "We still need to prepare teacher model [vit_base-224-in21k-ft-cifar100 from HuggingFace](https://huggingface.co/edumunozsala/vit_base-224-in21k-ft-cifar100) for a complete Distiller definition. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "368fa749",
      "metadata": {
        "id": "368fa749"
      },
      "outputs": [],
      "source": [
        "from transformers import ViTForImageClassification\n",
        "teacher_model = ViTForImageClassification.from_pretrained('edumunozsala/vit_base-224-in21k-ft-cifar100')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "033ac27b",
      "metadata": {
        "id": "033ac27b"
      },
      "source": [
        "### Define Distiller\n",
        "Here we define a distiller using KD algorithm, and it take a teacher model as input.\n",
        "\n",
        "If teacher comes from Hugginface, please clarify \"teacher_type\" with a name starting with \"huggingface\", otherwise no need.\n",
        "\n",
        "Set use_saved_logits to be True when we want to load logits saved before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd31b80f",
      "metadata": {
        "id": "dd31b80f"
      },
      "outputs": [],
      "source": [
        "from e2eAIOK.ModelAdapter.engine_core.distiller import KD\n",
        "distiller= KD(teacher_model, use_saved_logits=True,teacher_type=\"huggingface_vit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bf6e4c5",
      "metadata": {
        "id": "5bf6e4c5"
      },
      "source": [
        "### Make Model transferrable with distiller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6456289e",
      "metadata": {
        "id": "6456289e"
      },
      "outputs": [],
      "source": [
        "from e2eAIOK.ModelAdapter.engine_core.transferrable_model import *\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "model = make_transferrable_with_knowledge_distillation(backbone,loss_fn,distiller)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f79311e",
      "metadata": {
        "id": "3f79311e"
      },
      "source": [
        "## 2.3 Train and Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa226f93",
      "metadata": {
        "id": "aa226f93"
      },
      "source": [
        "### create optimizer and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c9561a5",
      "metadata": {
        "id": "5c9561a5"
      },
      "outputs": [],
      "source": [
        "################# create optimizer #################\n",
        "init_lr = 0.01\n",
        "weight_decay = 0.005\n",
        "momentum = 0.9\n",
        "optimizer = optim.SGD(model.parameters(),lr=init_lr, weight_decay=weight_decay,momentum=momentum)\n",
        "################# create scheduler #################\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e633199",
      "metadata": {
        "id": "4e633199"
      },
      "source": [
        "### Create Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f73dfa",
      "metadata": {
        "id": "e4f73dfa"
      },
      "outputs": [],
      "source": [
        "max_epoch = 1 # max 1 epoch\n",
        "print_interval = 10 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "874fb6b2",
      "metadata": {
        "id": "874fb6b2"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, scheduler):\n",
        "        self._model = model\n",
        "        self._optimizer = optimizer\n",
        "        self._scheduler = scheduler\n",
        "        \n",
        "    def train(self, train_dataloader, valid_dataloader, max_epoch):\n",
        "        ''' \n",
        "        :param train_dataloader: train dataloader\n",
        "        :param valid_dataloader: validation dataloader\n",
        "        :param max_epoch: steps per epoch\n",
        "        '''\n",
        "        for epoch in range(0, max_epoch):\n",
        "            train_dataloader.dataset.set_epoch(epoch) # Update epoch for dataset\n",
        "            ################## train #####################\n",
        "            self._model.train()  # set training flag\n",
        "            for (cur_step,(data, label)) in enumerate(train_dataloader):\n",
        "                self._optimizer.zero_grad()\n",
        "                output = self._model(data)\n",
        "                loss_value = self._model.loss(output, label) # transferrable model has loss attribute\n",
        "                loss_value.backward() \n",
        "                if cur_step%print_interval == 0:\n",
        "                    batch_acc = accuracy(output.backbone_output,label)[0] # use output.backbone_output instead of output\n",
        "                    dt = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') # date time\n",
        "                    print(\"[{}] epoch {} step {} : total loss {:4f}, training backbone loss {:.4f}, distiller loss {:4f}, training batch acc {:.4f}\".format(\n",
        "                      dt, epoch, cur_step, loss_value.total_loss.item(),loss_value.backbone_loss.item(), loss_value.distiller_loss.item(), batch_acc.item())) \n",
        "                self._optimizer.step()\n",
        "            self._scheduler.step()\n",
        "            ################## evaluate ######################\n",
        "            self.evaluate(valid_dataloader)\n",
        "            \n",
        "    def evaluate(self, valid_dataloader):\n",
        "        with torch.no_grad():\n",
        "            self._model.eval()  \n",
        "            backbone = self._model.backbone # use backbone in evaluation\n",
        "            loss_cum = 0.0\n",
        "            sample_num = 0\n",
        "            acc_cum = 0.0\n",
        "            total_step = len(valid_dataloader)\n",
        "            for (cur_step,(data, label)) in enumerate(valid_dataloader):\n",
        "                output = backbone(data)\n",
        "                batch_size = data.size(0)\n",
        "                sample_num += batch_size\n",
        "                loss_cum += loss_fn(output, label).item() * batch_size\n",
        "                acc_cum += accuracy(output, label)[0].item() * batch_size\n",
        "                if cur_step%print_interval == 0:\n",
        "                    print(f\"step {cur_step}/{total_step}\")\n",
        "            dt = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') # date time\n",
        "            loss_value = loss_cum/sample_num\n",
        "            acc_value = acc_cum/sample_num\n",
        "\n",
        "            print(\"[{}] evaluation loss {:.4f}, evaluation acc {:.4f}\".format(\n",
        "                dt, loss_value, acc_value))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad7615c",
      "metadata": {
        "id": "6ad7615c"
      },
      "source": [
        "## Train and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bae383b6",
      "metadata": {
        "id": "bae383b6",
        "outputId": "137e82d1-eb16-4032-c7b0-b797461b7347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-02-13 07:29:34] epoch 0 step 0 : total loss 3.773066, training backbone loss 6.0263, distiller loss 3.522707, training batch acc 0.7812\n",
            "[2023-02-13 07:29:35] epoch 0 step 10 : total loss 2.993048, training backbone loss 5.2592, distiller loss 2.741256, training batch acc 1.5625\n",
            "[2023-02-13 07:29:36] epoch 0 step 20 : total loss 2.633675, training backbone loss 4.6729, distiller loss 2.407095, training batch acc 3.1250\n",
            "[2023-02-13 07:29:37] epoch 0 step 30 : total loss 2.505098, training backbone loss 4.5768, distiller loss 2.274914, training batch acc 3.9062\n",
            "[2023-02-13 07:29:38] epoch 0 step 40 : total loss 2.404030, training backbone loss 4.4975, distiller loss 2.171418, training batch acc 2.3438\n",
            "[2023-02-13 07:29:38] epoch 0 step 50 : total loss 2.420904, training backbone loss 4.4462, distiller loss 2.195874, training batch acc 3.1250\n",
            "[2023-02-13 07:29:39] epoch 0 step 60 : total loss 2.248125, training backbone loss 4.3429, distiller loss 2.015368, training batch acc 3.9062\n",
            "[2023-02-13 07:29:40] epoch 0 step 70 : total loss 2.321840, training backbone loss 4.2973, distiller loss 2.102342, training batch acc 4.6875\n",
            "[2023-02-13 07:29:41] epoch 0 step 80 : total loss 2.230834, training backbone loss 4.2331, distiller loss 2.008360, training batch acc 8.5938\n",
            "[2023-02-13 07:29:41] epoch 0 step 90 : total loss 2.253711, training backbone loss 4.2742, distiller loss 2.029218, training batch acc 4.6875\n",
            "[2023-02-13 07:29:42] epoch 0 step 100 : total loss 2.296232, training backbone loss 4.2674, distiller loss 2.077210, training batch acc 3.1250\n",
            "[2023-02-13 07:29:43] epoch 0 step 110 : total loss 2.214659, training backbone loss 4.1841, distiller loss 1.995834, training batch acc 10.9375\n",
            "[2023-02-13 07:29:44] epoch 0 step 120 : total loss 2.167941, training backbone loss 4.0522, distiller loss 1.958576, training batch acc 11.7188\n",
            "[2023-02-13 07:29:44] epoch 0 step 130 : total loss 2.177191, training backbone loss 4.1369, distiller loss 1.959448, training batch acc 4.6875\n",
            "[2023-02-13 07:29:45] epoch 0 step 140 : total loss 2.197548, training backbone loss 4.0600, distiller loss 1.990607, training batch acc 8.5938\n",
            "[2023-02-13 07:29:46] epoch 0 step 150 : total loss 2.251618, training backbone loss 4.1912, distiller loss 2.036113, training batch acc 4.6875\n",
            "[2023-02-13 07:29:47] epoch 0 step 160 : total loss 2.231474, training backbone loss 4.0895, distiller loss 2.025022, training batch acc 13.2812\n",
            "[2023-02-13 07:29:47] epoch 0 step 170 : total loss 2.095718, training backbone loss 3.9709, distiller loss 1.887363, training batch acc 10.1562\n",
            "[2023-02-13 07:29:48] epoch 0 step 180 : total loss 2.155930, training backbone loss 3.9719, distiller loss 1.954157, training batch acc 7.8125\n",
            "[2023-02-13 07:29:49] epoch 0 step 190 : total loss 2.189214, training backbone loss 4.0060, distiller loss 1.987350, training batch acc 10.1562\n",
            "[2023-02-13 07:29:50] epoch 0 step 200 : total loss 2.172372, training backbone loss 3.9340, distiller loss 1.976635, training batch acc 9.3750\n",
            "[2023-02-13 07:29:50] epoch 0 step 210 : total loss 2.141020, training backbone loss 3.8878, distiller loss 1.946929, training batch acc 15.6250\n",
            "[2023-02-13 07:29:51] epoch 0 step 220 : total loss 2.179835, training backbone loss 4.0104, distiller loss 1.976435, training batch acc 7.8125\n",
            "[2023-02-13 07:29:52] epoch 0 step 230 : total loss 2.227055, training backbone loss 4.0528, distiller loss 2.024195, training batch acc 10.1562\n",
            "[2023-02-13 07:29:53] epoch 0 step 240 : total loss 2.151903, training backbone loss 3.8811, distiller loss 1.959773, training batch acc 14.0625\n",
            "[2023-02-13 07:29:53] epoch 0 step 250 : total loss 2.125401, training backbone loss 3.8856, distiller loss 1.929823, training batch acc 16.4062\n",
            "[2023-02-13 07:29:54] epoch 0 step 260 : total loss 2.066773, training backbone loss 3.7483, distiller loss 1.879933, training batch acc 13.2812\n",
            "[2023-02-13 07:29:55] epoch 0 step 270 : total loss 2.069456, training backbone loss 3.7478, distiller loss 1.882975, training batch acc 10.9375\n",
            "[2023-02-13 07:29:56] epoch 0 step 280 : total loss 2.054992, training backbone loss 3.7233, distiller loss 1.869629, training batch acc 16.4062\n",
            "[2023-02-13 07:29:56] epoch 0 step 290 : total loss 2.121195, training backbone loss 3.8075, distiller loss 1.933833, training batch acc 14.8438\n",
            "[2023-02-13 07:29:57] epoch 0 step 300 : total loss 2.103102, training backbone loss 3.7902, distiller loss 1.915648, training batch acc 13.2812\n",
            "[2023-02-13 07:29:58] epoch 0 step 310 : total loss 2.122793, training backbone loss 3.9142, distiller loss 1.923751, training batch acc 13.2812\n",
            "[2023-02-13 07:29:59] epoch 0 step 320 : total loss 2.121093, training backbone loss 3.8971, distiller loss 1.923754, training batch acc 10.9375\n",
            "[2023-02-13 07:29:59] epoch 0 step 330 : total loss 2.174914, training backbone loss 4.0120, distiller loss 1.970794, training batch acc 7.8125\n",
            "[2023-02-13 07:30:00] epoch 0 step 340 : total loss 2.127625, training backbone loss 3.8402, distiller loss 1.937343, training batch acc 10.9375\n",
            "[2023-02-13 07:30:01] epoch 0 step 350 : total loss 2.126092, training backbone loss 3.9243, distiller loss 1.926293, training batch acc 12.5000\n",
            "[2023-02-13 07:30:02] epoch 0 step 360 : total loss 2.122418, training backbone loss 3.9176, distiller loss 1.922956, training batch acc 10.9375\n",
            "[2023-02-13 07:30:02] epoch 0 step 370 : total loss 2.045721, training backbone loss 3.7792, distiller loss 1.853114, training batch acc 15.6250\n",
            "[2023-02-13 07:30:03] epoch 0 step 380 : total loss 2.096254, training backbone loss 3.8772, distiller loss 1.898376, training batch acc 10.1562\n",
            "[2023-02-13 07:30:04] epoch 0 step 390 : total loss 2.134264, training backbone loss 3.8453, distiller loss 1.944148, training batch acc 7.5000\n",
            "step 0/79\n",
            "step 10/79\n",
            "step 20/79\n",
            "step 30/79\n",
            "step 40/79\n",
            "step 50/79\n",
            "step 60/79\n",
            "step 70/79\n",
            "[2023-02-13 07:30:07] evaluation loss 3.8046, evaluation acc 15.0300\n",
            "CPU times: user 23min 58s, sys: 1min 8s, total: 25min 6s\n",
            "Wall time: 34 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "trainer = Trainer(model, optimizer, scheduler)\n",
        "trainer.train(train_loader,validate_loader,max_epoch)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}