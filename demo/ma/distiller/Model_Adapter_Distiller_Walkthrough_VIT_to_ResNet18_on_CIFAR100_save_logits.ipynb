{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhouyu5/e2eAIOK/blob/da-demo/demo/ma/distiller/Model_Adapter_Distiller_Walkthrough_VIT_to_ResNet18_on_CIFAR100_save_logits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eea0224",
      "metadata": {
        "id": "1eea0224"
      },
      "source": [
        "# Model Adapter Distiller Walkthrough DEMO - Save logits\n",
        "Model Adapter is a convenient framework can be used to reduce training and inference time, or data labeling cost by efficiently utilizing public advanced models and datasets. It mainly contains three components served for different cases: Finetuner, Distiller, and Domain Adapter. \n",
        "\n",
        "Distiller is based on knowledge distillation technology, it can transfer knowledge from a heavy model (teacher) to a light one (student) with different structure. However, during the distillation process, teacher forwarding usually takes a lot of time. We can use logits saving function in distiller to save predictions from teacher in adavance, then lots of time can be saved during student training. \n",
        "\n",
        "This demo mainly introduces the usage of Distiller saving logits function. Take image classification as an example, it shows how to use distiller to save logits from VIT pretrained model, which will be used to guide the learning of ResNet18 in next [demo](./Model_Adapter_Distiller_Walkthrough_VIT_to_ResNet18_CIFAR100_train_with_logits.ipynb).\n",
        "\n",
        "To enable saving logits function, we just need to add two steps in original pipeline:\n",
        "- Wrap train_dataset with DataWrapper\n",
        "- Call prepare_logits() in Distiller"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8eb236d1",
      "metadata": {
        "id": "8eb236d1"
      },
      "source": [
        "# Content\n",
        "\n",
        "* [Model Adapter Distiller Overview](#Model-Adapter-Distller-Overview)\n",
        "* [1. Environment Setup](#1.-Environment-Setup)\n",
        "* [2. Save Logits with Distiller](#2.-Save-Logits-with-Distiller)\n",
        "    * [2.1 Prepare Data](#2.1-Prepare-Data)\n",
        "    * [2.2 Create Distiller](#2.2-Create-Distiller)\n",
        "    * [2.3 Save Logits](#2.3-Save-Logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e0a0a46",
      "metadata": {
        "id": "5e0a0a46"
      },
      "source": [
        "# Model Adapter Distiller Overview\n",
        "Distiller is based on knowledge distillation technology, it can transfer knowledge from a heavy model (teacher) to a light one (student) with different structure. Teacher is a large model pretrained on specific dataset, which contains sufficient knowledge for this task, while the student model has much smaller structure. Distiller trains the student not only on the dataset, but also with the help of teacher’s knowledge. With distiller, we can take use of the knowledge from the existing pretrained large models but use much less training time. It can also significantly improve the converge speed and predicting accuracy of a small model, which is very helpful for inference.\n",
        "\n",
        "<img src=\"https://github.com/zhouyu5/e2eAIOK/blob/da-demo/demo/ma/imgs/distiller.png?raw=1\" width=\"60%\">\n",
        "<center>Model Adapter Distiller Structure</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5aeb716",
      "metadata": {
        "id": "d5aeb716"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95665de7",
      "metadata": {
        "id": "95665de7"
      },
      "source": [
        "### (Option 1) Use Pip install - recommend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9591f051",
      "metadata": {
        "id": "9591f051",
        "outputId": "8bccc955-9bce-4d25-a808-1daef3391232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: e2eAIOK-ModelAdapter in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (1.0.1b2023031702)\n",
            "Requirement already satisfied: torchsummary in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.5.1)\n",
            "Requirement already satisfied: thop in /home/xianyang/.local/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torchaudio==0.12.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.12.1)\n",
            "Requirement already satisfied: torchvision==0.13.1 in /home/xianyang/.local/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.13.1)\n",
            "Requirement already satisfied: intel-extension-for-pytorch==1.12.100 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.12.100)\n",
            "Requirement already satisfied: nnunet in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.7.0)\n",
            "Requirement already satisfied: transformers in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (4.8.2)\n",
            "Requirement already satisfied: scikit-learn in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.24.2)\n",
            "Requirement already satisfied: timm in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.6.12)\n",
            "Requirement already satisfied: tensorboard in /home/xianyang/.local/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (2.10.0)\n",
            "Requirement already satisfied: easydict in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.10)\n",
            "Requirement already satisfied: tllib==0.4 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.4)\n",
            "Requirement already satisfied: torch in /home/xianyang/.local/lib/python3.8/site-packages (from thop->e2eAIOK-ModelAdapter) (1.12.1)\n",
            "Requirement already satisfied: numpy in /home/xianyang/.local/lib/python3.8/site-packages (from torchvision==0.13.1->e2eAIOK-ModelAdapter) (1.22.4)\n",
            "Requirement already satisfied: requests in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from torchvision==0.13.1->e2eAIOK-ModelAdapter) (2.28.2)\n",
            "Requirement already satisfied: typing-extensions in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from torchvision==0.13.1->e2eAIOK-ModelAdapter) (3.10.0.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from torchvision==0.13.1->e2eAIOK-ModelAdapter) (9.1.0)\n",
            "Requirement already satisfied: psutil in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from intel-extension-for-pytorch==1.12.100->e2eAIOK-ModelAdapter) (5.8.0)\n",
            "Requirement already satisfied: sklearn in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.0.post1)\n",
            "Requirement already satisfied: medpy in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.4.0)\n",
            "Requirement already satisfied: tifffile in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (2022.10.10)\n",
            "Requirement already satisfied: scikit-image>=0.14 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.19.3)\n",
            "Requirement already satisfied: SimpleITK in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (2.2.1)\n",
            "Requirement already satisfied: batchgenerators>=0.23 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.24)\n",
            "Requirement already satisfied: nibabel in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (5.0.0)\n",
            "Requirement already satisfied: pandas in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (4.51.0)\n",
            "Requirement already satisfied: dicom2nifti in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (2.4.7)\n",
            "Requirement already satisfied: scipy in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (1.6.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (0.10.3)\n",
            "Requirement already satisfied: packaging in /home/xianyang/.local/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (23.0)\n",
            "Requirement already satisfied: sacremoses in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (2021.7.6)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (0.0.12)\n",
            "Requirement already satisfied: pyyaml in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (5.4.1)\n",
            "Requirement already satisfied: filelock in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (3.0.12)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-learn->e2eAIOK-ModelAdapter) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-learn->e2eAIOK-ModelAdapter) (1.0.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (3.19.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (2.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (0.35.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (2.11.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (50.3.1.post20201107)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (3.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (1.47.0)\n",
            "Requirement already satisfied: prettytable in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (3.6.0)\n",
            "Requirement already satisfied: opencv-python in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (4.7.0.68)\n",
            "Requirement already satisfied: numba in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (0.55.2)\n",
            "Requirement already satisfied: matplotlib in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (3.5.1)\n",
            "Requirement already satisfied: webcolors in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (1.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.1->e2eAIOK-ModelAdapter) (1.26.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.1->e2eAIOK-ModelAdapter) (3.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.1->e2eAIOK-ModelAdapter) (2020.6.20)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.1->e2eAIOK-ModelAdapter) (2.10)\n",
            "Requirement already satisfied: networkx>=2.2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-image>=0.14->nnunet->e2eAIOK-ModelAdapter) (3.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-image>=0.14->nnunet->e2eAIOK-ModelAdapter) (2.24.0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyWavelets>=1.1.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-image>=0.14->nnunet->e2eAIOK-ModelAdapter) (1.4.1)\n",
            "Requirement already satisfied: future in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (0.18.3)\n",
            "Requirement already satisfied: unittest2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from pandas->nnunet->e2eAIOK-ModelAdapter) (2021.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from pandas->nnunet->e2eAIOK-ModelAdapter) (2.8.1)\n",
            "Requirement already satisfied: pydicom>=2.2.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from dicom2nifti->nnunet->e2eAIOK-ModelAdapter) (2.3.1)\n",
            "Requirement already satisfied: python-gdcm in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from dicom2nifti->nnunet->e2eAIOK-ModelAdapter) (3.0.20)\n",
            "Requirement already satisfied: click in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from sacremoses->transformers->e2eAIOK-ModelAdapter) (8.0.1)\n",
            "Requirement already satisfied: six in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from sacremoses->transformers->e2eAIOK-ModelAdapter) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/xianyang/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard->e2eAIOK-ModelAdapter) (2.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->e2eAIOK-ModelAdapter) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard->e2eAIOK-ModelAdapter) (4.10.1)\n",
            "Requirement already satisfied: wcwidth in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from prettytable->tllib==0.4->e2eAIOK-ModelAdapter) (0.2.5)\n",
            "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from numba->tllib==0.4->e2eAIOK-ModelAdapter) (0.38.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (1.4.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (4.32.0)\n",
            "Requirement already satisfied: traceback2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from unittest2->batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.4.0)\n",
            "Requirement already satisfied: argparse in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from unittest2->batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->e2eAIOK-ModelAdapter) (3.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard->e2eAIOK-ModelAdapter) (3.7.0)\n",
            "Requirement already satisfied: linecache2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from traceback2->unittest2->batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install e2eAIOK-ModelAdapter --pre"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88d51987",
      "metadata": {
        "id": "88d51987"
      },
      "source": [
        "### (Option 2) Use Docker \n",
        "\n",
        "Step1. prepare code\n",
        "   ``` bash\n",
        "   git clone https://github.com/intel/e2eAIOK.git\n",
        "   cd e2eAIOK\n",
        "   git submodule update --init –recursive\n",
        "   ```\n",
        "    \n",
        "Step2. build docker image\n",
        "   ``` bash\n",
        "   python3 scripts/start_e2eaiok_docker.py -b pytorch112 --dataset_path ${dataset_path} -w ${host0} ${host1} ${host2} ${host3} --proxy  \"http://addr:ip\"\n",
        "   ```\n",
        "   \n",
        "Step3. run docker and start conda env\n",
        "   ``` bash\n",
        "   sshpass -p docker ssh ${host0} -p 12347\n",
        "   conda activate pytorch-1.12.0\n",
        "   ```\n",
        "  \n",
        "Step4. Start the jupyter notebook and tensorboard service\n",
        "   ``` bash\n",
        "   nohup jupyter notebook --notebook-dir=/home/vmagent/app/e2eaiok --ip=${hostname} --port=8899 --allow-root &\n",
        "   nohup tensorboard --logdir /home/vmagent/app/data/tensorboard --host=${hostname} --port=6006 & \n",
        "   ```\n",
        "   Now you can visit demso in `http://${hostname}:8899/`, and see tensorboad log in ` http://${hostname}:6006`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a4ce35d",
      "metadata": {
        "id": "6a4ce35d"
      },
      "source": [
        "# 2. Save Logits with Distiller"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e11c2e32",
      "metadata": {
        "id": "e11c2e32"
      },
      "source": [
        "Import lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f878badd",
      "metadata": {
        "id": "f878badd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms,datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n",
        "import sys,os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec28cbf4",
      "metadata": {
        "id": "ec28cbf4"
      },
      "source": [
        "## 2.1 Prepare Data\n",
        "### Prepare transformer and dataset\n",
        "For teacher, as pretrained model is trained on large imgage size, scale 32\\*32 to 224\\*224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c016312d",
      "metadata": {
        "id": "c016312d"
      },
      "outputs": [],
      "source": [
        "IMAGE_MEAN = [0.5, 0.5, 0.5]\n",
        "IMAGE_STD = [0.5, 0.5, 0.5]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.Resize(224),  # pretrained model is trained on large imgage size, scale 32x32 to 224x224\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(IMAGE_MEAN, IMAGE_STD)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69896736",
      "metadata": {
        "id": "69896736",
        "outputId": "ff7da157-91b3-433d-8038-784638508b09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "data_folder='./data' # dataset location\n",
        "train_set = datasets.CIFAR100(root=data_folder, train=True, download=True, transform=train_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e6ccda0",
      "metadata": {
        "id": "5e6ccda0"
      },
      "source": [
        "### Warp dataset with DataWrapper\n",
        "Warp train dataset with DataWrapper, which helps to save data augmentation information during the forwarding of teacher model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b46a046",
      "metadata": {
        "id": "2b46a046"
      },
      "outputs": [],
      "source": [
        "from e2eAIOK.ModelAdapter.engine_core.distiller.utils import logits_wrap_dataset\n",
        "logits_path = \"./data\" # path to save the logits\n",
        "train_set = logits_wrap_dataset(train_set, logits_path=logits_path, num_classes=100, save_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3210a1e2",
      "metadata": {
        "id": "3210a1e2"
      },
      "source": [
        "### Create dataloader\n",
        "\n",
        "Note: We need to save all the data without any sampling, make sure you have disable \"channel_last\" or \"sampler\" in dataloader, which can avoid data lossing in later logits using process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "232dee55",
      "metadata": {
        "id": "232dee55"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_set, batch_size=128, shuffle=True, num_workers=1, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbc18f19",
      "metadata": {
        "id": "bbc18f19"
      },
      "source": [
        "## 2.2 Create Distiller"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c25ac60a",
      "metadata": {
        "id": "c25ac60a"
      },
      "source": [
        "### Prepare teacher model\n",
        "To use distiller, we need to prepare teacher model to guide the training. Here we select pretrained [vit_base-224-in21k-ft-cifar100 from HuggingFace](https://huggingface.co/edumunozsala/vit_base-224-in21k-ft-cifar100)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93b99862",
      "metadata": {
        "id": "93b99862"
      },
      "outputs": [],
      "source": [
        "from transformers import ViTForImageClassification\n",
        "teacher_model = ViTForImageClassification.from_pretrained('edumunozsala/vit_base-224-in21k-ft-cifar100')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "481901ed",
      "metadata": {
        "id": "481901ed"
      },
      "source": [
        "### Create Distiller with KD type\n",
        "### Define Distiller\n",
        "Here we define a distiller using KD algorithm, and it take a teacher model as input. If teacher comes from Hugginface, please clarify \"teacher_type\" with a name starting with \"huggingface\", otherwise no need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d750e1d6",
      "metadata": {
        "id": "d750e1d6"
      },
      "outputs": [],
      "source": [
        "from e2eAIOK.ModelAdapter.engine_core.distiller import KD\n",
        "distiller= KD(teacher_model,teacher_type=\"huggingface_vit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "120f1c55",
      "metadata": {
        "id": "120f1c55"
      },
      "source": [
        "## 2.3 Save Logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b9cedb3",
      "metadata": {
        "id": "7b9cedb3"
      },
      "source": [
        "Call prepare_logits() of distiller to save the logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15548288",
      "metadata": {
        "id": "15548288",
        "outputId": "b7f9b630-3e05-49cf-970c-a67e9fd59832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-02-13 06:48:11 save 0/391\n",
            "2023-02-13 06:49:03 save 10/391\n",
            "2023-02-13 06:49:55 save 20/391\n",
            "2023-02-13 06:50:47 save 30/391\n",
            "2023-02-13 06:51:40 save 40/391\n",
            "2023-02-13 06:52:31 save 50/391\n",
            "2023-02-13 06:53:24 save 60/391\n",
            "2023-02-13 06:54:15 save 70/391\n",
            "2023-02-13 06:55:05 save 80/391\n",
            "2023-02-13 06:55:56 save 90/391\n",
            "2023-02-13 06:56:47 save 100/391\n",
            "2023-02-13 06:57:39 save 110/391\n",
            "2023-02-13 06:58:29 save 120/391\n",
            "2023-02-13 06:59:20 save 130/391\n",
            "2023-02-13 07:00:11 save 140/391\n",
            "2023-02-13 07:01:02 save 150/391\n",
            "2023-02-13 07:01:52 save 160/391\n",
            "2023-02-13 07:02:44 save 170/391\n",
            "2023-02-13 07:03:36 save 180/391\n",
            "2023-02-13 07:04:27 save 190/391\n",
            "2023-02-13 07:05:17 save 200/391\n",
            "2023-02-13 07:06:08 save 210/391\n",
            "2023-02-13 07:06:59 save 220/391\n",
            "2023-02-13 07:07:48 save 230/391\n",
            "2023-02-13 07:08:38 save 240/391\n",
            "2023-02-13 07:09:31 save 250/391\n",
            "2023-02-13 07:10:22 save 260/391\n",
            "2023-02-13 07:11:13 save 270/391\n",
            "2023-02-13 07:12:03 save 280/391\n",
            "2023-02-13 07:12:54 save 290/391\n",
            "2023-02-13 07:13:46 save 300/391\n",
            "2023-02-13 07:14:39 save 310/391\n",
            "2023-02-13 07:15:30 save 320/391\n",
            "2023-02-13 07:16:20 save 330/391\n",
            "2023-02-13 07:17:10 save 340/391\n",
            "2023-02-13 07:18:00 save 350/391\n",
            "2023-02-13 07:18:53 save 360/391\n",
            "2023-02-13 07:19:44 save 370/391\n",
            "2023-02-13 07:20:36 save 380/391\n",
            "2023-02-13 07:21:27 save 390/391\n",
            "Epoch 0 took 2001.7463374137878 seconds\n"
          ]
        }
      ],
      "source": [
        "distiller.prepare_logits(train_loader, epochs=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}