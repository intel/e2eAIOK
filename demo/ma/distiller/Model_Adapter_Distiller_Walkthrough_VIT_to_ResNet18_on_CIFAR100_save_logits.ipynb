{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0dae1af",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/e2eAIOK/blob/main/demo/ma/distiller/Model_Adapter_Distiller_Walkthrough_VIT_to_ResNet18_on_CIFAR100_save_logits.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea0224",
   "metadata": {
    "id": "1eea0224"
   },
   "source": [
    "# Model Adapter Distiller Walkthrough DEMO - Save logits\n",
    "Model Adapter is a convenient framework can be used to reduce training and inference time, or data labeling cost by efficiently utilizing public advanced models and datasets. It mainly contains three components served for different cases: Finetuner, Distiller, and Domain Adapter. \n",
    "\n",
    "Distiller is based on knowledge distillation technology, it can transfer knowledge from a heavy model (teacher) to a light one (student) with different structure. However, during the distillation process, teacher forwarding usually takes a lot of time. We can use logits saving function in distiller to save predictions from teacher in adavance, then lots of time can be saved during student training. \n",
    "\n",
    "This demo mainly introduces the usage of Distiller saving logits function. Take image classification as an example, it shows how to use distiller to save logits from VIT pretrained model, which will be used to guide the learning of ResNet18 in next [demo](./Model_Adapter_Distiller_Walkthrough_VIT_to_ResNet18_CIFAR100_train_with_logits.ipynb).\n",
    "\n",
    "To enable saving logits function, we just need to add two steps in original pipeline:\n",
    "- Wrap train_dataset with DataWrapper\n",
    "- Call prepare_logits() in Distiller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb236d1",
   "metadata": {
    "id": "8eb236d1"
   },
   "source": [
    "  \n",
    "# Content\n",
    "\n",
    "* [Overview](#Overview)\n",
    "    * [Model Adapter Distiller Overview](#Model-Adapter-Distiller-Overview)\n",
    "* [Getting Started](#Getting-Started)\n",
    "    * [1. Environment Setup](#1.-Environment-Setup)\n",
    "    * [2. Data Prepare](#2.-Data-Prepare)\n",
    "    * [3. Model Prepare](#3.-Model-Prepare)\n",
    "    * [4. Save Logits](#4.-Save-Logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a0a46",
   "metadata": {
    "id": "5e0a0a46"
   },
   "source": [
    "# Overview\n",
    "\n",
    "## Model Adapter Distiller Overview\n",
    "Distiller is based on knowledge distillation technology, it can transfer knowledge from a heavy model (teacher) to a light one (student) with different structure. Teacher is a large model pretrained on specific dataset, which contains sufficient knowledge for this task, while the student model has much smaller structure. Distiller trains the student not only on the dataset, but also with the help of teacher’s knowledge. With distiller, we can take use of the knowledge from the existing pretrained large models but use much less training time. It can also significantly improve the converge speed and predicting accuracy of a small model, which is very helpful for inference.\n",
    "\n",
    "<img src=\"../imgs/distiller.png\" width=\"60%\">\n",
    "<center>Model Adapter Distiller Structure</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc21d7",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aeb716",
   "metadata": {
    "id": "d5aeb716"
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95665de7",
   "metadata": {
    "id": "95665de7"
   },
   "source": [
    "### (Option 1) Use Pip install\n",
    "We can directly install ModelAdapter module from Intel® End-to-End AI Optimization Kit with following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9591f051",
   "metadata": {
    "id": "9591f051",
    "outputId": "8bccc955-9bce-4d25-a808-1daef3391232"
   },
   "outputs": [],
   "source": [
    "!pip install e2eAIOK-ModelAdapter --pre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d51987",
   "metadata": {
    "id": "88d51987"
   },
   "source": [
    "### (Option 2) Use Docker \n",
    "\n",
    "We can also use Docker, which contains a complete environment.\n",
    "\n",
    "Step1. prepare code\n",
    "   ``` bash\n",
    "   git clone https://github.com/intel/e2eAIOK.git\n",
    "   cd e2eAIOK\n",
    "   git submodule update --init –recursive\n",
    "   ```\n",
    "    \n",
    "Step2. build docker image\n",
    "   ``` bash\n",
    "   python3 scripts/start_e2eaiok_docker.py -b pytorch112 --dataset_path ${dataset_path} -w ${host0} ${host1} ${host2} ${host3} --proxy  \"http://addr:ip\"\n",
    "   ```\n",
    "   \n",
    "Step3. run docker and start conda env\n",
    "   ``` bash\n",
    "   sshpass -p docker ssh ${host0} -p 12347\n",
    "   conda activate pytorch-1.12.0\n",
    "   ```\n",
    "  \n",
    "Step4. Start the jupyter notebook and tensorboard service\n",
    "   ``` bash\n",
    "   nohup jupyter notebook --notebook-dir=/home/vmagent/app/e2eaiok --ip=${hostname} --port=8899 --allow-root &\n",
    "   nohup tensorboard --logdir /home/vmagent/app/data/tensorboard --host=${hostname} --port=6006 & \n",
    "   ```\n",
    "   Now you can visit demso in `http://${hostname}:8899/`, and see tensorboad log in ` http://${hostname}:6006`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec28cbf4",
   "metadata": {
    "id": "ec28cbf4"
   },
   "source": [
    "## 2. Data Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3272879a",
   "metadata": {},
   "source": [
    "Let's import some required modules. We will use ResNet from Timm lib in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878badd",
   "metadata": {
    "id": "f878badd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms,datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "import sys,os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f38bb",
   "metadata": {},
   "source": [
    "First let's define transformer for dataset, which will be needed to augment input image. \n",
    "\n",
    "For teacher, as pretrained model is trained on large imgage size, scale 32\\*32 to 224\\*224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016312d",
   "metadata": {
    "id": "c016312d"
   },
   "outputs": [],
   "source": [
    "IMAGE_MEAN = [0.5, 0.5, 0.5]\n",
    "IMAGE_STD = [0.5, 0.5, 0.5]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "  transforms.RandomCrop(32, padding=4),\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.Resize(224),  # pretrained model is trained on large imgage size, scale 32x32 to 224x224\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(IMAGE_MEAN, IMAGE_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487220ef",
   "metadata": {},
   "source": [
    "Then let's define CIFAR100 dataset and download it with torchvision lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69896736",
   "metadata": {
    "id": "69896736",
    "outputId": "ff7da157-91b3-433d-8038-784638508b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_folder='./data' # dataset location\n",
    "train_set = datasets.CIFAR100(root=data_folder, train=True, download=True, transform=train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ccda0",
   "metadata": {
    "id": "5e6ccda0"
   },
   "source": [
    "**Warp dataset with DataWrapper**\n",
    "\n",
    "Warp train dataset with DataWrapper, which helps to save data augmentation information during the forwarding of teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46a046",
   "metadata": {
    "id": "2b46a046"
   },
   "outputs": [],
   "source": [
    "from e2eAIOK.ModelAdapter.engine_core.distiller.utils import logits_wrap_dataset\n",
    "logits_path = \"./data\" # path to save the logits\n",
    "train_set = logits_wrap_dataset(train_set, logits_path=logits_path, num_classes=100, save_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210a1e2",
   "metadata": {
    "id": "3210a1e2"
   },
   "source": [
    "**Create dataloader**\n",
    "\n",
    "Note: We need to save all the data without any sampling, make sure you have disable \"channel_last\" or \"sampler\" in dataloader, which can avoid data lossing in later logits using process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232dee55",
   "metadata": {
    "id": "232dee55"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set, batch_size=128, shuffle=True, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc18f19",
   "metadata": {
    "id": "bbc18f19"
   },
   "source": [
    "## 3. Model Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ac60a",
   "metadata": {
    "id": "c25ac60a"
   },
   "source": [
    "**Prepare teacher model**\n",
    "\n",
    "To use distiller, we need to prepare teacher model to guide the training. Here we select pretrained [vit_base-224-in21k-ft-cifar100 from HuggingFace](https://huggingface.co/edumunozsala/vit_base-224-in21k-ft-cifar100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b99862",
   "metadata": {
    "id": "93b99862"
   },
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "teacher_model = ViTForImageClassification.from_pretrained('edumunozsala/vit_base-224-in21k-ft-cifar100')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481901ed",
   "metadata": {
    "id": "481901ed"
   },
   "source": [
    "**Define Distiller**\n",
    "\n",
    "Here we define a distiller using KD algorithm, and it take a teacher model as input. If teacher comes from Hugginface, please clarify \"teacher_type\" with a name starting with \"huggingface\", otherwise no need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d750e1d6",
   "metadata": {
    "id": "d750e1d6"
   },
   "outputs": [],
   "source": [
    "from e2eAIOK.ModelAdapter.engine_core.distiller import KD\n",
    "distiller= KD(teacher_model,teacher_type=\"huggingface_vit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f1c55",
   "metadata": {
    "id": "120f1c55"
   },
   "source": [
    "## 4. Save Logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9cedb3",
   "metadata": {
    "id": "7b9cedb3"
   },
   "source": [
    "Call prepare_logits() of distiller to save the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15548288",
   "metadata": {
    "id": "15548288",
    "outputId": "b7f9b630-3e05-49cf-970c-a67e9fd59832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-13 06:48:11 save 0/391\n",
      "2023-02-13 06:49:03 save 10/391\n",
      "2023-02-13 06:49:55 save 20/391\n",
      "2023-02-13 06:50:47 save 30/391\n",
      "2023-02-13 06:51:40 save 40/391\n",
      "2023-02-13 06:52:31 save 50/391\n",
      "2023-02-13 06:53:24 save 60/391\n",
      "2023-02-13 06:54:15 save 70/391\n",
      "2023-02-13 06:55:05 save 80/391\n",
      "2023-02-13 06:55:56 save 90/391\n",
      "2023-02-13 06:56:47 save 100/391\n",
      "2023-02-13 06:57:39 save 110/391\n",
      "2023-02-13 06:58:29 save 120/391\n",
      "2023-02-13 06:59:20 save 130/391\n",
      "2023-02-13 07:00:11 save 140/391\n",
      "2023-02-13 07:01:02 save 150/391\n",
      "2023-02-13 07:01:52 save 160/391\n",
      "2023-02-13 07:02:44 save 170/391\n",
      "2023-02-13 07:03:36 save 180/391\n",
      "2023-02-13 07:04:27 save 190/391\n",
      "2023-02-13 07:05:17 save 200/391\n",
      "2023-02-13 07:06:08 save 210/391\n",
      "2023-02-13 07:06:59 save 220/391\n",
      "2023-02-13 07:07:48 save 230/391\n",
      "2023-02-13 07:08:38 save 240/391\n",
      "2023-02-13 07:09:31 save 250/391\n",
      "2023-02-13 07:10:22 save 260/391\n",
      "2023-02-13 07:11:13 save 270/391\n",
      "2023-02-13 07:12:03 save 280/391\n",
      "2023-02-13 07:12:54 save 290/391\n",
      "2023-02-13 07:13:46 save 300/391\n",
      "2023-02-13 07:14:39 save 310/391\n",
      "2023-02-13 07:15:30 save 320/391\n",
      "2023-02-13 07:16:20 save 330/391\n",
      "2023-02-13 07:17:10 save 340/391\n",
      "2023-02-13 07:18:00 save 350/391\n",
      "2023-02-13 07:18:53 save 360/391\n",
      "2023-02-13 07:19:44 save 370/391\n",
      "2023-02-13 07:20:36 save 380/391\n",
      "2023-02-13 07:21:27 save 390/391\n",
      "Epoch 0 took 2001.7463374137878 seconds\n"
     ]
    }
   ],
   "source": [
    "distiller.prepare_logits(train_loader, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
