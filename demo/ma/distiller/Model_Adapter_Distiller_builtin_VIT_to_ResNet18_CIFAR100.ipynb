{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhouyu5/e2eAIOK/blob/da-demo/demo/ma/distiller/Model_Adapter_Distiller_builtin_VIT_to_ResNet18_CIFAR100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5c7ec59",
      "metadata": {
        "id": "a5c7ec59"
      },
      "source": [
        "# Model Adapter Distiller Built-in DEMO\n",
        "Model Adapter is a convenient framework can be used to reduce training and inference time, or data labeling cost by efficiently utilizing public advanced models and those datasets from many domains. It mainly contains three components served for different cases: Finetuner, Distiller, and Domain Adapter. \n",
        "\n",
        "This demo mainly introduces the usage of Distiller. Take image classification as an example, it shows how to integrate distiller  from VIT to ResNet18 on CIFAR100 dataset. This is a build-in usage, you can find customized detailed demo at [here](./Model_Adapter_Distiller_Walkthrough_VIT_to_ResNet18_CIFAR100.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09c721aa",
      "metadata": {
        "id": "09c721aa"
      },
      "source": [
        "# Content\n",
        "\n",
        "* [Model Adapter Distiller Overview](#Model-Adapter-Distller-Overview)\n",
        "* [Getting Started](#Getting-Started)\n",
        "    * [1. Environment Setup](#1.-Environment-Setup)\n",
        "    * [2. Launch training on baseline](#2.-Launch-training-on-baseline)\n",
        "    * [3. Launch training with Distiller](#3.-Launch-training-with-Distiller)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b462e304",
      "metadata": {
        "id": "b462e304"
      },
      "source": [
        "## Model Adapter Distiller Overview\n",
        "Distiller is based on knowledge distillation technology, it can transfer knowledge from a heavy model (teacher) to a light one (student) with different structure. Teacher is a large model pretrained on specific dataset, which contains sufficient knowledge for this task, while the student model has much smaller structure. Distiller trains the student not only on the dataset, but also with the help of teacher’s knowledge. With distiller, we can take use of the knowledge from the existing pretrained large models but use much less training time. It can also significantly improve the converge speed and predicting accuracy of a small model, which is very helpful for inference.\n",
        "\n",
        "<img src=\"https://github.com/zhouyu5/e2eAIOK/blob/da-demo/demo/ma/imgs/distiller.png?raw=1\" width=\"60%\">\n",
        "<center>Model Adapter Distiller Structure</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78cdf893",
      "metadata": {
        "id": "78cdf893"
      },
      "source": [
        "# Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fb3473d",
      "metadata": {
        "id": "0fb3473d"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3ce01cc",
      "metadata": {
        "id": "b3ce01cc"
      },
      "source": [
        "### (Option 1) Use Pip install - recommend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479fa0a4",
      "metadata": {
        "id": "479fa0a4",
        "outputId": "4757def4-9a0d-4bcc-cf97-74dece630cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: e2eAIOK-ModelAdapter in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (1.0.1b2023031702)\n",
            "Requirement already satisfied: scikit-learn in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.24.2)\n",
            "Requirement already satisfied: transformers in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (4.8.2)\n",
            "Requirement already satisfied: nnunet in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.7.0)\n",
            "Requirement already satisfied: thop in /home/xianyang/.local/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: tensorboard in /home/xianyang/.local/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (2.10.0)\n",
            "Requirement already satisfied: intel-extension-for-pytorch==1.12.100 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.12.100)\n",
            "Requirement already satisfied: tllib==0.4 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.4)\n",
            "Requirement already satisfied: torchaudio==0.12.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.12.1)\n",
            "Requirement already satisfied: torchvision==0.13.1 in /home/xianyang/.local/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.13.1)\n",
            "Requirement already satisfied: easydict in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.10)\n",
            "Requirement already satisfied: timm in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (0.6.12)\n",
            "Requirement already satisfied: torchsummary in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from e2eAIOK-ModelAdapter) (1.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-learn->e2eAIOK-ModelAdapter) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /home/xianyang/.local/lib/python3.8/site-packages (from scikit-learn->e2eAIOK-ModelAdapter) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-learn->e2eAIOK-ModelAdapter) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-learn->e2eAIOK-ModelAdapter) (1.6.3)\n",
            "Requirement already satisfied: pyyaml in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (5.4.1)\n",
            "Requirement already satisfied: packaging in /home/xianyang/.local/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (23.0)\n",
            "Requirement already satisfied: requests in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (2.28.2)\n",
            "Requirement already satisfied: sacremoses in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (2021.7.6)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (0.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (4.51.0)\n",
            "Requirement already satisfied: filelock in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from transformers->e2eAIOK-ModelAdapter) (0.10.3)\n",
            "Requirement already satisfied: medpy in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.4.0)\n",
            "Requirement already satisfied: sklearn in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.0.post1)\n",
            "Requirement already satisfied: SimpleITK in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (2.2.1)\n",
            "Requirement already satisfied: tifffile in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (2022.10.10)\n",
            "Requirement already satisfied: scikit-image>=0.14 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.19.3)\n",
            "Requirement already satisfied: batchgenerators>=0.23 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (0.24)\n",
            "Requirement already satisfied: torch>=1.6.0a in /home/xianyang/.local/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (1.12.1)\n",
            "Requirement already satisfied: pandas in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (1.4.2)\n",
            "Requirement already satisfied: dicom2nifti in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (2.4.7)\n",
            "Requirement already satisfied: nibabel in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from nnunet->e2eAIOK-ModelAdapter) (5.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (1.47.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (2.2.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (0.35.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (3.19.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (50.3.1.post20201107)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (1.2.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/xianyang/.local/lib/python3.8/site-packages (from tensorboard->e2eAIOK-ModelAdapter) (2.11.0)\n",
            "Requirement already satisfied: psutil in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from intel-extension-for-pytorch==1.12.100->e2eAIOK-ModelAdapter) (5.8.0)\n",
            "Requirement already satisfied: opencv-python in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (4.7.0.68)\n",
            "Requirement already satisfied: matplotlib in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (3.5.1)\n",
            "Requirement already satisfied: webcolors in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (1.12)\n",
            "Requirement already satisfied: numba in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (0.55.2)\n",
            "Requirement already satisfied: prettytable in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from tllib==0.4->e2eAIOK-ModelAdapter) (3.6.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from torchvision==0.13.1->e2eAIOK-ModelAdapter) (9.1.0)\n",
            "Requirement already satisfied: typing-extensions in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from torchvision==0.13.1->e2eAIOK-ModelAdapter) (3.10.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->transformers->e2eAIOK-ModelAdapter) (1.26.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->transformers->e2eAIOK-ModelAdapter) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->transformers->e2eAIOK-ModelAdapter) (3.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests->transformers->e2eAIOK-ModelAdapter) (2020.6.20)\n",
            "Requirement already satisfied: click in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from sacremoses->transformers->e2eAIOK-ModelAdapter) (8.0.1)\n",
            "Requirement already satisfied: six in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from sacremoses->transformers->e2eAIOK-ModelAdapter) (1.15.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-image>=0.14->nnunet->e2eAIOK-ModelAdapter) (2.24.0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: networkx>=2.2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-image>=0.14->nnunet->e2eAIOK-ModelAdapter) (3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from scikit-image>=0.14->nnunet->e2eAIOK-ModelAdapter) (1.4.1)\n",
            "Requirement already satisfied: unittest2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.1.0)\n",
            "Requirement already satisfied: future in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (0.18.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from pandas->nnunet->e2eAIOK-ModelAdapter) (2021.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from pandas->nnunet->e2eAIOK-ModelAdapter) (2.8.1)\n",
            "Requirement already satisfied: pydicom>=2.2.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from dicom2nifti->nnunet->e2eAIOK-ModelAdapter) (2.3.1)\n",
            "Requirement already satisfied: python-gdcm in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from dicom2nifti->nnunet->e2eAIOK-ModelAdapter) (3.0.20)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->e2eAIOK-ModelAdapter) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/xianyang/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard->e2eAIOK-ModelAdapter) (2.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard->e2eAIOK-ModelAdapter) (4.10.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (0.2.8)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (2.4.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (4.32.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from matplotlib->tllib==0.4->e2eAIOK-ModelAdapter) (0.11.0)\n",
            "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from numba->tllib==0.4->e2eAIOK-ModelAdapter) (0.38.1)\n",
            "Requirement already satisfied: wcwidth in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from prettytable->tllib==0.4->e2eAIOK-ModelAdapter) (0.2.5)\n",
            "Requirement already satisfied: argparse in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from unittest2->batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.4.0)\n",
            "Requirement already satisfied: traceback2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from unittest2->batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->e2eAIOK-ModelAdapter) (3.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard->e2eAIOK-ModelAdapter) (3.7.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard->e2eAIOK-ModelAdapter) (0.4.8)\n",
            "Requirement already satisfied: linecache2 in /home/xianyang/sw/miniconda3/lib/python3.8/site-packages (from traceback2->unittest2->batchgenerators>=0.23->nnunet->e2eAIOK-ModelAdapter) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install e2eAIOK-ModelAdapter --pre"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2444d7e9",
      "metadata": {
        "id": "2444d7e9"
      },
      "source": [
        "### (Option 2) Use Docker \n",
        "\n",
        "Step1. prepare code\n",
        "   ``` bash\n",
        "   git clone https://github.com/intel/e2eAIOK.git\n",
        "   cd e2eAIOK\n",
        "   git submodule update --init –recursive\n",
        "   ```\n",
        "    \n",
        "Step2. build docker image\n",
        "   ``` bash\n",
        "   python3 scripts/start_e2eaiok_docker.py -b pytorch112 --dataset_path ${dataset_path} -w ${host0} ${host1} ${host2} ${host3} --proxy  \"http://addr:ip\"\n",
        "   ```\n",
        "   \n",
        "Step3. run docker and start conda env\n",
        "   ``` bash\n",
        "   sshpass -p docker ssh ${host0} -p 12347\n",
        "   conda activate pytorch-1.12.0\n",
        "   ```\n",
        "  \n",
        "Step4. Start the jupyter notebook and tensorboard service\n",
        "   ``` bash\n",
        "   nohup jupyter notebook --notebook-dir=/home/vmagent/app/e2eaiok --ip=${hostname} --port=8899 --allow-root &\n",
        "   nohup tensorboard --logdir /home/vmagent/app/data/tensorboard --host=${hostname} --port=6006 & \n",
        "   ```\n",
        "   Now you can visit demso in `http://${hostname}:8899/`, and see tensorboad log in ` http://${hostname}:6006`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2877927",
      "metadata": {
        "id": "b2877927"
      },
      "source": [
        "## 2. Launch training on baseline\n",
        "First we train a vanilla ResNet18 on CIFAR100.\n",
        "\n",
        "### 2.1 Configuration\n",
        "Create a configuration for ResNet18 with CIFAR100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7812a74a",
      "metadata": {
        "id": "7812a74a",
        "outputId": "f8647bda-3661-46e2-ffa7-b359b8240493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-03-19 23:11:25--  https://raw.githubusercontent.com/intel/e2eAIOK/main/conf/ma/demo/baseline/cifar100_res18.yaml\n",
            "Resolving child-prc.intel.com (child-prc.intel.com)... 10.239.120.56\n",
            "Connecting to child-prc.intel.com (child-prc.intel.com)|10.239.120.56|:913... connected.\n",
            "Proxy request sent, awaiting response... 200 OK\n",
            "Length: 505 [text/plain]\n",
            "Saving to: ‘cifar100_res18.yaml’\n",
            "\n",
            "100%[======================================>] 505         --.-K/s   in 0s      \n",
            "\n",
            "2023-03-19 23:11:26 (14.5 MB/s) - ‘cifar100_res18.yaml’ saved [505/505]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/intel/e2eAIOK/main/conf/ma/demo/baseline/cifar100_res18.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "687d2107",
      "metadata": {
        "id": "687d2107",
        "outputId": "d09501ae-20e0-48a5-9507-f8272f696344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "experiment:\r\n",
            "    project: \"demo\"\r\n",
            "    tag: \"cifar100_res18\"\r\n",
            "\r\n",
            "output_dir: \"./data\"\r\n",
            "train_epochs: 1\r\n",
            "\r\n",
            "data_set: \"cifar100\"\r\n",
            "data_path:  \"./data\"\r\n",
            "num_workers: 0\r\n",
            "input_size: 224\r\n",
            "\r\n",
            "model_type: \"resnet18\"\r\n",
            "\r\n",
            "optimizer: \"SGD\"\r\n",
            "learning_rate: 0.1\r\n",
            "weight_decay: 0.0001\r\n",
            "momentum: 0.9\r\n",
            "\r\n",
            "lr_scheduler: \"ReduceLROnPlateau\"\r\n",
            "lr_scheduler_config:\r\n",
            "    decay_rate: 0.2\r\n",
            "    decay_patience: 10 # for ReduceLROnPlateau\r\n",
            "  \r\n",
            "early_stop: \"EarlyStopping\"\r\n",
            "early_stop_config:\r\n",
            "    tolerance_epoch: 15\r\n"
          ]
        }
      ],
      "source": [
        "! cat cifar100_res18.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68ad9b98",
      "metadata": {
        "id": "68ad9b98"
      },
      "source": [
        "### 2.2 Launch training\n",
        "**Training resnet18 on CIFAR100 from scratch (train one epoch for example):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3262cd54",
      "metadata": {
        "id": "3262cd54",
        "outputId": "f6ea087b-86e1-4325-bf84-eb8f2e8371ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "No Trial\n",
            "configurations:\n",
            "{'distiller': {'type': '', 'teacher': {'type': '', 'initial_pretrain': '', 'pretrain': '', 'frozen': True}, 'save_logits': False, 'use_saved_logits': False, 'check_logits': False, 'logits_path': '', 'logits_topk': 0, 'save_logits_start_epoch': 0}, 'learning_rate': 0.1, 'weight_decay': 0.0001, 'warmup_scheduler_epoch': 0, 'loss_weight': {'backbone': 1.0, 'distiller': 0.0, 'adapter': 0.0}, 'metric_threshold': 100.0, 'profiler': False, 'test_transform': 'default', 'data_set': 'cifar100', 'pretrain': '', 'tensorboard_dir': '/home/vmagent/app/data/tensorboard/cifar100_res18_resnet18_cifar100', 'dist_backend': 'gloo', 'start_epoch': 0, 'train_batch_size': 128, 'eval_batch_size': 128, 'kd': {'temperature': 4}, 'num_workers': 0, 'criterion': 'CrossEntropyLoss', 'device': 'cpu', 'train_transform': 'default', 'model_type': 'resnet18', 'eval_step': 10, 'warmup_scheduler': '', 'dkd': {'alpha': 1.0, 'beta': 8.0, 'temperature': 4.0, 'warmup': 20}, 'input_size': 224, 'train_epochs': 1, 'optimizer': 'SGD', 'eval_metric': 'accuracy', 'lr_scheduler': 'ReduceLROnPlateau', 'early_stop_config': {'tolerance_epoch': 15, 'is_max': True, 'delta': 0.0001}, 'seed': 0, 'lr_scheduler_config': {'decay_patience': 10, 'decay_stages': [], 'decay_rate': 0.2, 'T_max': 0}, 'momentum': 0.9, 'initial_pretrain': '', 'finetuner': {'type': '', 'initial_pretrain': '', 'pretrain': '', 'pretrained_num_classes': 10, 'finetuned_lr': 0.01, 'frozen': False}, 'eval_epochs': 1, 'log_interval_step': 10, 'early_stop': 'EarlyStopping', 'model_save_interval': 40, 'drop_last': False, 'adapter': {'type': '', 'feature_size': 1, 'feature_layer_name': 'x'}, 'profiler_config': {'skip_first': 1, 'wait': 1, 'warmup': 1, 'active': 2, 'repeat': 1, 'trace_file': '/home/vmagent/app/data/model/demo/cifar100_res18/profile/profile_resnet18_cifar100_1676258110'}, 'output_dir': '/home/vmagent/app/data/model', 'experiment': {'tag': 'cifar100_res18', 'strategy': '', 'project': 'demo'}, 'pin_mem': False, 'data_path': '/home/vmagent/app/data/dataset/cifar', 'enable_ipex': False}\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Model params:  11227812\n",
            "Epoch [0] learning rate: [0.1]\n",
            "[2023-02-13 03:15:14] rank(0) epoch(0) step (0/391) Train: loss = 5.2327;\taccuracy = 1.5625\n",
            "[2023-02-13 03:15:37] rank(0) epoch(0) step (10/391) Train: loss = 5.9162;\taccuracy = 3.9062\n",
            "[2023-02-13 03:15:55] rank(0) epoch(0) step (20/391) Train: loss = 5.1079;\taccuracy = 1.5625\n",
            "[2023-02-13 03:16:14] rank(0) epoch(0) step (30/391) Train: loss = 4.6421;\taccuracy = 4.6875\n",
            "[2023-02-13 03:16:32] rank(0) epoch(0) step (40/391) Train: loss = 4.7618;\taccuracy = 5.4688\n",
            "[2023-02-13 03:16:52] rank(0) epoch(0) step (50/391) Train: loss = 4.3421;\taccuracy = 9.3750\n",
            "[2023-02-13 03:17:10] rank(0) epoch(0) step (60/391) Train: loss = 4.3036;\taccuracy = 7.0312\n",
            "[2023-02-13 03:17:28] rank(0) epoch(0) step (70/391) Train: loss = 4.3936;\taccuracy = 5.4688\n",
            "[2023-02-13 03:17:47] rank(0) epoch(0) step (80/391) Train: loss = 4.1740;\taccuracy = 2.3438\n",
            "[2023-02-13 03:18:04] rank(0) epoch(0) step (90/391) Train: loss = 4.0016;\taccuracy = 4.6875\n",
            "[2023-02-13 03:18:24] rank(0) epoch(0) step (100/391) Train: loss = 4.3137;\taccuracy = 6.2500\n",
            "[2023-02-13 03:18:45] rank(0) epoch(0) step (110/391) Train: loss = 4.1459;\taccuracy = 7.0312\n",
            "[2023-02-13 03:19:03] rank(0) epoch(0) step (120/391) Train: loss = 4.1750;\taccuracy = 5.4688\n",
            "[2023-02-13 03:19:20] rank(0) epoch(0) step (130/391) Train: loss = 3.8443;\taccuracy = 7.0312\n",
            "[2023-02-13 03:19:40] rank(0) epoch(0) step (140/391) Train: loss = 3.9862;\taccuracy = 8.5938\n",
            "[2023-02-13 03:19:58] rank(0) epoch(0) step (150/391) Train: loss = 3.7643;\taccuracy = 12.5000\n",
            "[2023-02-13 03:20:15] rank(0) epoch(0) step (160/391) Train: loss = 4.0623;\taccuracy = 7.0312\n",
            "[2023-02-13 03:20:34] rank(0) epoch(0) step (170/391) Train: loss = 3.9744;\taccuracy = 9.3750\n",
            "[2023-02-13 03:20:52] rank(0) epoch(0) step (180/391) Train: loss = 3.8588;\taccuracy = 12.5000\n",
            "[2023-02-13 03:21:10] rank(0) epoch(0) step (190/391) Train: loss = 3.8252;\taccuracy = 12.5000\n",
            "[2023-02-13 03:21:29] rank(0) epoch(0) step (200/391) Train: loss = 3.9266;\taccuracy = 10.1562\n",
            "[2023-02-13 03:21:50] rank(0) epoch(0) step (210/391) Train: loss = 3.7679;\taccuracy = 9.3750\n",
            "[2023-02-13 03:22:09] rank(0) epoch(0) step (220/391) Train: loss = 3.9166;\taccuracy = 6.2500\n",
            "[2023-02-13 03:22:27] rank(0) epoch(0) step (230/391) Train: loss = 3.7651;\taccuracy = 12.5000\n",
            "[2023-02-13 03:22:44] rank(0) epoch(0) step (240/391) Train: loss = 3.8886;\taccuracy = 7.0312\n",
            "[2023-02-13 03:23:02] rank(0) epoch(0) step (250/391) Train: loss = 3.8251;\taccuracy = 7.0312\n",
            "[2023-02-13 03:23:21] rank(0) epoch(0) step (260/391) Train: loss = 3.8505;\taccuracy = 12.5000\n",
            "[2023-02-13 03:23:40] rank(0) epoch(0) step (270/391) Train: loss = 4.0052;\taccuracy = 7.8125\n",
            "[2023-02-13 03:23:59] rank(0) epoch(0) step (280/391) Train: loss = 3.7336;\taccuracy = 8.5938\n",
            "[2023-02-13 03:24:18] rank(0) epoch(0) step (290/391) Train: loss = 3.7000;\taccuracy = 11.7188\n",
            "[2023-02-13 03:24:35] rank(0) epoch(0) step (300/391) Train: loss = 3.8272;\taccuracy = 11.7188\n",
            "[2023-02-13 03:24:57] rank(0) epoch(0) step (310/391) Train: loss = 3.9097;\taccuracy = 8.5938\n",
            "[2023-02-13 03:25:15] rank(0) epoch(0) step (320/391) Train: loss = 3.7368;\taccuracy = 10.1562\n",
            "[2023-02-13 03:25:34] rank(0) epoch(0) step (330/391) Train: loss = 3.5672;\taccuracy = 17.9688\n",
            "[2023-02-13 03:25:51] rank(0) epoch(0) step (340/391) Train: loss = 3.8955;\taccuracy = 11.7188\n",
            "[2023-02-13 03:26:11] rank(0) epoch(0) step (350/391) Train: loss = 3.6014;\taccuracy = 19.5312\n",
            "[2023-02-13 03:26:30] rank(0) epoch(0) step (360/391) Train: loss = 3.4740;\taccuracy = 14.8438\n",
            "[2023-02-13 03:26:50] rank(0) epoch(0) step (370/391) Train: loss = 3.6566;\taccuracy = 17.1875\n",
            "[2023-02-13 03:27:08] rank(0) epoch(0) step (380/391) Train: loss = 3.7122;\taccuracy = 8.5938\n",
            "[2023-02-13 03:27:26] rank(0) epoch(0) step (390/391) Train: loss = 3.4692;\taccuracy = 16.2500\n",
            "2023-02-13 03:27:29 0/391\n",
            "2023-02-13 03:27:34 10/391\n",
            "2023-02-13 03:27:40 20/391\n",
            "2023-02-13 03:27:45 30/391\n",
            "2023-02-13 03:27:51 40/391\n",
            "2023-02-13 03:27:57 50/391\n",
            "2023-02-13 03:28:03 60/391\n",
            "2023-02-13 03:28:09 70/391\n",
            "[2023-02-13 03:28:13] rank(0) epoch(0) Validation: accuracy = 13.5100;\tloss = 3.6731\n",
            "Best Epoch: 0, accuracy: 13.510000228881836\n",
            "Epoch 0 took 784.2462615966797 seconds\n",
            "Total seconds:784.246972\n",
            "Totally take 785.898199558258 seconds\n"
          ]
        }
      ],
      "source": [
        "! python -u /usr/local/lib/python3.9/dist-packages/e2eAIOK/ModelAdapter/main.py --conf cifar100_res18.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec69744",
      "metadata": {
        "id": "eec69744"
      },
      "source": [
        "## 3. Launch training with Distiller\n",
        "Then we train ResNet18 on CIFAR100 with Distiller to show the performance imrpovement."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc056f90",
      "metadata": {
        "id": "fc056f90"
      },
      "source": [
        "### 3.1 Prepare teacher model\n",
        "To use distiller, we need to prepare teacher model to guide the training. Here we select pretrained [vit_base-224-in21k-ft-cifar100 from HuggingFace](https://huggingface.co/edumunozsala/vit_base-224-in21k-ft-cifar100)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa72d83b",
      "metadata": {
        "id": "fa72d83b"
      },
      "source": [
        "### 3.2 Configuration\n",
        "\n",
        "Create a configuration for Distiller with ResNet18 with CIFAR100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "287b3247",
      "metadata": {
        "id": "287b3247",
        "outputId": "150e7d07-2269-49d7-c11d-16b9e7b62fd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-03-19 23:13:29--  https://raw.githubusercontent.com/intel/e2eAIOK/main/conf/ma/demo/distiller/cifar100_kd_vit_res18.yaml\n",
            "Resolving child-prc.intel.com (child-prc.intel.com)... 10.239.120.56\n",
            "Connecting to child-prc.intel.com (child-prc.intel.com)|10.239.120.56|:913... connected.\n",
            "Proxy request sent, awaiting response... 200 OK\n",
            "Length: 992 [text/plain]\n",
            "Saving to: ‘cifar100_kd_vit_res18.yaml’\n",
            "\n",
            "100%[======================================>] 992         --.-K/s   in 0s      \n",
            "\n",
            "2023-03-19 23:13:30 (28.3 MB/s) - ‘cifar100_kd_vit_res18.yaml’ saved [992/992]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/intel/e2eAIOK/main/conf/ma/demo/distiller/cifar100_kd_vit_res18.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c112617b",
      "metadata": {
        "id": "c112617b",
        "outputId": "3e97b065-f24f-4538-9bde-7244e3ff2881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "experiment:\r\n",
            "  project: \"demo\"\r\n",
            "  tag: \"cifar100_kd_vit_res18\"\r\n",
            "  strategy: \"OnlyDistillationStrategy\"\r\n",
            "  \r\n",
            "output_dir: \"./data\"\r\n",
            "train_epochs: 1\r\n",
            "\r\n",
            "### dataset\r\n",
            "data_set: \"cifar100\"\r\n",
            "data_path:  \"./data\"\r\n",
            "num_workers: 4\r\n",
            "train_transform: \"vit\"\r\n",
            "test_transform: \"vit\"\r\n",
            "input_size: 224\r\n",
            "\r\n",
            "### model\r\n",
            "model_type: \"resnet18\"\r\n",
            "\r\n",
            "# loss\r\n",
            "loss_weight:\r\n",
            "    backbone: 0.1\r\n",
            "    distiller: 0.9\r\n",
            "\r\n",
            "## distiller\r\n",
            "distiller:\r\n",
            "    type: \"kd\"\r\n",
            "    teacher: \r\n",
            "        type: \"huggingface_vit_base_224_in21k_ft_cifar100\"\r\n",
            "        initial_pretrain: True\r\n",
            "\r\n",
            "## optimizer\r\n",
            "optimizer: \"SGD\"\r\n",
            "learning_rate: 0.1\r\n",
            "weight_decay: 0.0001\r\n",
            "momentum: 0.9\r\n",
            "\r\n",
            "### scheduler\r\n",
            "lr_scheduler: \"ReduceLROnPlateau\"\r\n",
            "lr_scheduler_config:\r\n",
            "    decay_rate: 0.2\r\n",
            "    decay_patience: 10 # for ReduceLROnPlateau\r\n",
            "  \r\n",
            "### early stop\r\n",
            "early_stop: \"EarlyStopping\"\r\n",
            "early_stop_config:\r\n",
            "    tolerance_epoch: 15\r\n"
          ]
        }
      ],
      "source": [
        "! cat cifar100_kd_vit_res18.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35068e74",
      "metadata": {
        "id": "35068e74"
      },
      "source": [
        "### 3.3 Launch Training with Distiller\n",
        "**Training resnet18 on CIFAR100 with Distiller (train one epoch for example):**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ae9f14",
      "metadata": {
        "id": "e5ae9f14"
      },
      "source": [
        "This will take some time(~45min), have a break and get a coffee!\n",
        "\n",
        "You can get an optimized and accelerated training with saving logits function, refer to [logits saving demo](Model_Adapter_Distiller_customized_ResNet18_CIFAR100_train_with_logits.ipynb) and [training with saved logits demo](./Model_Adapter_Distiller_customized_ResNet18_CIFAR100_train_with_logits.ipynb) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6779f8b2",
      "metadata": {
        "id": "6779f8b2",
        "outputId": "7bc8fbb9-dde9-48f5-c724-4312b134606e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "No Trial\n",
            "configurations:\n",
            "{'eval_metric': 'accuracy', 'dist_backend': 'gloo', 'eval_batch_size': 128, 'warmup_scheduler': '', 'eval_epochs': 1, 'experiment': {'project': 'demo', 'tag': 'cifar100_kd_vit_res18', 'strategy': 'OnlyDistillationStrategy'}, 'optimizer': 'SGD', 'loss_weight': {'adapter': 0.0, 'backbone': 0.1, 'distiller': 0.9}, 'momentum': 0.9, 'num_workers': 4, 'profiler_config': {'skip_first': 1, 'wait': 1, 'warmup': 1, 'active': 2, 'repeat': 1, 'trace_file': '/home/vmagent/app/data/model/demo/cifar100_kd_vit_res18/profile/profile_resnet18_OnlyDistillationStrategy_cifar100_1676258899'}, 'drop_last': False, 'lr_scheduler_config': {'decay_stages': [], 'decay_patience': 10, 'decay_rate': 0.2, 'T_max': 0}, 'start_epoch': 0, 'pretrain': '', 'warmup_scheduler_epoch': 0, 'early_stop_config': {'tolerance_epoch': 15, 'delta': 0.0001, 'is_max': True}, 'model_type': 'resnet18', 'distiller': {'check_logits': False, 'use_saved_logits': False, 'teacher': {'type': 'huggingface_vit_base_224_in21k_ft_cifar100', 'pretrain': '', 'frozen': True, 'initial_pretrain': True}, 'logits_path': '', 'save_logits': False, 'logits_topk': 0, 'type': 'kd', 'save_logits_start_epoch': 0}, 'train_batch_size': 128, 'tensorboard_dir': '/home/vmagent/app/data/tensorboard/cifar100_kd_vit_res18_resnet18_OnlyDistillationStrategy_cifar100', 'data_path': '/home/vmagent/app/data/dataset/cifar', 'kd': {'temperature': 4}, 'device': 'cpu', 'enable_ipex': False, 'output_dir': '/home/vmagent/app/data/model', 'initial_pretrain': '', 'train_epochs': 1, 'eval_step': 10, 'input_size': 224, 'dkd': {'alpha': 1.0, 'beta': 8.0, 'temperature': 4.0, 'warmup': 20}, 'criterion': 'CrossEntropyLoss', 'learning_rate': 0.1, 'weight_decay': 0.0001, 'test_transform': 'vit', 'finetuner': {'type': '', 'initial_pretrain': '', 'pretrain': '', 'pretrained_num_classes': 10, 'finetuned_lr': 0.01, 'frozen': False}, 'model_save_interval': 40, 'early_stop': 'EarlyStopping', 'profiler': False, 'data_set': 'cifar100', 'pin_mem': False, 'lr_scheduler': 'ReduceLROnPlateau', 'adapter': {'type': '', 'feature_size': 1, 'feature_layer_name': 'x'}, 'metric_threshold': 100.0, 'seed': 0, 'log_interval_step': 10, 'train_transform': 'vit'}\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Model params:  11227812\n",
            "Epoch [0] learning rate: [0.1]\n",
            "[2023-02-13 03:28:31] rank(0) epoch(0) step (0/391) Train: total_loss = 2.8613;\tbackbone_loss = 5.0709;\tdistiller_loss = 2.6158;\taccuracy = 0.7812\n",
            "[2023-02-13 03:29:49] rank(0) epoch(0) step (10/391) Train: total_loss = 2.5512;\tbackbone_loss = 4.6630;\tdistiller_loss = 2.3166;\taccuracy = 5.4688\n",
            "[2023-02-13 03:30:55] rank(0) epoch(0) step (20/391) Train: total_loss = 2.3478;\tbackbone_loss = 4.3990;\tdistiller_loss = 2.1199;\taccuracy = 7.0312\n",
            "[2023-02-13 03:32:02] rank(0) epoch(0) step (30/391) Train: total_loss = 2.3372;\tbackbone_loss = 4.2609;\tdistiller_loss = 2.1235;\taccuracy = 4.6875\n",
            "[2023-02-13 03:33:09] rank(0) epoch(0) step (40/391) Train: total_loss = 2.2828;\tbackbone_loss = 4.2696;\tdistiller_loss = 2.0621;\taccuracy = 7.0312\n",
            "[2023-02-13 03:34:17] rank(0) epoch(0) step (50/391) Train: total_loss = 2.2566;\tbackbone_loss = 4.1938;\tdistiller_loss = 2.0414;\taccuracy = 7.8125\n",
            "[2023-02-13 03:35:24] rank(0) epoch(0) step (60/391) Train: total_loss = 2.2396;\tbackbone_loss = 4.0905;\tdistiller_loss = 2.0339;\taccuracy = 10.1562\n",
            "[2023-02-13 03:36:30] rank(0) epoch(0) step (70/391) Train: total_loss = 2.2684;\tbackbone_loss = 4.1433;\tdistiller_loss = 2.0601;\taccuracy = 6.2500\n",
            "[2023-02-13 03:37:35] rank(0) epoch(0) step (80/391) Train: total_loss = 2.1754;\tbackbone_loss = 4.1399;\tdistiller_loss = 1.9571;\taccuracy = 5.4688\n",
            "[2023-02-13 03:38:40] rank(0) epoch(0) step (90/391) Train: total_loss = 2.1530;\tbackbone_loss = 3.9572;\tdistiller_loss = 1.9525;\taccuracy = 14.0625\n",
            "[2023-02-13 03:39:45] rank(0) epoch(0) step (100/391) Train: total_loss = 2.1641;\tbackbone_loss = 3.9599;\tdistiller_loss = 1.9646;\taccuracy = 8.5938\n",
            "[2023-02-13 03:41:00] rank(0) epoch(0) step (110/391) Train: total_loss = 2.1332;\tbackbone_loss = 4.0488;\tdistiller_loss = 1.9204;\taccuracy = 10.1562\n",
            "[2023-02-13 03:42:07] rank(0) epoch(0) step (120/391) Train: total_loss = 2.1617;\tbackbone_loss = 3.9302;\tdistiller_loss = 1.9652;\taccuracy = 11.7188\n",
            "[2023-02-13 03:43:14] rank(0) epoch(0) step (130/391) Train: total_loss = 2.1624;\tbackbone_loss = 4.0270;\tdistiller_loss = 1.9552;\taccuracy = 10.9375\n",
            "[2023-02-13 03:44:20] rank(0) epoch(0) step (140/391) Train: total_loss = 2.0829;\tbackbone_loss = 3.8385;\tdistiller_loss = 1.8879;\taccuracy = 13.2812\n",
            "[2023-02-13 03:45:27] rank(0) epoch(0) step (150/391) Train: total_loss = 2.1305;\tbackbone_loss = 3.8676;\tdistiller_loss = 1.9375;\taccuracy = 15.6250\n",
            "[2023-02-13 03:46:34] rank(0) epoch(0) step (160/391) Train: total_loss = 2.1792;\tbackbone_loss = 4.0635;\tdistiller_loss = 1.9698;\taccuracy = 9.3750\n",
            "[2023-02-13 03:47:40] rank(0) epoch(0) step (170/391) Train: total_loss = 2.1589;\tbackbone_loss = 3.9684;\tdistiller_loss = 1.9579;\taccuracy = 10.1562\n",
            "[2023-02-13 03:48:45] rank(0) epoch(0) step (180/391) Train: total_loss = 2.1109;\tbackbone_loss = 3.7571;\tdistiller_loss = 1.9280;\taccuracy = 14.0625\n",
            "[2023-02-13 03:49:52] rank(0) epoch(0) step (190/391) Train: total_loss = 2.1241;\tbackbone_loss = 3.7860;\tdistiller_loss = 1.9394;\taccuracy = 10.9375\n",
            "[2023-02-13 03:50:58] rank(0) epoch(0) step (200/391) Train: total_loss = 2.0968;\tbackbone_loss = 3.7854;\tdistiller_loss = 1.9091;\taccuracy = 14.8438\n",
            "[2023-02-13 03:52:14] rank(0) epoch(0) step (210/391) Train: total_loss = 2.0391;\tbackbone_loss = 3.7022;\tdistiller_loss = 1.8543;\taccuracy = 17.9688\n",
            "[2023-02-13 03:53:20] rank(0) epoch(0) step (220/391) Train: total_loss = 2.1858;\tbackbone_loss = 3.9818;\tdistiller_loss = 1.9862;\taccuracy = 14.0625\n",
            "[2023-02-13 03:54:27] rank(0) epoch(0) step (230/391) Train: total_loss = 2.0720;\tbackbone_loss = 3.7966;\tdistiller_loss = 1.8804;\taccuracy = 14.0625\n",
            "[2023-02-13 03:55:34] rank(0) epoch(0) step (240/391) Train: total_loss = 2.0178;\tbackbone_loss = 3.6610;\tdistiller_loss = 1.8352;\taccuracy = 12.5000\n",
            "[2023-02-13 03:56:41] rank(0) epoch(0) step (250/391) Train: total_loss = 2.0711;\tbackbone_loss = 3.6771;\tdistiller_loss = 1.8926;\taccuracy = 10.9375\n",
            "[2023-02-13 03:57:48] rank(0) epoch(0) step (260/391) Train: total_loss = 1.9992;\tbackbone_loss = 3.6647;\tdistiller_loss = 1.8141;\taccuracy = 21.0938\n",
            "[2023-02-13 03:58:55] rank(0) epoch(0) step (270/391) Train: total_loss = 2.0581;\tbackbone_loss = 3.7354;\tdistiller_loss = 1.8717;\taccuracy = 14.0625\n",
            "[2023-02-13 04:00:03] rank(0) epoch(0) step (280/391) Train: total_loss = 2.0995;\tbackbone_loss = 3.8003;\tdistiller_loss = 1.9105;\taccuracy = 14.0625\n",
            "[2023-02-13 04:01:12] rank(0) epoch(0) step (290/391) Train: total_loss = 2.0269;\tbackbone_loss = 3.5826;\tdistiller_loss = 1.8540;\taccuracy = 17.1875\n",
            "[2023-02-13 04:02:20] rank(0) epoch(0) step (300/391) Train: total_loss = 2.1234;\tbackbone_loss = 3.8305;\tdistiller_loss = 1.9337;\taccuracy = 13.2812\n",
            "[2023-02-13 04:03:38] rank(0) epoch(0) step (310/391) Train: total_loss = 2.0663;\tbackbone_loss = 3.7107;\tdistiller_loss = 1.8836;\taccuracy = 18.7500\n",
            "[2023-02-13 04:04:45] rank(0) epoch(0) step (320/391) Train: total_loss = 2.1008;\tbackbone_loss = 3.6999;\tdistiller_loss = 1.9231;\taccuracy = 16.4062\n",
            "[2023-02-13 04:05:52] rank(0) epoch(0) step (330/391) Train: total_loss = 2.0667;\tbackbone_loss = 3.6667;\tdistiller_loss = 1.8889;\taccuracy = 16.4062\n",
            "[2023-02-13 04:06:58] rank(0) epoch(0) step (340/391) Train: total_loss = 2.0286;\tbackbone_loss = 3.6310;\tdistiller_loss = 1.8506;\taccuracy = 19.5312\n",
            "[2023-02-13 04:08:05] rank(0) epoch(0) step (350/391) Train: total_loss = 2.1055;\tbackbone_loss = 3.6987;\tdistiller_loss = 1.9284;\taccuracy = 17.1875\n",
            "[2023-02-13 04:09:12] rank(0) epoch(0) step (360/391) Train: total_loss = 2.0438;\tbackbone_loss = 3.5380;\tdistiller_loss = 1.8778;\taccuracy = 15.6250\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-02-13 04:10:20] rank(0) epoch(0) step (370/391) Train: total_loss = 2.0250;\tbackbone_loss = 3.6623;\tdistiller_loss = 1.8431;\taccuracy = 11.7188\n",
            "[2023-02-13 04:11:28] rank(0) epoch(0) step (380/391) Train: total_loss = 2.0208;\tbackbone_loss = 3.5435;\tdistiller_loss = 1.8516;\taccuracy = 17.9688\n",
            "[2023-02-13 04:12:33] rank(0) epoch(0) step (390/391) Train: total_loss = 1.9110;\tbackbone_loss = 3.4433;\tdistiller_loss = 1.7407;\taccuracy = 18.7500\n",
            "2023-02-13 04:12:44 0/391\n",
            "2023-02-13 04:12:49 10/391\n",
            "2023-02-13 04:12:53 20/391\n",
            "2023-02-13 04:12:58 30/391\n",
            "2023-02-13 04:13:03 40/391\n",
            "2023-02-13 04:13:07 50/391\n",
            "2023-02-13 04:13:12 60/391\n",
            "2023-02-13 04:13:16 70/391\n",
            "[2023-02-13 04:13:20] rank(0) epoch(0) Validation: accuracy = 17.3100;\tloss = 3.5807\n",
            "Best Epoch: 0, accuracy: 17.309999465942383\n",
            "Epoch 0 took 2708.9147386550903 seconds\n",
            "Total seconds:2708.916575\n",
            "Totally take 2713.286825656891 seconds\n"
          ]
        }
      ],
      "source": [
        "! python -u /usr/local/lib/python3.9/dist-packages/e2eAIOK/ModelAdapter/main.py --conf cifar100_kd_vit_res18.yaml"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}