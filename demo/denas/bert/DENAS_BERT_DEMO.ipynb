{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIDK DE-NAS BERT Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo mainly introduces the DE-NAS application on the BERT, which is mainly expected to express how to leverage the DE-NAS, a train-free and hardware-aware NAS, for optimizing the BERT-structure model to a lighter and faster model through DE-NAS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "* [Background and Motivation](#1)\n",
    "* [DE-NAS Introduction](#2)\n",
    "* [DE-NAS on BERT Experiment](#3)\n",
    "* [Summary](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p id=\"1\"></p>\n",
    "\n",
    "## Background and Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An automatic approach to democratize Deep Neural networks becomes increasingly popular, where compression, HPO and recently emerging NAS are emerging to improve DL efficiency. Howerver, compression and HPO cannot cover all the required optimizations for efficient DL, where NAS with its ability to automatically design neural network has been paid more attention.\n",
    "\n",
    "NAS is becoming increasingly important technique for automatic model design, and quite often it is capable of outperform human hand-designed architectures, conventional NAS is mostly targeting for single domain, which possesses poor cross-domain generalization ability. Additionally, it is extremely computation intensive due to the large search space and iterative training-based evaluation on the candidate networks. Moreover, determining the suitable architecture on different target hardware requires task-specific search that exacerbates this challenge. \n",
    "\n",
    "<center>\n",
    "<img src=\"./img/NAS.png\" width=\"400\"/><figure>Conventional NAS</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p id=\"2\"></p>\n",
    "\n",
    "## DE-NAS Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DE-NAS constructs compact neural architecture directly from carefully designed search spaces for multiple domains, leverages a hardware-aware search strategy based on given budget to determine the best network, and employs hardware-aware train-free scoring method to evaluate the candidate network’s performance rather than train each candidate and acquire its accuracy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DE-NAS on BERT Search Space\n",
    "Transformer-based search space consists of number of transformer layer, number of attention head, size of query/key/value, size of MLP, and dimension of embedding, and the supernet of DE-NAS on BERT is a BERT-based structure, which are shown as the below figure.\n",
    "\n",
    "<center>\n",
    "<img src=\"./img/NLP_Search_Space.png\" width=\"800\"/><figure>DE-NAS on BERT search space</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DE-NAS Search Engine on BERT\n",
    "The search strategy in the DE-NAS search engine generates candidate architecture adaptively based on target-hardware from search space, maximize the DE-Score to determine the best architecture using on pluggable search strategy and innovatively integrated latency into train-free DE-Score as an indicator. Currentlty, the DE-NAS search engine supports the random , EA and Bayesian optimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the DE-score is a train-free score used as the proxy to predict model accuracy instead of full training and validation. It used a novel zero-cost metric combined Gaussian complexity based on network expressivity, NTK score based on network complexity, nuclear norm score based on network diversity, Synflow score based on network saliency, and latency score. The computation of DE-Score only takes a few forward inferences other than iterative training, making it extremely fast, lightweight, and data-free. Below figure shows the hardware-aware search strategy with EA algorightm.\n",
    "\n",
    "<center>\n",
    "<img src=\"./img/EA_Search_Algorithm.png\" width=\"600\"/><figure>Hardware-aware EA Search Algorithm</figure>\n",
    "</center>\n",
    "\n",
    "And the DE-score is a train-free score used as the proxy to predict model accuracy instead of full training and validation. It used a novel zero-cost metric combined Gaussian complexity based on network expressivity, NTK score based on network complexity, nuclear norm score based on network diversity, Synflow score based on network saliency, and latency score. The computation of DE-Score only takes a few forward inferences other than iterative training, making it extremely fast, lightweight, and data-free. The overall DE_Score was calculated as following equation:\n",
    "\n",
    "$$DE_{score}=(\\alpha_1D_{EXP}+\\alpha_2D_{COM}+\\alpha_3D_{DIV}+\\alpha_4{SAL})D_{LAT}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p id=\"3\"></p>\n",
    "\n",
    "## DE-NAS on BERT Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "* Build docker image\n",
    "\n",
    "```\n",
    "cd Dockerfile-ubuntu18.04\n",
    "docker build -t aidk-pytorch110 . -f DockerfilePytorch110 --build-arg http_proxy --build-arg https_proxy\n",
    "```\n",
    "\n",
    "```\n",
    "docker run -itd --name aidk-denas-bert --privileged --network host --device=/dev/dri -v ${dataset_path}:/home/vmagent/app/dataset -v ${aidk_code_path}:/home/vmagent/app/aidk -w /home/vmagent/app/ aidk-pytorch110 /bin/bash\n",
    "```\n",
    "* Enter container with `docker exec -it aidk-denas-bert bash`\n",
    "\n",
    "* Install the jupyter\n",
    "\n",
    "```\n",
    "source /opt/intel/oneapi/setvars.sh --ccl-configuration=cpu_icc --force\n",
    "conda activate pytorch-1.10.0\n",
    "pip install jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset and Pre-trained BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-14 03:44:51--  https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\n",
      "Resolving child-prc.intel.com (child-prc.intel.com)... 10.239.120.56\n",
      "Connecting to child-prc.intel.com (child-prc.intel.com)|10.239.120.56|:913... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 231508 (226K) [text/plain]\n",
      "Saving to: ‘vocab.txt’\n",
      "\n",
      "vocab.txt           100%[===================>] 226.08K   321KB/s    in 0.7s    \n",
      "\n",
      "2022-10-14 03:44:53 (321 KB/s) - ‘vocab.txt’ saved [231508/231508]\n",
      "\n",
      "--2022-10-14 03:44:53--  https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin\n",
      "Resolving child-prc.intel.com (child-prc.intel.com)... 10.239.120.56\n",
      "Connecting to child-prc.intel.com (child-prc.intel.com)|10.239.120.56|:913... connected.\n",
      "Proxy request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/bert-base-uncased/097417381d6c7230bd9e3557456d726de6e83245ec8b24f529f60198a67b203a?response-content-disposition=attachment%3B%20filename%3D%22pytorch_model.bin%22&Expires=1665976343&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2JlcnQtYmFzZS11bmNhc2VkLzA5NzQxNzM4MWQ2YzcyMzBiZDllMzU1NzQ1NmQ3MjZkZTZlODMyNDVlYzhiMjRmNTI5ZjYwMTk4YTY3YjIwM2E~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj1hdHRhY2htZW50JTNCJTIwZmlsZW5hbWUlM0QlMjJweXRvcmNoX21vZGVsLmJpbiUyMiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY2NTk3NjM0M319fV19&Signature=ZVk3zfHoHn1UV-lnBP1vl~sZLLVItyJHyZyMIE3WzO76K~9Zz3iMF1jjF9PGUVm0LH65F7HYrA2GtPCjVzFGROmzn7i5XKIoPcmWyTOTyjsgld7SU6R6lw0ZhztS8knXdij1IeOCW1Rpcs~kRdCK805jPbKTNQoVa0v54y24QnLTnRj2M7pW6Fs-Pg6b00XlAgFVxLuPJ6k2VBaBOwWbfDZSnnhY3O5s8PUXxb7u3y464~~e7yzJ6n8Y3XPZBe7q3Mi3ERH8fE-lB8CW7XxmZkz8vMIUVRZ9tqZG3mJAWxzfSQ8JoKWb9~V6~uf1fqdNg84S-AVdBMhfEKtpSJgq4g__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2022-10-14 03:44:54--  https://cdn-lfs.huggingface.co/bert-base-uncased/097417381d6c7230bd9e3557456d726de6e83245ec8b24f529f60198a67b203a?response-content-disposition=attachment%3B%20filename%3D%22pytorch_model.bin%22&Expires=1665976343&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2JlcnQtYmFzZS11bmNhc2VkLzA5NzQxNzM4MWQ2YzcyMzBiZDllMzU1NzQ1NmQ3MjZkZTZlODMyNDVlYzhiMjRmNTI5ZjYwMTk4YTY3YjIwM2E~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj1hdHRhY2htZW50JTNCJTIwZmlsZW5hbWUlM0QlMjJweXRvcmNoX21vZGVsLmJpbiUyMiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY2NTk3NjM0M319fV19&Signature=ZVk3zfHoHn1UV-lnBP1vl~sZLLVItyJHyZyMIE3WzO76K~9Zz3iMF1jjF9PGUVm0LH65F7HYrA2GtPCjVzFGROmzn7i5XKIoPcmWyTOTyjsgld7SU6R6lw0ZhztS8knXdij1IeOCW1Rpcs~kRdCK805jPbKTNQoVa0v54y24QnLTnRj2M7pW6Fs-Pg6b00XlAgFVxLuPJ6k2VBaBOwWbfDZSnnhY3O5s8PUXxb7u3y464~~e7yzJ6n8Y3XPZBe7q3Mi3ERH8fE-lB8CW7XxmZkz8vMIUVRZ9tqZG3mJAWxzfSQ8JoKWb9~V6~uf1fqdNg84S-AVdBMhfEKtpSJgq4g__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Connecting to child-prc.intel.com (child-prc.intel.com)|10.239.120.56|:913... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 440473133 (420M) [application/octet-stream]\n",
      "Saving to: ‘pytorch_model.bin’\n",
      "\n",
      "pytorch_model.bin   100%[===================>] 420.07M  43.9MB/s    in 17s     \n",
      "\n",
      "2022-10-14 03:45:11 (25.4 MB/s) - ‘pytorch_model.bin’ saved [440473133/440473133]\n",
      "\n",
      "--2022-10-14 03:45:11--  https://huggingface.co/bert-base-uncased/resolve/main/config.json\n",
      "Resolving child-prc.intel.com (child-prc.intel.com)... 10.239.120.56\n",
      "Connecting to child-prc.intel.com (child-prc.intel.com)|10.239.120.56|:913... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 570 [text/plain]\n",
      "Saving to: ‘bert_config.json’\n",
      "\n",
      "bert_config.json    100%[===================>]     570  --.-KB/s    in 0s      \n",
      "\n",
      "2022-10-14 03:45:12 (119 MB/s) - ‘bert_config.json’ saved [570/570]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd /home/vmagent/app/dataset && mkdir -p bert-base-uncased && cd bert-base-uncased && wget https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt -O vocab.txt && wget https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin -O pytorch_model.bin && wget https://huggingface.co/bert-base-uncased/resolve/main/config.json -O bert_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch DE-NAS Search Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paths: /home/vmagent/app/aidk/DeNas/asr/utils, /home/vmagent/app/aidk/DeNas/asr\n",
      "['/home/vmagent/app/aidk/DeNas', '/opt/intel/oneapi/advisor/2022.1.0/pythonapi', '/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python39.zip', '/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9', '/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/lib-dynload', '/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/site-packages', '/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/site-packages/warprnnt_pytorch-0.1-py3.9-linux-x86_64.egg', '', '..', '/home/vmagent/app/aidk/DeNas', '/home/vmagent/app/aidk/DeNas', '/home/vmagent/app/aidk/DeNas', '/home/vmagent/app/aidk/DeNas', '/home/vmagent/app/aidk/DeNas', '/home/vmagent/app/aidk/DeNas/asr']\n",
      "loading archive file /home/vmagent/app/dataset/bert-base-uncased\n",
      "10/14/2022 05:26:19 - INFO - nlp.supernet_bert -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.6.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Weights of SuperBertModel not initialized from pretrained model: ['bert.dense_fit.weight', 'bert.dense_fit.bias']\n",
      "Weights from pretrained model not used in SuperBertModel: ['bert.cls.predictions.bias', 'bert.cls.predictions.transform.dense.weight', 'bert.cls.predictions.transform.dense.bias', 'bert.cls.predictions.decoder.weight', 'bert.cls.seq_relationship.weight', 'bert.cls.seq_relationship.bias', 'bert.cls.predictions.transform.LayerNorm.weight', 'bert.cls.predictions.transform.LayerNorm.bias']\n",
      "10/14/2022 05:26:21 - INFO - DENAS -   epoch = 0\n",
      "10/14/2022 05:26:26 - INFO - DENAS -   random 1/50 structure (11, 10, 640, 720, 992) nas_score 198.36463928222656 params 58.934512\n",
      "10/14/2022 05:26:31 - INFO - DENAS -   random 2/50 structure (6, 8, 512, 752, 2816) nas_score 138.51315307617188 params 58.612176\n",
      "10/14/2022 05:26:37 - INFO - DENAS -   random 3/50 structure (12, 11, 704, 656, 1248) nas_score 180.458740234375 params 62.695536\n",
      "10/14/2022 05:26:42 - INFO - DENAS -   random 4/50 structure (10, 12, 768, 640, 1376) nas_score 209.848388671875 params 57.62336\n",
      "10/14/2022 05:26:47 - INFO - DENAS -   random 5/50 structure (8, 10, 640, 720, 2720) nas_score 111.16072082519531 params 69.01816\n",
      "10/14/2022 05:26:53 - INFO - DENAS -   random 6/50 structure (11, 11, 704, 704, 1824) nas_score 226.09779357910156 params 72.494048\n",
      "10/14/2022 05:26:58 - INFO - DENAS -   random 7/50 structure (11, 11, 704, 768, 1888) nas_score 234.3850555419922 params 80.21168\n",
      "10/14/2022 05:27:03 - INFO - DENAS -   random 8/50 structure (12, 10, 640, 576, 2112) nas_score 164.90086364746094 params 65.191104\n",
      "10/14/2022 05:27:10 - INFO - DENAS -   random 9/50 structure (10, 11, 704, 656, 2144) nas_score 203.9038848876953 params 67.47608\n",
      "10/14/2022 05:27:16 - INFO - DENAS -   random 10/50 structure (9, 11, 704, 624, 2720) nas_score 148.4894256591797 params 66.200592\n",
      "10/14/2022 05:27:20 - INFO - DENAS -   random 11/50 structure (11, 10, 640, 640, 1664) nas_score 230.10482788085938 params 61.807744\n",
      "10/14/2022 05:27:25 - INFO - DENAS -   random 12/50 structure (10, 11, 704, 512, 2592) nas_score 190.04978942871094 params 57.191872\n",
      "10/14/2022 05:27:30 - INFO - DENAS -   random 13/50 structure (11, 12, 768, 768, 1504) nas_score 246.09823608398438 params 75.884192\n",
      "10/14/2022 05:27:33 - INFO - DENAS -   random 14/50 structure (8, 8, 512, 656, 2848) nas_score 132.03643798828125 params 61.498992\n",
      "10/14/2022 05:27:38 - INFO - DENAS -   random 15/50 structure (12, 12, 768, 544, 2176) nas_score 205.53419494628906 params 65.737952\n",
      "10/14/2022 05:27:42 - INFO - DENAS -   random 16/50 structure (8, 10, 640, 688, 2720) nas_score 145.0950469970703 params 65.93032\n",
      "10/14/2022 05:27:45 - INFO - DENAS -   random 17/50 structure (10, 10, 640, 768, 1568) nas_score 296.18182373046875 params 68.254016\n",
      "10/14/2022 05:27:49 - INFO - DENAS -   random 18/50 structure (8, 8, 512, 688, 2592) nas_score 147.72894287109375 params 61.699152\n",
      "10/14/2022 05:27:54 - INFO - DENAS -   random 19/50 structure (9, 11, 704, 768, 2720) nas_score 190.4207000732422 params 81.578208\n",
      "10/14/2022 05:27:57 - INFO - DENAS -   random 20/50 structure (11, 9, 576, 672, 1760) nas_score 289.1500549316406 params 64.44352\n",
      "10/14/2022 05:28:01 - INFO - DENAS -   random 21/50 structure (12, 12, 768, 528, 1920) nas_score 194.75482177734375 params 60.550512\n",
      "10/14/2022 05:28:06 - INFO - DENAS -   random 22/50 structure (11, 9, 576, 688, 2848) nas_score 261.1834716796875 params 82.46792\n",
      "10/14/2022 05:28:09 - INFO - DENAS -   random 23/50 structure (8, 10, 640, 768, 2048) nas_score 156.3389434814453 params 65.390848\n",
      "10/14/2022 05:28:13 - INFO - DENAS -   random 24/50 structure (10, 9, 576, 608, 2112) nas_score 251.4327392578125 params 59.006496\n",
      "10/14/2022 05:28:19 - INFO - DENAS -   random 25/50 structure (12, 10, 640, 624, 2784) nas_score 244.38552856445312 params 80.721552\n",
      "10/14/2022 05:28:22 - INFO - DENAS -   random 26/50 structure (11, 8, 512, 752, 992) nas_score 274.84698486328125 params 57.336976\n",
      "10/14/2022 05:28:25 - INFO - DENAS -   random 27/50 structure (11, 9, 576, 656, 1408) nas_score 300.0719299316406 params 57.815632\n",
      "10/14/2022 05:28:30 - INFO - DENAS -   random 28/50 structure (12, 12, 768, 560, 2496) nas_score 182.16014099121094 params 71.98344\n",
      "10/14/2022 05:28:33 - INFO - DENAS -   random 29/50 structure (11, 8, 512, 544, 2144) nas_score 265.25030517578125 params 55.17216\n",
      "10/14/2022 05:28:37 - INFO - DENAS -   random 30/50 structure (10, 9, 576, 576, 2624) nas_score 256.6051940917969 params 61.78784\n",
      "10/14/2022 05:28:40 - INFO - DENAS -   random 31/50 structure (8, 11, 704, 640, 2592) nas_score 147.6556396484375 params 61.302912\n",
      "10/14/2022 05:28:43 - INFO - DENAS -   random 32/50 structure (11, 12, 768, 768, 1184) nas_score 295.49114990234375 params 70.473952\n",
      "10/14/2022 05:28:47 - INFO - DENAS -   random 33/50 structure (9, 9, 576, 672, 2816) nas_score 204.51071166992188 params 69.383904\n",
      "10/14/2022 05:28:51 - INFO - DENAS -   random 34/50 structure (12, 10, 640, 496, 2496) nas_score 149.5797882080078 params 60.679568\n",
      "10/14/2022 05:28:54 - INFO - DENAS -   random 35/50 structure (7, 11, 704, 704, 2976) nas_score 169.6655731201172 params 65.62096\n",
      "10/14/2022 05:28:59 - INFO - DENAS -   random 36/50 structure (10, 10, 640, 736, 2528) nas_score 275.8394470214844 params 79.5288\n",
      "10/14/2022 05:29:02 - INFO - DENAS -   random 37/50 structure (11, 11, 704, 672, 1408) nas_score 290.8549499511719 params 63.024608\n",
      "10/14/2022 05:29:05 - INFO - DENAS -   random 38/50 structure (12, 8, 512, 768, 736) nas_score 117.34862518310547 params 56.950656\n",
      "10/14/2022 05:29:09 - INFO - DENAS -   random 39/50 structure (9, 8, 512, 624, 2688) nas_score 140.53968811035156 params 61.522608\n",
      "10/14/2022 05:29:13 - INFO - DENAS -   random 40/50 structure (10, 10, 640, 672, 2304) nas_score 269.4963073730469 params 69.561312\n",
      "10/14/2022 05:29:19 - INFO - DENAS -   random 41/50 structure (12, 9, 576, 752, 2816) nas_score 223.0218048095703 params 95.629968\n",
      "10/14/2022 05:29:23 - INFO - DENAS -   random 42/50 structure (11, 9, 576, 752, 2592) nas_score 279.4496154785156 params 85.94472\n",
      "10/14/2022 05:29:27 - INFO - DENAS -   random 43/50 structure (12, 12, 768, 688, 1184) nas_score 142.95510864257812 params 66.832208\n",
      "10/14/2022 05:29:31 - INFO - DENAS -   random 44/50 structure (9, 9, 576, 720, 2880) nas_score 188.78500366210938 params 75.201552\n",
      "10/14/2022 05:29:36 - INFO - DENAS -   random 45/50 structure (12, 12, 768, 736, 1696) nas_score 190.66891479492188 params 80.57744\n",
      "10/14/2022 05:29:39 - INFO - DENAS -   random 46/50 structure (12, 12, 768, 688, 1408) nas_score 164.270263671875 params 70.533584\n",
      "10/14/2022 05:29:45 - INFO - DENAS -   random 47/50 structure (12, 11, 704, 768, 2624) nas_score 285.5487365722656 params 98.857728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/14/2022 05:29:48 - INFO - DENAS -   random 48/50 structure (8, 10, 640, 656, 1984) nas_score 157.05245971679688 params 55.113584\n",
      "10/14/2022 05:29:51 - INFO - DENAS -   random 49/50 structure (9, 9, 576, 608, 2400) nas_score 201.1036834716797 params 58.184448\n",
      "10/14/2022 05:29:54 - INFO - DENAS -   random 50/50 structure (11, 10, 640, 512, 2208) nas_score 287.7393493652344 params 55.522144\n",
      "10/14/2022 05:29:54 - INFO - DENAS -   random_num = 50\n",
      "10/14/2022 05:29:57 - INFO - DENAS -   mutation 1/25 structure (6, 9, 576, 768, 2912) nas_score 179.87596130371094 params 61.937088\n",
      "10/14/2022 05:29:59 - INFO - DENAS -   mutation 2/25 structure (10, 10, 640, 768, 1088) nas_score 301.97967529296875 params 60.876416\n",
      "10/14/2022 05:30:03 - INFO - DENAS -   mutation 3/25 structure (9, 10, 640, 608, 2400) nas_score 194.6211395263672 params 59.587008\n",
      "10/14/2022 05:30:06 - INFO - DENAS -   mutation 4/25 structure (9, 11, 704, 768, 1728) nas_score 211.99317932128906 params 67.855872\n",
      "10/14/2022 05:30:10 - INFO - DENAS -   mutation 5/25 structure (12, 11, 704, 464, 2624) nas_score 107.57535552978516 params 59.607984\n",
      "10/14/2022 05:30:13 - INFO - DENAS -   mutation 6/25 structure (10, 10, 640, 640, 1632) nas_score 262.67120361328125 params 57.62208\n",
      "10/14/2022 05:30:19 - INFO - DENAS -   mutation 7/25 structure (11, 11, 704, 752, 2592) nas_score 286.77117919921875 params 90.184208\n",
      "10/14/2022 05:30:25 - INFO - DENAS -   mutation 8/25 structure (12, 8, 512, 768, 2624) nas_score 190.70587158203125 params 91.772928\n",
      "10/14/2022 05:30:29 - INFO - DENAS -   mutation 9/25 structure (8, 10, 640, 768, 2528) nas_score 151.4256134033203 params 71.292928\n",
      "10/14/2022 05:30:34 - INFO - DENAS -   mutation 10/25 structure (10, 11, 704, 736, 2528) nas_score 281.6607666015625 params 81.41488\n",
      "10/14/2022 05:30:38 - INFO - DENAS -   mutation 11/25 structure (11, 10, 640, 592, 2656) nas_score 262.415283203125 params 70.077424\n",
      "10/14/2022 05:30:42 - INFO - DENAS -   mutation 12/25 structure (10, 8, 512, 736, 2528) nas_score 262.66900634765625 params 75.75664\n",
      "10/14/2022 05:30:46 - INFO - DENAS -   mutation 13/25 structure (10, 10, 640, 656, 2144) nas_score 255.93316650390625 params 65.7948\n",
      "10/14/2022 05:30:51 - INFO - DENAS -   mutation 14/25 structure (12, 11, 704, 624, 2784) nas_score 245.87783813476562 params 82.640784\n",
      "10/14/2022 05:30:54 - INFO - DENAS -   mutation 15/25 structure (8, 12, 768, 768, 2048) nas_score 157.68515014648438 params 68.539648\n",
      "10/14/2022 05:30:58 - INFO - DENAS -   mutation 16/25 structure (10, 11, 704, 576, 2624) nas_score 244.73263549804688 params 64.7408\n",
      "10/14/2022 05:31:02 - INFO - DENAS -   mutation 17/25 structure (12, 8, 512, 576, 2112) nas_score 134.2028350830078 params 61.647552\n",
      "10/14/2022 05:31:06 - INFO - DENAS -   mutation 18/25 structure (12, 10, 640, 576, 1728) nas_score 178.26275634765625 params 59.87808\n",
      "10/14/2022 05:31:09 - INFO - DENAS -   mutation 19/25 structure (8, 10, 640, 768, 2336) nas_score 150.7130584716797 params 68.932096\n",
      "10/14/2022 05:31:13 - INFO - DENAS -   mutation 20/25 structure (9, 8, 512, 752, 2464) nas_score 197.33547973632812 params 71.197008\n",
      "10/14/2022 05:31:17 - INFO - DENAS -   mutation 21/25 structure (12, 12, 768, 576, 1216) nas_score 127.85527801513672 params 56.3376\n",
      "10/14/2022 05:31:21 - INFO - DENAS -   mutation 22/25 structure (10, 9, 576, 688, 2624) nas_score 277.352294921875 params 73.870736\n",
      "10/14/2022 05:31:25 - INFO - DENAS -   mutation 23/25 structure (7, 12, 768, 704, 2976) nas_score 174.6195068359375 params 66.883872\n",
      "10/14/2022 05:31:30 - INFO - DENAS -   mutation 24/25 structure (11, 10, 640, 688, 2496) nas_score 272.5540466308594 params 79.075696\n",
      "10/14/2022 05:31:32 - INFO - DENAS -   mutation 25/25 structure (11, 11, 704, 768, 416) nas_score 310.12640380859375 params 55.324576\n",
      "10/14/2022 05:31:32 - INFO - DENAS -   mutation_num = 25\n",
      "10/14/2022 05:31:37 - INFO - DENAS -   crossover 1/25 structure (12, 11, 704, 704, 2496) nas_score 277.1458435058594 params 88.41504\n",
      "10/14/2022 05:31:41 - INFO - DENAS -   crossover 2/25 structure (8, 10, 640, 768, 2720) nas_score 145.66542053222656 params 73.65376\n",
      "10/14/2022 05:31:46 - INFO - DENAS -   crossover 3/25 structure (12, 10, 640, 560, 2496) nas_score 216.3732147216797 params 68.538192\n",
      "10/14/2022 05:31:52 - INFO - DENAS -   crossover 4/25 structure (12, 12, 768, 624, 2784) nas_score 242.30099487304688 params 84.560016\n",
      "10/14/2022 05:31:55 - INFO - DENAS -   crossover 5/25 structure (12, 10, 640, 624, 1408) nas_score 193.0673828125 params 60.098064\n",
      "10/14/2022 05:31:58 - INFO - DENAS -   crossover 6/25 structure (8, 10, 640, 656, 2048) nas_score 158.88995361328125 params 55.78584\n",
      "10/14/2022 05:32:03 - INFO - DENAS -   crossover 7/25 structure (11, 9, 576, 752, 2848) nas_score 268.0054016113281 params 90.1828\n",
      "10/14/2022 05:32:08 - INFO - DENAS -   crossover 8/25 structure (12, 12, 768, 528, 2048) nas_score 218.70806884765625 params 62.174064\n",
      "10/14/2022 05:32:11 - INFO - DENAS -   crossover 9/25 structure (11, 11, 704, 640, 1824) nas_score 279.98834228515625 params 65.866656\n",
      "10/14/2022 05:32:15 - INFO - DENAS -   crossover 10/25 structure (11, 8, 512, 768, 1888) nas_score 287.3402404785156 params 73.71728\n",
      "10/14/2022 05:32:20 - INFO - DENAS -   crossover 11/25 structure (12, 10, 640, 624, 2496) nas_score 259.1663513183594 params 76.405008\n",
      "10/14/2022 05:32:22 - INFO - DENAS -   crossover 12/25 structure (8, 8, 512, 688, 1984) nas_score 162.34759521484375 params 55.001424\n",
      "10/14/2022 05:32:25 - INFO - DENAS -   crossover 13/25 structure (11, 10, 640, 672, 1408) nas_score 293.8133239746094 params 61.130144\n",
      "10/14/2022 05:32:29 - INFO - DENAS -   crossover 14/25 structure (9, 11, 704, 608, 2400) nas_score 190.74725341796875 params 60.989568\n",
      "10/14/2022 05:32:33 - INFO - DENAS -   crossover 15/25 structure (11, 10, 640, 768, 1888) nas_score 301.0667419433594 params 78.04688\n",
      "10/14/2022 05:32:36 - INFO - DENAS -   crossover 16/25 structure (12, 11, 704, 720, 1248) nas_score 210.32046508789062 params 68.85432\n",
      "10/14/2022 05:32:40 - INFO - DENAS -   crossover 17/25 structure (8, 10, 640, 752, 2720) nas_score 147.10635375976562 params 72.108048\n",
      "10/14/2022 05:32:44 - INFO - DENAS -   crossover 18/25 structure (8, 9, 576, 656, 2848) nas_score 145.6713409423828 params 62.844016\n"
     ]
    }
   ],
   "source": [
    "!cd /home/vmagent/app/aidk/DeNas && python -u search.py --domain bert --conf ../conf/denas/nlp/aidk_denas_bert.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch DE-NAS Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/runpy.py:127: RuntimeWarning: 'intel_extension_for_pytorch.cpu.launch' found in sys.modules after import of package 'intel_extension_for_pytorch.cpu', but prior to execution of 'intel_extension_for_pytorch.cpu.launch'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2022-10-14 05:49:14,458 - __main__ - INFO - MASTER_ADDR=127.0.0.1\n",
      "2022-10-14 05:49:14,458 - __main__ - INFO - MASTER_PORT=29500\n",
      "2022-10-14 05:49:14,458 - __main__ - INFO - I_MPI_PIN_DOMAIN=[0xfffffffffff0,]\n",
      "2022-10-14 05:49:14,459 - __main__ - WARNING - Both TCMalloc and JeMalloc are not found in $CONDA_PREFIX/lib or $VIRTUAL_ENV/lib or /.local/lib/ or /usr/local/lib/ or /usr/local/lib64/ or /usr/lib or /usr/lib64 or /root/.local/lib/ so the LD_PRELOAD environment variable will not be set. This may drop the performance\n",
      "2022-10-14 05:49:14,459 - __main__ - INFO - OMP_NUM_THREADS=44\n",
      "2022-10-14 05:49:14,459 - __main__ - INFO - Using Intel OpenMP\n",
      "2022-10-14 05:49:14,459 - __main__ - INFO - KMP_AFFINITY=granularity=fine,compact,1,0\n",
      "2022-10-14 05:49:14,459 - __main__ - INFO - KMP_BLOCKTIME=1\n",
      "2022-10-14 05:49:14,459 - __main__ - INFO - LD_PRELOAD=/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/libiomp5.so\n",
      "2022-10-14 05:49:14,459 - __main__ - INFO - CCL_WORKER_COUNT=4\n",
      "2022-10-14 05:49:14,459 - __main__ - INFO - CCL_WORKER_AFFINITY=0,1,2,3\n",
      "2022-10-14 05:49:14,459 - __main__ - INFO - ['mpiexec.hydra', '-l', '-np', '1', '-ppn', '1', '-genv', 'I_MPI_PIN_DOMAIN=[0xfffffffffff0,]', '-genv', 'OMP_NUM_THREADS=44', '/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/bin/python', '-u', './trainer/train.py', '--domain', 'bert', '--conf', '/home/vmagent/app/aidk/conf/denas/nlp/aidk_denas_train_bert.conf', '--do_lower_case']\n",
      "[0] 10/14/2022 05:49:15 - INFO - module.nlp.tokenization -   loading vocabulary file\n",
      "[0] 10/14/2022 05:49:15 - INFO - trainer.data.nlp_build_datasets -   load 1027 examples!\n",
      "[0] 10/14/2022 05:49:17 - INFO - module.nlp.tokenization -   loading vocabulary file\n",
      "[0] 10/14/2022 05:49:17 - INFO - trainer.data.nlp_build_datasets -   load 1680 examples!\n",
      "[0] /opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "[0]   warnings.warn(_create_warning_msg(\n",
      "[0] loading archive file /home/vmagent/app/dataset/bert-base-uncased/\n",
      "[0] 10/14/2022 05:49:20 - INFO - nlp.supernet_bert -   Model config {\n",
      "[0]   \"architectures\": [\n",
      "[0]     \"BertForMaskedLM\"\n",
      "[0]   ],\n",
      "[0]   \"attention_probs_dropout_prob\": 0.1,\n",
      "[0]   \"gradient_checkpointing\": false,\n",
      "[0]   \"hidden_act\": \"gelu\",\n",
      "[0]   \"hidden_dropout_prob\": 0.1,\n",
      "[0]   \"hidden_size\": 768,\n",
      "[0]   \"initializer_range\": 0.02,\n",
      "[0]   \"intermediate_size\": 3072,\n",
      "[0]   \"layer_norm_eps\": 1e-12,\n",
      "[0]   \"max_position_embeddings\": 512,\n",
      "[0]   \"model_type\": \"bert\",\n",
      "[0]   \"num_attention_heads\": 12,\n",
      "[0]   \"num_hidden_layers\": 12,\n",
      "[0]   \"pad_token_id\": 0,\n",
      "[0]   \"position_embedding_type\": \"absolute\",\n",
      "[0]   \"transformers_version\": \"4.6.0.dev0\",\n",
      "[0]   \"type_vocab_size\": 2,\n",
      "[0]   \"use_cache\": true,\n",
      "[0]   \"vocab_size\": 30522\n",
      "[0] }\n",
      "[0] \n",
      "[0] 10/14/2022 05:49:20 - INFO - nlp.supernet_bert -   Model config {\n",
      "[0]   \"architectures\": [\n",
      "[0]     \"BertForMaskedLM\"\n",
      "[0]   ],\n",
      "[0]   \"attention_probs_dropout_prob\": 0.1,\n",
      "[0]   \"gradient_checkpointing\": false,\n",
      "[0]   \"hidden_act\": \"gelu\",\n",
      "[0]   \"hidden_dropout_prob\": 0.1,\n",
      "[0]   \"hidden_size\": 768,\n",
      "[0]   \"initializer_range\": 0.02,\n",
      "[0]   \"intermediate_size\": 3072,\n",
      "[0]   \"layer_norm_eps\": 1e-12,\n",
      "[0]   \"max_position_embeddings\": 512,\n",
      "[0]   \"model_type\": \"bert\",\n",
      "[0]   \"num_attention_heads\": 12,\n",
      "[0]   \"num_hidden_layers\": 12,\n",
      "[0]   \"pad_token_id\": 0,\n",
      "[0]   \"position_embedding_type\": \"absolute\",\n",
      "[0]   \"transformers_version\": \"4.6.0.dev0\",\n",
      "[0]   \"type_vocab_size\": 2,\n",
      "[0]   \"use_cache\": true,\n",
      "[0]   \"vocab_size\": 30522\n",
      "[0] }\n",
      "[0] \n",
      "[0] Weights of SuperBertForQuestionAnswering not initialized from pretrained model: ['bert.dense_fit.weight', 'bert.dense_fit.bias', 'qa_outputs.weight', 'qa_outputs.bias']\n",
      "[0] Weights from pretrained model not used in SuperBertForQuestionAnswering: ['bert.cls.predictions.bias', 'bert.cls.predictions.transform.dense.weight', 'bert.cls.predictions.transform.dense.bias', 'bert.cls.predictions.decoder.weight', 'bert.cls.seq_relationship.weight', 'bert.cls.seq_relationship.bias', 'bert.cls.predictions.transform.LayerNorm.weight', 'bert.cls.predictions.transform.LayerNorm.bias']\n",
      "[0] 10/14/2022 05:49:22 - INFO - model.nlp.bert_model_builder -   subbert_config: {'sample_layer_num': 11, 'sample_num_attention_heads': [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11], 'sample_qkv_sizes': [704, 704, 704, 704, 704, 704, 704, 704, 704, 704, 704], 'sample_hidden_size': 768, 'sample_intermediate_sizes': [416, 416, 416, 416, 416, 416, 416, 416, 416, 416, 416]}\n",
      "[0] 10/14/2022 05:49:22 - INFO - model.nlp.bert_model_builder -   Total parameters: 55324576\n",
      "[0]   Num examples = 1027\n",
      "[0]   Batch size = 12\n",
      "[0]   Num steps = 171\n",
      "[0] 10/14/2022 05:49:22 - INFO - model.nlp.bert_trainer -   ***** Running training *****\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s][0] \n",
      "Iteration:   0%|          | 0/88 [00:00<?, ?it/s]\u001b[A[0] /home/vmagent/app/aidk/DeNas/module/nlp/optimization.py:249: UserWarning: This overload of add_ is deprecated:\n",
      "[0] \tadd_(Number alpha, Tensor other)\n",
      "[0] Consider using one of the following signatures instead:\n",
      "[0] \tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
      "[0]   next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "[0] \n",
      "Iteration:   1%|1         | 1/88 [00:07<10:24,  7.18s/it]\u001b[A[0] \n",
      "Iteration:   2%|2         | 2/88 [00:09<05:49,  4.06s/it]\u001b[A[0] \n",
      "Iteration:   3%|3         | 3/88 [00:10<04:08,  2.92s/it]\u001b[A[0] \n",
      "Iteration:   5%|4         | 4/88 [00:11<03:11,  2.28s/it]\u001b[A[0] \n",
      "Iteration:   6%|5         | 5/88 [00:13<02:37,  1.90s/it]\u001b[A[0] \n",
      "Iteration:   7%|6         | 6/88 [00:14<02:21,  1.72s/it]\u001b[A[0] \n",
      "Iteration:   8%|7         | 7/88 [00:15<02:07,  1.57s/it]\u001b[A[0] \n",
      "Iteration:   9%|9         | 8/88 [00:17<01:58,  1.49s/it][0] \u001b[A[0] \n",
      "Iteration:  10%|#         | 9/88 [00:18<01:50,  1.40s/it]\u001b[A[0] \n",
      "Iteration:  11%|#1        | 10/88 [00:19<01:47,  1.37s/it]\u001b[A[0] \n",
      "Iteration:  12%|#2        | 11/88 [00:20<01:42,  1.33s/it]\u001b[A[0] \n",
      "Iteration:  14%|#3        | 12/88 [00:22<01:39,  1.30s/it]\u001b[A[0] \n",
      "Iteration:  15%|#4        | 13/88 [00:23<01:39,  1.33s/it]\u001b[A[0] \n",
      "Iteration:  16%|#5        | 14/88 [00:24<01:37,  1.32s/it]\u001b[A[0] \n",
      "Iteration:  17%|#7        | 15/88 [00:25<01:34,  1.29s/it]\u001b[A[0] \n",
      "Iteration:  18%|#8        | 16/88 [00:27<01:34,  1.31s/it]\u001b[A[0] \n",
      "Iteration:  19%|#9        | 17/88 [00:28<01:36,  1.36s/it]\u001b[A[0] \n",
      "Iteration:  20%|##        | 18/88 [00:30<01:32,  1.32s/it]\u001b[A[0] \n",
      "Iteration:  22%|##1       | 19/88 [00:31<01:29,  1.30s/it]\u001b[A[0] \n",
      "Iteration:  23%|##2       | 20/88 [00:32<01:30,  1.34s/it]\u001b[A[0] \n",
      "Iteration:  24%|##3       | 21/88 [00:34<01:29,  1.34s/it]\u001b[A[0] \n",
      "Iteration:  25%|##5       | 22/88 [00:35<01:27,  1.32s/it]\u001b[A[0] \n",
      "Iteration:  26%|##6       | 23/88 [00:36<01:23,  1.28s/it][0] \u001b[A[0] \n",
      "Iteration:  27%|##7       | 24/88 [00:37<01:19,  1.25s/it]\u001b[A[0] \n",
      "Iteration:  28%|##8       | 25/88 [00:38<01:18,  1.24s/it]\u001b[A[0] \n",
      "Iteration:  30%|##9       | 26/88 [00:40<01:16,  1.23s/it]\u001b[A[0] \n",
      "Iteration:  31%|###       | 27/88 [00:41<01:14,  1.22s/it]\u001b[A[0] \n",
      "Iteration:  32%|###1      | 28/88 [00:42<01:14,  1.24s/it]\u001b[A[0] \n",
      "Iteration:  33%|###2      | 29/88 [00:43<01:12,  1.23s/it]\u001b[A[0] \n",
      "Iteration:  34%|###4      | 30/88 [00:45<01:10,  1.22s/it]\u001b[A[0] \n",
      "Iteration:  35%|###5      | 31/88 [00:46<01:09,  1.22s/it]\u001b[A[0] \n",
      "Iteration:  36%|###6      | 32/88 [00:47<01:09,  1.25s/it]\u001b[A[0] \n",
      "Iteration:  38%|###7      | 33/88 [00:48<01:10,  1.27s/it]\u001b[A[0] \n",
      "Iteration:  39%|###8      | 34/88 [00:50<01:08,  1.26s/it]\u001b[A[0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  40%|###9      | 35/88 [00:51<01:07,  1.27s/it]\u001b[A[0] \n",
      "Iteration:  41%|####      | 36/88 [00:52<01:08,  1.31s/it]\u001b[A[0] \n",
      "Iteration:  42%|####2     | 37/88 [00:54<01:05,  1.29s/it]\u001b[A[0] \n",
      "Iteration:  43%|####3     | 38/88 [00:55<01:05,  1.32s/it]\u001b[A[0] \n",
      "Iteration:  44%|####4     | 39/88 [00:56<01:04,  1.32s/it]\u001b[A[0] \n",
      "Iteration:  45%|####5     | 40/88 [00:58<01:05,  1.37s/it]\u001b[A[0] \n",
      "Iteration:  47%|####6     | 41/88 [00:59<01:02,  1.32s/it][0] \u001b[A[0] \n",
      "Iteration:  48%|####7     | 42/88 [01:00<01:01,  1.34s/it]\u001b[A[0] \n",
      "Iteration:  49%|####8     | 43/88 [01:02<00:58,  1.31s/it]\u001b[A[0] \n",
      "Iteration:  50%|#####     | 44/88 [01:03<00:57,  1.30s/it]\u001b[A[0] \n",
      "Iteration:  51%|#####1    | 45/88 [01:04<00:54,  1.27s/it][0] \u001b[A[0] \n",
      "Iteration:  52%|#####2    | 46/88 [01:05<00:52,  1.25s/it]\u001b[A[0] \n",
      "Iteration:  53%|#####3    | 47/88 [01:07<00:51,  1.27s/it][0] \u001b[A[0] \n",
      "Iteration:  55%|#####4    | 48/88 [01:08<00:49,  1.25s/it]\u001b[A[0] 10/14/2022 05:50:31 - INFO - model.nlp.bert_trainer -   ***** Running evaluation *****\n",
      "[0] 10/14/2022 05:50:31 - INFO - model.nlp.bert_trainer -     Epoch = 0 iter 49 step\n",
      "[0] 10/14/2022 05:50:31 - INFO - model.nlp.bert_trainer -     Num examples = 1680\n",
      "[0] 10/14/2022 05:51:51 - INFO - model.nlp.utils -   ***** Eval results *****\n",
      "[0] 10/14/2022 05:51:51 - INFO - model.nlp.utils -     cls_loss = 4.855080361268958\n",
      "[0] 10/14/2022 05:51:51 - INFO - model.nlp.utils -     em = 4.880952380952381\n",
      "[0] 10/14/2022 05:51:51 - INFO - model.nlp.utils -     f1 = 11.284467434282645\n",
      "[0] 10/14/2022 05:51:51 - INFO - model.nlp.utils -     global_step = 49\n",
      "[0] 10/14/2022 05:51:51 - INFO - model.nlp.utils -     infer_cnt = 54\n",
      "[0] 10/14/2022 05:51:51 - INFO - model.nlp.utils -     infer_time = 250.4530555555555\n",
      "[0] 10/14/2022 05:51:51 - INFO - model.nlp.utils -     loss = 4.855080361268958\n",
      "[0] 10/14/2022 05:51:51 - INFO - root -   ** ** * Saving fine-tuned model ** ** * \n",
      "[0] \n",
      "Iteration:  56%|#####5    | 49/88 [02:29<16:25, 25.27s/it]\u001b[A[0] \n",
      "Iteration:  57%|#####6    | 50/88 [02:30<11:26, 18.06s/it]\u001b[A[0] \n",
      "Iteration:  58%|#####7    | 51/88 [02:31<07:58, 12.92s/it]\u001b[A[0] \n",
      "Iteration:  59%|#####9    | 52/88 [02:32<05:35,  9.33s/it]\u001b[A[0] \n",
      "Iteration:  60%|######    | 53/88 [02:33<03:58,  6.81s/it]\u001b[A[0] \n",
      "Iteration:  61%|######1   | 54/88 [02:34<02:51,  5.05s/it]\u001b[A[0] \n",
      "Iteration:  62%|######2   | 55/88 [02:35<02:05,  3.81s/it]\u001b[A[0] \n",
      "Iteration:  64%|######3   | 56/88 [02:36<01:34,  2.94s/it]\u001b[A[0] \n",
      "Iteration:  65%|######4   | 57/88 [02:37<01:12,  2.33s/it]\u001b[A[0] \n",
      "Iteration:  66%|######5   | 58/88 [02:38<00:57,  1.92s/it]\u001b[A[0] \n",
      "Iteration:  67%|######7   | 59/88 [02:39<00:48,  1.67s/it]\u001b[A[0] \n",
      "Iteration:  68%|######8   | 60/88 [02:40<00:40,  1.45s/it][0] \u001b[A[0] \n",
      "Iteration:  69%|######9   | 61/88 [02:41<00:34,  1.29s/it][0] \u001b[A[0] \n",
      "Iteration:  70%|#######   | 62/88 [02:42<00:30,  1.18s/it]\u001b[A[0] \n",
      "Iteration:  72%|#######1  | 63/88 [02:43<00:27,  1.12s/it][0] \u001b[A[0] \n",
      "Iteration:  73%|#######2  | 64/88 [02:44<00:25,  1.07s/it]\u001b[A[0] \n",
      "Iteration:  74%|#######3  | 65/88 [02:45<00:23,  1.03s/it]\u001b[A[0] \n",
      "Iteration:  75%|#######5  | 66/88 [02:46<00:22,  1.03s/it]\u001b[A[0] \n",
      "Iteration:  76%|#######6  | 67/88 [02:47<00:21,  1.03s/it]\u001b[A[0] \n",
      "Iteration:  77%|#######7  | 68/88 [02:48<00:20,  1.01s/it]\u001b[A[0] \n",
      "Iteration:  78%|#######8  | 69/88 [02:49<00:19,  1.00s/it][0] \u001b[A[0] \n",
      "Iteration:  80%|#######9  | 70/88 [02:50<00:18,  1.02s/it]\u001b[A[0] \n",
      "Iteration:  81%|########  | 71/88 [02:51<00:16,  1.00it/s][0] \u001b[A[0] \n",
      "Iteration:  82%|########1 | 72/88 [02:52<00:15,  1.01it/s]\u001b[A[0] \n",
      "Iteration:  83%|########2 | 73/88 [02:52<00:14,  1.02it/s]\u001b[A[0] \n",
      "Iteration:  84%|########4 | 74/88 [02:53<00:13,  1.02it/s]\u001b[A[0] \n",
      "Iteration:  85%|########5 | 75/88 [02:55<00:15,  1.18s/it]\u001b[A[0] \n",
      "Iteration:  86%|########6 | 76/88 [02:56<00:13,  1.14s/it][0] \u001b[A[0] \n",
      "Iteration:  88%|########7 | 77/88 [02:57<00:12,  1.09s/it]\u001b[A[0] \n",
      "Iteration:  89%|########8 | 78/88 [02:58<00:10,  1.05s/it]\u001b[A[0] \n",
      "Iteration:  90%|########9 | 79/88 [02:59<00:09,  1.03s/it]\u001b[A[0] \n",
      "Iteration:  91%|######### | 80/88 [03:00<00:08,  1.02s/it]\u001b[A[0] \n",
      "Iteration:  92%|#########2| 81/88 [03:01<00:07,  1.00s/it]\u001b[A[0] \n",
      "Iteration:  93%|#########3| 82/88 [03:02<00:05,  1.01it/s]\u001b[A[0] \n",
      "Iteration:  94%|#########4| 83/88 [03:03<00:04,  1.01it/s][0] \u001b[A[0] \n",
      "Iteration:  95%|#########5| 84/88 [03:04<00:03,  1.00it/s]\u001b[A[0] \n",
      "Iteration:  97%|#########6| 85/88 [03:05<00:02,  1.00it/s]\u001b[A[0] \n",
      "Iteration:  98%|#########7| 86/88 [03:06<00:02,  1.03s/it]\u001b[A[0] \n",
      "Iteration:  99%|#########8| 87/88 [03:07<00:01,  1.01s/it][0] \u001b[A[0] \n",
      "Iteration: 100%|##########| 88/88 [03:08<00:00,  2.14s/it]\u001b[A[0] \n",
      "Epoch:  50%|█████     | 1/2 [03:08<03:08, 188.63s/it][0] \n",
      "Iteration:   0%|          | 0/88 [00:00<?, ?it/s]\u001b[A[0] \n",
      "Iteration:   1%|1         | 1/88 [00:12<18:06, 12.49s/it]\u001b[A[0] \n",
      "Iteration:   2%|2         | 2/88 [00:13<08:27,  5.90s/it]\u001b[A[0] \n",
      "Iteration:   3%|3         | 3/88 [00:15<05:23,  3.81s/it][0] \u001b[A[0] \n",
      "Iteration:   5%|4         | 4/88 [00:16<04:01,  2.87s/it]\u001b[A[0] \n",
      "Iteration:   6%|5         | 5/88 [00:17<03:08,  2.27s/it]\u001b[A[0] \n",
      "Iteration:   7%|6         | 6/88 [00:19<02:42,  1.98s/it]\u001b[A[0] \n",
      "Iteration:   8%|7         | 7/88 [00:20<02:19,  1.72s/it]\u001b[A[0] \n",
      "Iteration:   9%|9         | 8/88 [00:21<02:06,  1.58s/it][0] \u001b[A[0] \n",
      "Iteration:  10%|#         | 9/88 [00:22<01:56,  1.47s/it]\u001b[A[0] \n",
      "Iteration:  11%|#1        | 10/88 [00:24<01:49,  1.41s/it][0] \u001b[A[0] 10/14/2022 05:52:56 - INFO - model.nlp.bert_trainer -   ***** Running evaluation *****\n",
      "[0] 10/14/2022 05:52:56 - INFO - model.nlp.bert_trainer -     Epoch = 1 iter 99 step\n",
      "[0] 10/14/2022 05:52:56 - INFO - model.nlp.bert_trainer -     Num examples = 1680\n",
      "[0] 10/14/2022 05:54:17 - INFO - model.nlp.utils -   ***** Eval results *****\n",
      "[0] 10/14/2022 05:54:17 - INFO - model.nlp.utils -     cls_loss = 3.3257308223030786\n",
      "[0] 10/14/2022 05:54:17 - INFO - model.nlp.utils -     em = 7.738095238095238\n",
      "[0] 10/14/2022 05:54:17 - INFO - model.nlp.utils -     f1 = 13.126335079769465\n",
      "[0] 10/14/2022 05:54:17 - INFO - model.nlp.utils -     global_step = 99\n",
      "[0] 10/14/2022 05:54:17 - INFO - model.nlp.utils -     infer_cnt = 54\n",
      "[0] 10/14/2022 05:54:17 - INFO - model.nlp.utils -     infer_time = 281.00470370370374\n",
      "[0] 10/14/2022 05:54:17 - INFO - model.nlp.utils -     loss = 3.3257308223030786\n",
      "[0] 10/14/2022 05:54:17 - INFO - root -   ** ** * Saving fine-tuned model ** ** * \n",
      "[0] \n",
      "Iteration:  12%|#2        | 11/88 [01:47<33:49, 26.35s/it]\u001b[A[0] \n",
      "Iteration:  14%|#3        | 12/88 [01:48<23:40, 18.70s/it]\u001b[A[0] \n",
      "Iteration:  15%|#4        | 13/88 [01:49<16:38, 13.32s/it]\u001b[A[0] \n",
      "Iteration:  16%|#5        | 14/88 [01:50<11:48,  9.58s/it]\u001b[A[0] \n",
      "Iteration:  17%|#7        | 15/88 [01:51<08:28,  6.97s/it]\u001b[A[0] \n",
      "Iteration:  18%|#8        | 16/88 [01:51<06:11,  5.16s/it]\u001b[A[0] \n",
      "Iteration:  19%|#9        | 17/88 [01:52<04:36,  3.89s/it][0] \u001b[A[0] \n",
      "Iteration:  20%|##        | 18/88 [01:53<03:29,  3.00s/it][0] \u001b[A[0] \n",
      "Iteration:  22%|##1       | 19/88 [01:54<02:43,  2.37s/it]\u001b[A[0] \n",
      "Iteration:  23%|##2       | 20/88 [01:55<02:12,  1.94s/it]\u001b[A[0] \n",
      "Iteration:  24%|##3       | 21/88 [01:56<01:51,  1.66s/it]\u001b[A[0] \n",
      "Iteration:  25%|##5       | 22/88 [01:57<01:34,  1.44s/it]\u001b[A[0] \n",
      "Iteration:  26%|##6       | 23/88 [01:58<01:23,  1.29s/it]\u001b[A[0] \n",
      "Iteration:  27%|##7       | 24/88 [01:59<01:15,  1.19s/it]\u001b[A[0] \n",
      "Iteration:  28%|##8       | 25/88 [02:00<01:09,  1.11s/it]\u001b[A[0] \n",
      "Iteration:  30%|##9       | 26/88 [02:01<01:05,  1.06s/it][0] \u001b[A[0] \n",
      "Iteration:  31%|###       | 27/88 [02:02<01:02,  1.03s/it]\u001b[A[0] \n",
      "Iteration:  32%|###1      | 28/88 [02:03<01:00,  1.01s/it]\u001b[A[0] \n",
      "Iteration:  33%|###2      | 29/88 [02:04<00:58,  1.01it/s]\u001b[A[0] \n",
      "Iteration:  34%|###4      | 30/88 [02:05<00:58,  1.00s/it]\u001b[A[0] \n",
      "Iteration:  35%|###5      | 31/88 [02:06<00:56,  1.01it/s]\u001b[A[0] \n",
      "Iteration:  36%|###6      | 32/88 [02:07<00:55,  1.01it/s][0] \u001b[A[0] \n",
      "Iteration:  38%|###7      | 33/88 [02:08<00:53,  1.02it/s]\u001b[A[0] \n",
      "Iteration:  39%|###8      | 34/88 [02:09<00:52,  1.02it/s][0] \u001b[A[0] \n",
      "Iteration:  40%|###9      | 35/88 [02:10<00:51,  1.03it/s][0] \u001b[A[0] \n",
      "Iteration:  41%|####      | 36/88 [02:11<00:50,  1.03it/s]\u001b[A[0] \n",
      "Iteration:  42%|####2     | 37/88 [02:12<00:49,  1.03it/s]\u001b[A[0] \n",
      "Iteration:  43%|####3     | 38/88 [02:12<00:48,  1.04it/s]\u001b[A[0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  44%|####4     | 39/88 [02:14<00:49,  1.00s/it][0] \u001b[A[0] \n",
      "Iteration:  45%|####5     | 40/88 [02:15<00:47,  1.01it/s]\u001b[A[0] \n",
      "Iteration:  47%|####6     | 41/88 [02:16<00:46,  1.01it/s]\u001b[A[0] \n",
      "Iteration:  48%|####7     | 42/88 [02:16<00:44,  1.02it/s]\u001b[A[0] \n",
      "Iteration:  49%|####8     | 43/88 [02:17<00:43,  1.03it/s]\u001b[A[0] \n",
      "Iteration:  50%|#####     | 44/88 [02:18<00:42,  1.03it/s]\u001b[A[0] \n",
      "Iteration:  51%|#####1    | 45/88 [02:19<00:41,  1.03it/s]\u001b[A[0] \n",
      "Iteration:  52%|#####2    | 46/88 [02:20<00:41,  1.02it/s]\u001b[A[0] \n",
      "Iteration:  53%|#####3    | 47/88 [02:21<00:39,  1.03it/s]\u001b[A[0] \n",
      "Iteration:  55%|#####4    | 48/88 [02:22<00:38,  1.03it/s]\u001b[A[0] \n",
      "Iteration:  56%|#####5    | 49/88 [02:23<00:37,  1.04it/s]\u001b[A[0] \n",
      "Iteration:  57%|#####6    | 50/88 [02:24<00:38,  1.02s/it][0] \u001b[A[0] \n",
      "Iteration:  58%|#####7    | 51/88 [02:25<00:37,  1.02s/it]\u001b[A[0] \n",
      "Iteration:  59%|#####9    | 52/88 [02:26<00:36,  1.01s/it]\u001b[A[0] \n",
      "Iteration:  60%|######    | 53/88 [02:27<00:34,  1.00it/s]\u001b[A[0] \n",
      "Iteration:  61%|######1   | 54/88 [02:28<00:34,  1.01s/it]\u001b[A[0] \n",
      "Iteration:  62%|######2   | 55/88 [02:29<00:33,  1.01s/it]\u001b[A[0] \n",
      "Iteration:  64%|######3   | 56/88 [02:30<00:31,  1.00it/s]\u001b[A[0] \n",
      "Iteration:  65%|######4   | 57/88 [02:31<00:31,  1.01s/it]\u001b[A[0] \n",
      "Iteration:  66%|######5   | 58/88 [02:33<00:31,  1.06s/it]\u001b[A[0] \n",
      "Iteration:  67%|######7   | 59/88 [02:34<00:32,  1.11s/it]\u001b[A[0] \n",
      "Iteration:  68%|######8   | 60/88 [02:35<00:31,  1.12s/it]\u001b[A[0] 10/14/2022 05:55:07 - INFO - model.nlp.bert_trainer -   ***** Running evaluation *****\n",
      "[0] 10/14/2022 05:55:07 - INFO - model.nlp.bert_trainer -     Epoch = 1 iter 149 step\n",
      "[0] 10/14/2022 05:55:07 - INFO - model.nlp.bert_trainer -     Num examples = 1680\n",
      "[0] 10/14/2022 05:56:29 - INFO - model.nlp.utils -   ***** Eval results *****\n",
      "[0] 10/14/2022 05:56:29 - INFO - model.nlp.utils -     cls_loss = 3.1966337180528486\n",
      "[0] 10/14/2022 05:56:29 - INFO - model.nlp.utils -     em = 6.190476190476191\n",
      "[0] 10/14/2022 05:56:29 - INFO - model.nlp.utils -     f1 = 13.087394593086758\n",
      "[0] 10/14/2022 05:56:29 - INFO - model.nlp.utils -     global_step = 149\n",
      "[0] 10/14/2022 05:56:29 - INFO - model.nlp.utils -     infer_cnt = 54\n",
      "[0] 10/14/2022 05:56:29 - INFO - model.nlp.utils -     infer_time = 303.48650000000004\n",
      "[0] 10/14/2022 05:56:29 - INFO - model.nlp.utils -     loss = 3.1966337180528486\n",
      "[0] \n",
      "Iteration:  69%|######9   | 61/88 [03:59<11:38, 25.87s/it]\u001b[A[0] \n",
      "Iteration:  70%|#######   | 62/88 [04:00<08:02, 18.54s/it]\u001b[A[0] \n",
      "Iteration:  72%|#######1  | 63/88 [04:01<05:32, 13.32s/it]\u001b[A[0] \n",
      "Iteration:  73%|#######2  | 64/88 [04:02<03:51,  9.65s/it]\u001b[A[0] \n",
      "Iteration:  74%|#######3  | 65/88 [04:03<02:43,  7.10s/it]\u001b[A[0] \n",
      "Iteration:  75%|#######5  | 66/88 [04:04<01:56,  5.28s/it]\u001b[A[0] \n",
      "Iteration:  76%|#######6  | 67/88 [04:05<01:23,  3.99s/it]\u001b[A[0] \n",
      "Iteration:  77%|#######7  | 68/88 [04:07<01:02,  3.14s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "!cd /home/vmagent/app/aidk/DeNas && python -m intel_extension_for_pytorch.cpu.launch --distributed --nproc_per_node=1 --nnodes=1 ./trainer/train.py --domain bert --conf /home/vmagent/app/aidk/conf/denas/nlp/aidk_denas_train_bert.conf --do_lower_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DE-NAS Performance on BERT\n",
    "* Overall DE-NAS performance on BERT\n",
    "\n",
    "<center>\n",
    "<img src=\"./img/Overall_Performance.png\" width=\"600\"/><figure>Overall Performance</figure>\n",
    "</center>\n",
    "\n",
    "DE-NAS assists BERT-base with the same training setting except the early stop, which delivers 1.64x parameter reduction, 7.15x training speedup and 1.01 F1 score improvement.\n",
    "\n",
    "* Training Optimization\n",
    "\n",
    "    * The DE-NAS helps the BERT delivers the 1.56x speedup within full epoch training.\n",
    "    * With the early stop optimization, the DE-BERT achieves further 4.59x speedup, and totally 7.15x speedup.\n",
    "    * With the distribution optimization (2 processes in 1 SKX node), the DE-BERT delivers 1.38x speedup, and totally 9.84x speedup.\n",
    "\n",
    "<center>\n",
    "<img src=\"./img/Training_Performance.png\" width=\"600\"/><figure>Training Optimization Performance</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p id=\"4\"></p>\n",
    "\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The DE-NAS deployed on BERT helps it deliver a lighter (1.64x parameter reduction) and faster (7.15x speedup) model within the similar performance (1.01 F1 score improvement).\n",
    "* With the training script optimization, the DE-NAS can help BERT deliver more performance speedup."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
