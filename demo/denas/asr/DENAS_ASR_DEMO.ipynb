{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4682c66d",
   "metadata": {},
   "source": [
    "# DENAS ASR DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70d64a",
   "metadata": {},
   "source": [
    "DE-NAS is a train-free and hardware-aware NAS. This demo mainly introduces ASR integration with DE-NAS to search lighter, faster and high performance transformer-based ASR model in a training-free way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337f3e2b",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "* [DENAS ASR Search Space](#DENAS-ASR-Search-Space)\n",
    "* [Performance Overview](#Performance-Overview)\n",
    "* [Demo](#Demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1685c8",
   "metadata": {},
   "source": [
    "# DENAS ASR Search Space\n",
    "\n",
    "Recently, Transformer has achieved remarkable success in several automatic speech recognition tasks. The progresses are highly relevant to the architecture design, then it is worthwhile to propose Transformer based Neural Architecture Search to search for better automatically. We will propose an unified effective method to synaptic diversity of MSA(multi-head self-attention) and synaptic saliency of MLP, which are the basic component of transformer.\n",
    "\n",
    "Transformer based search space consists of attention layer, layer normalization and feed forward layer, the search space can be controled by setting network depth, number attention heads, MLP layer ratio and layer dimension.\n",
    "\n",
    "<center>\n",
    "<img src=\"./img/transformer.png\" width=\"600\"/><figure>Overall architecture of NAS ASR</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afcdd5e",
   "metadata": {},
   "source": [
    "# Performance Overview\n",
    "\n",
    "leverage DENAS to search optimal transformer-based ASR model structure, traininig dataset: LibriSpeech train-clean-100, early stop metric: 25% WER\n",
    "\n",
    "performance data to be added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90002b86",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e9d31",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "``` bash\n",
    "# Setup ENV\n",
    "git clone https://github.com/intel/e2eAIOK.git\n",
    "cd e2eAIOK\n",
    "python3 scripts/start_e2eaiok_docker.py -b pytorch120 -w ${host0} ${host1} ${host2} ${host3} --proxy \"\"\n",
    "```\n",
    "\n",
    "## Enter Docker\n",
    "\n",
    "```\n",
    "sshpass -p docker ssh ${host0} -p 12347\n",
    "```\n",
    "\n",
    "## Workflow Prepare\n",
    "\n",
    "``` bash\n",
    "# Download Dataset\n",
    "# Download and unzip dataset from https://www.openslr.org/12 to /home/vmagent/app/dataset/LibriSpeech\n",
    "# Download tokenizer from https://huggingface.co/speechbrain/asr-transformer-transformerlm-librispeech/blob/main/tokenizer.ckpt to /home/vmagent/app/dataset/LibriSpeech\n",
    "\n",
    "# Process audio data\n",
    "cd /home/vmagent/app/e2eaiok/e2eAIOK/DeNas/asr\n",
    "conda activate pytorch\n",
    "bash scripts/preprocess_librispeech.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a294ce5",
   "metadata": {},
   "source": [
    "## Launch search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526ec6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conf for transformer based asr\r\n",
      "model_type: asr\r\n",
      "search_engine: RandomSearchEngine\r\n",
      "batch_size: 32\r\n",
      "random_max_epochs: 10\r\n",
      "max_epochs: 10\r\n",
      "select_num: 50\r\n",
      "population_num: 50\r\n",
      "m_prob: 0.2\r\n",
      "s_prob: 0.4\r\n",
      "crossover_num: 25\r\n",
      "mutation_num: 25\r\n",
      "max_param_limits: 100\r\n",
      "min_param_limits: 1\r\n",
      "supernet_cfg: ../../conf/denas/asr/supernet_large.conf\r\n",
      "img_size: 224\r\n",
      "seed: 0\r\n",
      "expressivity_weight: 0\r\n",
      "complexity_weight: 0\r\n",
      "diversity_weight: 1\r\n",
      "saliency_weight: 1\r\n",
      "latency_weight: 0"
     ]
    }
   ],
   "source": [
    "# DENAS ASR search configuration\n",
    "! cat /home/vmagent/app/e2eaiok/conf/denas/asr/e2eaiok_denas_asr.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0c6045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPERNET:\r\n",
      "  MLP_RATIO: 4.0\r\n",
      "  NUM_HEADS: 4\r\n",
      "  EMBED_DIM: 512\r\n",
      "  DEPTH: 12\r\n",
      "SEARCH_SPACE:\r\n",
      "  MLP_RATIO:\r\n",
      "    - 3.0\r\n",
      "    - 3.5\r\n",
      "    - 4.0\r\n",
      "  NUM_HEADS:\r\n",
      "    - 2\r\n",
      "    - 4\r\n",
      "  DEPTH:\r\n",
      "    - 5\r\n",
      "    - 6\r\n",
      "    - 7\r\n",
      "    - 8\r\n",
      "    - 9\r\n",
      "    - 10\r\n",
      "    - 11\r\n",
      "    - 12\r\n",
      "  EMBED_DIM:\r\n",
      "    - 128\r\n",
      "    - 256\r\n",
      "    - 512"
     ]
    }
   ],
   "source": [
    "# DENAS ASR supernet structure and search space\n",
    "! cat /home/vmagent/app/e2eaiok/conf/denas/asr/supernet_large.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ebf119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n",
      "12/01/2022 07:44:33 - INFO - DENAS -   epoch = 0 structure = (11, 3.5, 3.0, 3.5, 4.0, 3.5, 3.5, 3.5, 3.5, 3.5, 4.0, 3.0, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 512) nas_score = 0.14366315305233002 params = 60.231936\n",
      "12/01/2022 07:44:39 - INFO - DENAS -   epoch = 1 structure = (6, 3.5, 3.5, 3.5, 4.0, 4.0, 3.0, 4, 4, 4, 2, 2, 2, 512) nas_score = 0.1554543524980545 params = 46.044416\n",
      "12/01/2022 07:44:44 - INFO - DENAS -   epoch = 2 structure = (11, 4.0, 4.0, 4.0, 3.0, 4.0, 3.5, 3.5, 3.0, 4.0, 3.5, 4.0, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 256) nas_score = 0.19446012377738953 params = 19.309184\n",
      "12/01/2022 07:44:46 - INFO - DENAS -   epoch = 3 structure = (9, 4.0, 3.0, 4.0, 3.5, 4.0, 3.0, 4.0, 4.0, 4.0, 4, 4, 2, 4, 4, 2, 4, 2, 2, 128) nas_score = 0.020150350406765938 params = 6.462656\n",
      "12/01/2022 07:44:51 - INFO - DENAS -   epoch = 4 structure = (5, 4.0, 4.0, 3.5, 3.5, 3.0, 2, 2, 2, 2, 2, 512) nas_score = 0.06112755089998245 params = 43.154432\n",
      "12/01/2022 07:45:04 - INFO - DENAS -   epoch = 5 structure = (11, 4.0, 4.0, 3.5, 4.0, 3.0, 3.0, 4.0, 4.0, 3.5, 4.0, 3.5, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 512) nas_score = 0.5155283212661743 params = 61.281536\n",
      "12/01/2022 07:45:06 - INFO - DENAS -   epoch = 6 structure = (9, 3.0, 4.0, 3.0, 3.5, 3.0, 3.5, 3.5, 3.0, 3.0, 2, 2, 2, 2, 2, 2, 2, 2, 4, 128) nas_score = 0.04739942029118538 params = 6.331072\n",
      "12/01/2022 07:45:10 - INFO - DENAS -   epoch = 7 structure = (10, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.5, 3.0, 2, 2, 4, 2, 4, 2, 2, 2, 4, 4, 256) nas_score = 0.09349927306175232 params = 17.994112\n",
      "12/01/2022 07:45:12 - INFO - DENAS -   epoch = 8 structure = (7, 3.0, 4.0, 3.5, 3.0, 4.0, 3.0, 4.0, 4, 2, 4, 4, 4, 2, 2, 128) nas_score = 0.018545102328062057 params = 6.033216\n",
      "12/01/2022 07:45:19 - INFO - DENAS -   epoch = 9 structure = (7, 3.0, 3.5, 4.0, 3.5, 3.0, 4.0, 3.5, 2, 2, 4, 4, 4, 4, 4, 512) nas_score = 0.12111835181713104 params = 48.672\n",
      "12/01/2022 07:45:19 - INFO - DENAS -   best structure (11, 4.0, 4.0, 3.5, 4.0, 3.0, 3.0, 4.0, 4.0, 3.5, 4.0, 3.5, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 512) nas_score 0.5155283212661743 params 61.281536\n",
      "12/01/2022 07:45:19 - INFO - DENAS -   best structure (11, 4.0, 4.0, 3.5, 4.0, 3.0, 3.0, 4.0, 4.0, 3.5, 4.0, 3.5, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 512) nas_score 0.5155283212661743 params 61.281536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paths: /home/vmagent/app/e2eaiok/e2eAIOK/DeNas/asr/utils, /home/vmagent/app/e2eaiok/e2eAIOK/DeNas/asr\n",
      "['/home/vmagent/app/e2eaiok/e2eAIOK/DeNas', '/opt/intel/oneapi/advisor/2022.1.0/pythonapi', '/home/spark-3.2.1-bin-hadoop3.2/python/lib/py4j-0.10.9.3-src.zip', '/home/spark-3.2.1-bin-hadoop3.2/python', '/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python39.zip', '/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9', '/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/lib-dynload', '/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages', '/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/warprnnt_pytorch-0.1-py3.9-linux-x86_64.egg', '', '/home/vmagent/app/e2eaiok/e2eAIOK/DeNas', '/home/vmagent/app/e2eaiok/e2eAIOK/DeNas', '/home/vmagent/app/e2eaiok/e2eAIOK/DeNas', '/home/vmagent/app/e2eaiok/e2eAIOK/DeNas', '/home/vmagent/app/e2eaiok/e2eAIOK/DeNas', '/home/vmagent/app/e2eaiok/e2eAIOK/DeNas/asr']\n",
      "DE-NAS search best structure took 60.56221921485849 sec\n",
      "DE-NAS completed, best structure is (11, 4.0, 4.0, 3.5, 4.0, 3.0, 3.0, 4.0, 4.0, 3.5, 4.0, 3.5, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 512)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/vmagent/app/e2eaiok/e2eAIOK/DeNas\n",
    "conda activate pytorch\n",
    "python search.py --domain asr --conf /home/vmagent/app/e2eaiok/conf/denas/asr/e2eaiok_denas_asr.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de62d980",
   "metadata": {},
   "source": [
    "## Launch training with best searched model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1555538c",
   "metadata": {},
   "source": [
    "edit /home/vmagent/app/e2eaiok/conf/denas/asr/e2eaiok_denas_train.conf\n",
    "\n",
    "```\n",
    "train_csv: \"/home/vmagent/app/dataset/LibriSpeech/dev-clean.csv\"\n",
    "valid_csv: \"/home/vmagent/app/dataset/LibriSpeech/dev-clean.csv\"\n",
    "test_csv: \"/home/vmagent/app/dataset/LibriSpeech/dev-clean.csv\"\n",
    "tokenizer_ckpt: \"/home/vmagent/app/dataset/LibriSpeech/tokenizer.ckpt\"\n",
    "train_epochs: 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdea20f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n",
      "/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/runpy.py:127: RuntimeWarning: 'intel_extension_for_pytorch.cpu.launch' found in sys.modules after import of package 'intel_extension_for_pytorch.cpu', but prior to execution of 'intel_extension_for_pytorch.cpu.launch'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2022-12-01 07:47:43,833 - __main__ - WARNING - Both TCMalloc and JeMalloc are not found in $CONDA_PREFIX/lib or $VIRTUAL_ENV/lib or /.local/lib/ or /usr/local/lib/ or /usr/local/lib64/ or /usr/lib or /usr/lib64 or /root/.local/lib/ so the LD_PRELOAD environment variable will not be set. This may drop the performance\n",
      "2022-12-01 07:47:43,833 - __main__ - INFO - OMP_NUM_THREADS=48\n",
      "2022-12-01 07:47:43,833 - __main__ - INFO - Using Intel OpenMP\n",
      "2022-12-01 07:47:43,833 - __main__ - INFO - KMP_AFFINITY=granularity=fine,compact,1,0\n",
      "2022-12-01 07:47:43,833 - __main__ - INFO - KMP_BLOCKTIME=1\n",
      "2022-12-01 07:47:43,834 - __main__ - INFO - LD_PRELOAD=/opt/intel/oneapi/intelpython/latest/envs/pytorch/lib/libiomp5.so\n",
      "2022-12-01 07:47:43,834 - __main__ - WARNING - Numa Aware: cores:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] in different NUMA node\n",
      "2022-12-01 07:47:43,834 - __main__ - INFO - numactl -C 0-47 /opt/intel/oneapi/intelpython/latest/envs/pytorch/bin/python -u /home/vmagent/app/e2eaiok/e2eAIOK/DeNas/train.py --domain asr --conf /home/vmagent/app/e2eaiok/conf/denas/asr/e2eaiok_denas_train_asr.conf --random_seed 74443\n",
      "12/01/2022 07:47:44 - INFO - Trainer -   building model\n",
      "12/01/2022 07:47:45 - INFO - Trainer -   model created: ModuleDict(\n",
      "  (CNN): ConvolutionFrontEnd(\n",
      "    (convblock_0): ConvBlock(\n",
      "      (convs): Sequential(\n",
      "        (conv_0): Conv2d(\n",
      "          (conv): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "        )\n",
      "        (norm_0): LayerNorm((40, 64), eps=1e-05, elementwise_affine=True)\n",
      "        (act_0): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_0): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (convblock_1): ConvBlock(\n",
      "      (convs): Sequential(\n",
      "        (conv_0): Conv2d(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "        )\n",
      "        (norm_0): LayerNorm((20, 64), eps=1e-05, elementwise_affine=True)\n",
      "        (act_0): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_0): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (convblock_2): ConvBlock(\n",
      "      (convs): Sequential(\n",
      "        (conv_0): Conv2d(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (norm_0): LayerNorm((20, 64), eps=1e-05, elementwise_affine=True)\n",
      "        (act_0): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_0): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (reduce_conv): Sequential(\n",
      "        (conv): Conv2d(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (norm): LayerNorm((20, 64), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (Transformer): TransformerASRSuper(\n",
      "    (positional_encoding): PositionalEncoding()\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_att): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_att): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_att): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=1792, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=1792, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_att): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_att): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_att): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_att): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_att): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_att): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=1792, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=1792, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_att): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_att): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=1792, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=1792, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (mutihead_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (mutihead_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (mutihead_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (mutihead_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (mutihead_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (5): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (mutihead_attn): MultiheadAttention(\n",
      "            (att): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (pos_ffn): PositionalwiseFeedForward(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (custom_src_module): ModuleList(\n",
      "      (0): Linear(in_features=1280, out_features=512, bias=True)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (custom_tgt_module): ModuleList(\n",
      "      (0): NormalizedEmbedding(\n",
      "        (emb): Embedding(5000, 512, padding_idx=0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (seq_lin): Linear(in_features=512, out_features=5000, bias=True)\n",
      "  (ctc_lin): Linear(in_features=512, out_features=5000, bias=True)\n",
      "  (normalize): InputNormalization()\n",
      ")\n",
      "12/01/2022 07:47:45 - INFO - Trainer -   Trainer config: {'seed': '74443', 'output_folder': 'results/transformer/74443', 'save_folder': 'results/transformer/74443/save', 'device': 'cpu', 'dist_backend': 'ccl', 'mode': 'train', 'domain': 'asr', 'best_model_structure': '/home/vmagent/app/e2eaiok/e2eAIOK/DeNas/best_model_structure.txt', 'data_folder': '/home/vmagent/app/dataset/LibriSpeech', 'skip_prep': False, 'train_csv': '/home/vmagent/app/dataset/LibriSpeech/dev-clean.csv', 'valid_csv': '/home/vmagent/app/dataset/LibriSpeech/dev-clean.csv', 'test_csv': '/home/vmagent/app/dataset/LibriSpeech/dev-clean.csv', 'tokenizer_ckpt': '/home/vmagent/app/dataset/LibriSpeech/tokenizer.ckpt', 'ckpt_interval_minutes': 30, 'train_epochs': 1, 'eval_epochs': 1, 'train_batch_size': 32, 'eval_batch_size': 1, 'num_workers': 0, 'ctc_weight': 0.3, 'grad_accumulation_factor': 1, 'max_grad_norm': 5.0, 'loss_reduction': 'batchmean', 'sorting': 'random', 'metric_threshold': 25, 'lr_adam': 0.001, 'sample_rate': 16000, 'n_fft': 400, 'n_mels': 80, 'input_shape': [8, 10, 80], 'num_blocks': 3, 'num_layers_per_block': 1, 'out_channels': [64, 64, 64], 'kernel_sizes': [5, 5, 1], 'strides': [2, 2, 1], 'residuals': [False, False, True], 'input_size': 1280, 'd_model': 512, 'encoder_heads': [4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2], 'nhead': 4, 'num_encoder_layers': 11, 'num_decoder_layers': 6, 'mlp_ratio': [4.0, 4.0, 3.5, 4.0, 3.0, 3.0, 4.0, 4.0, 3.5, 4.0, 3.5], 'd_ffn': 2048, 'transformer_dropout': 0.1, 'output_neurons': 5000, 'blank_index': 0, 'label_smoothing': 0.0, 'pad_index': 0, 'bos_index': 1, 'eos_index': 2, 'min_decode_ratio': 0.0, 'max_decode_ratio': 1.0, 'valid_search_interval': 10, 'valid_beam_size': 10, 'test_beam_size': 66, 'lm_weight': 0.6, 'ctc_weight_decode': 0.4, 'n_warmup_steps': 2500, 'augmentation': {'time_warp': False, 'time_warp_window': 5, 'time_warp_mode': 'bicubic', 'freq_mask': True, 'n_freq_mask': 4, 'time_mask': True, 'n_time_mask': 4, 'replace_with_zero': False, 'freq_mask_width': 15, 'time_mask_width': 20}, 'speed_perturb': True, 'compute_features': {'sample_rate': 16000, 'n_fft': 400, 'n_mels': 80}}\n",
      "12/01/2022 07:47:59 - INFO - Trainer -   epoch: 1, step: 1|84, time: 12.73s, loss: 569.0787353515625, avg_loss: 569.0787, lr: 0.001\n",
      "12/01/2022 07:48:19 - INFO - Trainer -   epoch: 1, step: 2|84, time: 18.57s, loss: 263.37445068359375, avg_loss: 416.2266, lr: 4e-07\n",
      "12/01/2022 07:48:29 - INFO - Trainer -   epoch: 1, step: 3|84, time: 8.42s, loss: 336.5179443359375, avg_loss: 389.6570, lr: 8e-07\n",
      "12/01/2022 07:48:39 - INFO - Trainer -   epoch: 1, step: 4|84, time: 9.08s, loss: 300.3770751953125, avg_loss: 367.3371, lr: 1.2000000000000002e-06\n",
      "12/01/2022 07:48:58 - INFO - Trainer -   epoch: 1, step: 5|84, time: 17.78s, loss: 301.8660888671875, avg_loss: 354.2429, lr: 1.6e-06\n",
      "12/01/2022 07:49:12 - INFO - Trainer -   epoch: 1, step: 6|84, time: 12.07s, loss: 313.1339111328125, avg_loss: 347.3914, lr: 2e-06\n",
      "12/01/2022 07:49:26 - INFO - Trainer -   epoch: 1, step: 7|84, time: 13.24s, loss: 284.3330993652344, avg_loss: 338.3830, lr: 2.4000000000000003e-06\n",
      "12/01/2022 07:49:34 - INFO - Trainer -   epoch: 1, step: 8|84, time: 6.72s, loss: 212.03591918945312, avg_loss: 322.5897, lr: 2.8e-06\n",
      "12/01/2022 07:49:41 - INFO - Trainer -   epoch: 1, step: 9|84, time: 5.53s, loss: 236.5142364501953, avg_loss: 313.0257, lr: 3.2e-06\n",
      "12/01/2022 07:49:51 - INFO - Trainer -   epoch: 1, step: 10|84, time: 8.72s, loss: 286.6864013671875, avg_loss: 310.3918, lr: 3.6e-06\n",
      "12/01/2022 07:50:11 - INFO - Trainer -   epoch: 1, step: 11|84, time: 19.03s, loss: 306.2204284667969, avg_loss: 310.0126, lr: 4e-06\n",
      "12/01/2022 07:50:19 - INFO - Trainer -   epoch: 1, step: 12|84, time: 6.76s, loss: 246.54998779296875, avg_loss: 304.7240, lr: 4.4e-06\n",
      "12/01/2022 07:50:31 - INFO - Trainer -   epoch: 1, step: 13|84, time: 10.44s, loss: 296.3272705078125, avg_loss: 304.0781, lr: 4.800000000000001e-06\n",
      "12/01/2022 07:50:37 - INFO - Trainer -   epoch: 1, step: 14|84, time: 4.51s, loss: 203.03662109375, avg_loss: 296.8609, lr: 5.2e-06\n",
      "12/01/2022 07:50:46 - INFO - Trainer -   epoch: 1, step: 15|84, time: 8.17s, loss: 248.99575805664062, avg_loss: 293.6699, lr: 5.6e-06\n",
      "12/01/2022 07:50:56 - INFO - Trainer -   epoch: 1, step: 16|84, time: 8.47s, loss: 265.02313232421875, avg_loss: 291.8794, lr: 5.999999999999999e-06\n",
      "12/01/2022 07:51:04 - INFO - Trainer -   epoch: 1, step: 17|84, time: 6.13s, loss: 234.9435272216797, avg_loss: 288.5303, lr: 6.4e-06\n",
      "12/01/2022 07:51:13 - INFO - Trainer -   epoch: 1, step: 18|84, time: 7.79s, loss: 227.9154052734375, avg_loss: 285.1628, lr: 6.8e-06\n",
      "12/01/2022 07:51:19 - INFO - Trainer -   epoch: 1, step: 19|84, time: 5.03s, loss: 201.65867614746094, avg_loss: 280.7678, lr: 7.2e-06\n",
      "12/01/2022 07:51:34 - INFO - Trainer -   epoch: 1, step: 20|84, time: 13.17s, loss: 287.4023742675781, avg_loss: 281.0996, lr: 7.599999999999999e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2022 07:51:41 - INFO - Trainer -   epoch: 1, step: 21|84, time: 5.46s, loss: 233.23403930664062, avg_loss: 278.8202, lr: 8e-06\n",
      "12/01/2022 07:51:49 - INFO - Trainer -   epoch: 1, step: 22|84, time: 6.16s, loss: 229.02133178710938, avg_loss: 276.5567, lr: 8.4e-06\n",
      "12/01/2022 07:52:07 - INFO - Trainer -   epoch: 1, step: 23|84, time: 17.03s, loss: 245.9324493408203, avg_loss: 275.2252, lr: 8.8e-06\n",
      "12/01/2022 07:52:26 - INFO - Trainer -   epoch: 1, step: 24|84, time: 17.61s, loss: 221.91502380371094, avg_loss: 273.0039, lr: 9.2e-06\n",
      "12/01/2022 07:52:35 - INFO - Trainer -   epoch: 1, step: 25|84, time: 7.92s, loss: 190.89065551757812, avg_loss: 269.7194, lr: 9.600000000000001e-06\n",
      "12/01/2022 07:52:45 - INFO - Trainer -   epoch: 1, step: 26|84, time: 8.62s, loss: 248.9710235595703, avg_loss: 268.9214, lr: 9.999999999999999e-06\n",
      "12/01/2022 07:52:53 - INFO - Trainer -   epoch: 1, step: 27|84, time: 6.80s, loss: 218.224365234375, avg_loss: 267.0437, lr: 1.04e-05\n",
      "12/01/2022 07:53:03 - INFO - Trainer -   epoch: 1, step: 28|84, time: 8.90s, loss: 265.06396484375, avg_loss: 266.9730, lr: 1.0799999999999998e-05\n",
      "12/01/2022 07:53:18 - INFO - Trainer -   epoch: 1, step: 29|84, time: 13.02s, loss: 233.08706665039062, avg_loss: 265.8045, lr: 1.12e-05\n",
      "12/01/2022 07:53:24 - INFO - Trainer -   epoch: 1, step: 30|84, time: 5.29s, loss: 201.24722290039062, avg_loss: 263.6526, lr: 1.1599999999999999e-05\n",
      "12/01/2022 07:53:32 - INFO - Trainer -   epoch: 1, step: 31|84, time: 6.99s, loss: 181.8773956298828, avg_loss: 261.0147, lr: 1.1999999999999999e-05\n",
      "12/01/2022 07:53:44 - INFO - Trainer -   epoch: 1, step: 32|84, time: 11.23s, loss: 208.0370330810547, avg_loss: 259.3591, lr: 1.2400000000000002e-05\n",
      "12/01/2022 07:53:52 - INFO - Trainer -   epoch: 1, step: 33|84, time: 6.40s, loss: 204.33897399902344, avg_loss: 257.6919, lr: 1.28e-05\n",
      "12/01/2022 07:54:11 - INFO - Trainer -   epoch: 1, step: 34|84, time: 17.94s, loss: 247.4468231201172, avg_loss: 257.3905, lr: 1.3199999999999999e-05\n",
      "12/01/2022 07:54:17 - INFO - Trainer -   epoch: 1, step: 35|84, time: 4.48s, loss: 146.86685180664062, avg_loss: 254.2327, lr: 1.36e-05\n",
      "12/01/2022 07:54:27 - INFO - Trainer -   epoch: 1, step: 36|84, time: 8.88s, loss: 250.06414794921875, avg_loss: 254.1169, lr: 1.3999999999999998e-05\n",
      "12/01/2022 07:54:46 - INFO - Trainer -   epoch: 1, step: 37|84, time: 17.66s, loss: 213.28640747070312, avg_loss: 253.0134, lr: 1.44e-05\n",
      "12/01/2022 07:54:55 - INFO - Trainer -   epoch: 1, step: 38|84, time: 8.04s, loss: 172.1549835205078, avg_loss: 250.8855, lr: 1.4799999999999999e-05\n",
      "12/01/2022 07:55:12 - INFO - Trainer -   epoch: 1, step: 39|84, time: 15.62s, loss: 242.09039306640625, avg_loss: 250.6600, lr: 1.5199999999999998e-05\n",
      "12/01/2022 07:55:22 - INFO - Trainer -   epoch: 1, step: 40|84, time: 8.13s, loss: 234.7709503173828, avg_loss: 250.2628, lr: 1.56e-05\n",
      "12/01/2022 07:55:34 - INFO - Trainer -   epoch: 1, step: 41|84, time: 11.12s, loss: 209.5797882080078, avg_loss: 249.2705, lr: 1.6e-05\n",
      "12/01/2022 07:55:42 - INFO - Trainer -   epoch: 1, step: 42|84, time: 6.41s, loss: 199.0799560546875, avg_loss: 248.0755, lr: 1.6400000000000002e-05\n",
      "12/01/2022 07:55:50 - INFO - Trainer -   epoch: 1, step: 43|84, time: 7.36s, loss: 178.87576293945312, avg_loss: 246.4662, lr: 1.68e-05\n",
      "12/01/2022 07:55:58 - INFO - Trainer -   epoch: 1, step: 44|84, time: 6.16s, loss: 228.88555908203125, avg_loss: 246.0667, lr: 1.7199999999999998e-05\n",
      "12/01/2022 07:56:10 - INFO - Trainer -   epoch: 1, step: 45|84, time: 11.04s, loss: 248.51809692382812, avg_loss: 246.1211, lr: 1.76e-05\n",
      "12/01/2022 07:56:19 - INFO - Trainer -   epoch: 1, step: 46|84, time: 7.48s, loss: 218.21063232421875, avg_loss: 245.5144, lr: 1.8e-05\n",
      "12/01/2022 07:56:29 - INFO - Trainer -   epoch: 1, step: 47|84, time: 9.40s, loss: 205.79627990722656, avg_loss: 244.6693, lr: 1.84e-05\n",
      "12/01/2022 07:56:40 - INFO - Trainer -   epoch: 1, step: 48|84, time: 9.36s, loss: 210.4239501953125, avg_loss: 243.9559, lr: 1.8799999999999996e-05\n",
      "12/01/2022 07:56:47 - INFO - Trainer -   epoch: 1, step: 49|84, time: 6.14s, loss: 206.56182861328125, avg_loss: 243.1927, lr: 1.9200000000000003e-05\n",
      "12/01/2022 07:57:00 - INFO - Trainer -   epoch: 1, step: 50|84, time: 11.37s, loss: 174.0757598876953, avg_loss: 241.8104, lr: 1.96e-05\n",
      "12/01/2022 07:57:07 - INFO - Trainer -   epoch: 1, step: 51|84, time: 5.79s, loss: 178.9926300048828, avg_loss: 240.5787, lr: 1.9999999999999998e-05\n",
      "12/01/2022 07:57:15 - INFO - Trainer -   epoch: 1, step: 52|84, time: 6.54s, loss: 197.3976593017578, avg_loss: 239.7483, lr: 2.04e-05\n",
      "12/01/2022 07:57:23 - INFO - Trainer -   epoch: 1, step: 53|84, time: 6.70s, loss: 207.4735107421875, avg_loss: 239.1393, lr: 2.08e-05\n",
      "12/01/2022 07:57:34 - INFO - Trainer -   epoch: 1, step: 54|84, time: 9.56s, loss: 216.1961669921875, avg_loss: 238.7144, lr: 2.12e-05\n",
      "12/01/2022 07:57:43 - INFO - Trainer -   epoch: 1, step: 55|84, time: 7.74s, loss: 215.61480712890625, avg_loss: 238.2944, lr: 2.1599999999999996e-05\n",
      "12/01/2022 07:57:50 - INFO - Trainer -   epoch: 1, step: 56|84, time: 6.56s, loss: 191.1558380126953, avg_loss: 237.4527, lr: 2.2e-05\n",
      "12/01/2022 07:57:57 - INFO - Trainer -   epoch: 1, step: 57|84, time: 5.00s, loss: 196.23558044433594, avg_loss: 236.7296, lr: 2.24e-05\n",
      "12/01/2022 07:58:10 - INFO - Trainer -   epoch: 1, step: 58|84, time: 11.37s, loss: 204.9269561767578, avg_loss: 236.1813, lr: 2.28e-05\n",
      "12/01/2022 07:58:20 - INFO - Trainer -   epoch: 1, step: 59|84, time: 9.46s, loss: 152.2890167236328, avg_loss: 234.7594, lr: 2.3199999999999998e-05\n",
      "12/01/2022 07:58:40 - INFO - Trainer -   epoch: 1, step: 60|84, time: 18.56s, loss: 199.35928344726562, avg_loss: 234.1694, lr: 2.36e-05\n",
      "12/01/2022 07:58:50 - INFO - Trainer -   epoch: 1, step: 61|84, time: 8.89s, loss: 171.2724609375, avg_loss: 233.1383, lr: 2.3999999999999997e-05\n",
      "12/01/2022 07:59:02 - INFO - Trainer -   epoch: 1, step: 62|84, time: 10.96s, loss: 206.87554931640625, avg_loss: 232.7147, lr: 2.44e-05\n",
      "12/01/2022 07:59:12 - INFO - Trainer -   epoch: 1, step: 63|84, time: 8.24s, loss: 187.84275817871094, avg_loss: 232.0024, lr: 2.4800000000000003e-05\n",
      "12/01/2022 07:59:29 - INFO - Trainer -   epoch: 1, step: 64|84, time: 15.81s, loss: 182.11520385742188, avg_loss: 231.2229, lr: 2.52e-05\n",
      "12/01/2022 07:59:37 - INFO - Trainer -   epoch: 1, step: 65|84, time: 6.33s, loss: 160.3518524169922, avg_loss: 230.1326, lr: 2.56e-05\n",
      "12/01/2022 07:59:45 - INFO - Trainer -   epoch: 1, step: 66|84, time: 7.27s, loss: 193.48699951171875, avg_loss: 229.5774, lr: 2.6e-05\n",
      "12/01/2022 07:59:55 - INFO - Trainer -   epoch: 1, step: 67|84, time: 8.51s, loss: 203.794921875, avg_loss: 229.1926, lr: 2.6399999999999998e-05\n",
      "12/01/2022 08:00:03 - INFO - Trainer -   epoch: 1, step: 68|84, time: 7.15s, loss: 218.0487060546875, avg_loss: 229.0287, lr: 2.68e-05\n",
      "12/01/2022 08:00:18 - INFO - Trainer -   epoch: 1, step: 69|84, time: 13.09s, loss: 217.79698181152344, avg_loss: 228.8659, lr: 2.72e-05\n",
      "12/01/2022 08:00:25 - INFO - Trainer -   epoch: 1, step: 70|84, time: 5.47s, loss: 188.40884399414062, avg_loss: 228.2879, lr: 2.76e-05\n",
      "12/01/2022 08:00:30 - INFO - Trainer -   epoch: 1, step: 71|84, time: 4.42s, loss: 145.21119689941406, avg_loss: 227.1178, lr: 2.7999999999999996e-05\n",
      "12/01/2022 08:00:40 - INFO - Trainer -   epoch: 1, step: 72|84, time: 8.78s, loss: 205.4453125, avg_loss: 226.8168, lr: 2.8399999999999996e-05\n",
      "12/01/2022 08:01:00 - INFO - Trainer -   epoch: 1, step: 73|84, time: 18.02s, loss: 201.4026641845703, avg_loss: 226.4687, lr: 2.88e-05\n",
      "12/01/2022 08:01:09 - INFO - Trainer -   epoch: 1, step: 74|84, time: 7.48s, loss: 183.52650451660156, avg_loss: 225.8884, lr: 2.92e-05\n",
      "12/01/2022 08:01:24 - INFO - Trainer -   epoch: 1, step: 75|84, time: 14.31s, loss: 185.98825073242188, avg_loss: 225.3564, lr: 2.9599999999999998e-05\n",
      "12/01/2022 08:01:39 - INFO - Trainer -   epoch: 1, step: 76|84, time: 13.52s, loss: 185.70309448242188, avg_loss: 224.8346, lr: 3e-05\n",
      "12/01/2022 08:01:48 - INFO - Trainer -   epoch: 1, step: 77|84, time: 8.41s, loss: 242.6257781982422, avg_loss: 225.0657, lr: 3.0399999999999997e-05\n",
      "12/01/2022 08:02:07 - INFO - Trainer -   epoch: 1, step: 78|84, time: 17.43s, loss: 171.20242309570312, avg_loss: 224.3751, lr: 3.08e-05\n",
      "12/01/2022 08:02:16 - INFO - Trainer -   epoch: 1, step: 79|84, time: 7.71s, loss: 172.75067138671875, avg_loss: 223.7217, lr: 3.12e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2022 08:02:24 - INFO - Trainer -   epoch: 1, step: 80|84, time: 6.71s, loss: 177.7315216064453, avg_loss: 223.1468, lr: 3.1599999999999996e-05\n",
      "12/01/2022 08:02:35 - INFO - Trainer -   epoch: 1, step: 81|84, time: 10.42s, loss: 193.48794555664062, avg_loss: 222.7806, lr: 3.2e-05\n",
      "12/01/2022 08:02:44 - INFO - Trainer -   epoch: 1, step: 82|84, time: 7.25s, loss: 182.6701202392578, avg_loss: 222.2915, lr: 3.24e-05\n",
      "12/01/2022 08:02:57 - INFO - Trainer -   epoch: 1, step: 83|84, time: 11.35s, loss: 222.13172912597656, avg_loss: 222.2896, lr: 3.2800000000000004e-05\n",
      "12/01/2022 08:03:04 - INFO - Trainer -   epoch: 1, step: 84|84, time: 6.56s, loss: 163.16845703125, avg_loss: 221.5857, lr: 3.32e-05\n",
      "12/01/2022 08:03:04 - INFO - Trainer -   epoch: 1, time: 918.91s, avg_loss: 221.5857\n",
      "12/01/2022 08:06:08 - INFO - Trainer -   epoch: 1, time: 184.09759664535522, wer: 112.10249623175619, avg_loss: 188.94259714577498\n",
      "12/01/2022 08:06:08 - INFO - Trainer -   Evaluate time:184.0989682674408\n",
      "12/01/2022 08:06:08 - INFO - Trainer -   Epoch 1 training time:1103.0080680847168\n",
      "12/01/2022 08:06:08 - INFO - Trainer -   Total time:1103.008092880249\n",
      "12/01/2022 08:06:08 - INFO - Trainer -   Trainer complete\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/vmagent/app/e2eaiok/e2eAIOK/DeNas\n",
    "conda activate pytorch\n",
    "python -m intel_extension_for_pytorch.cpu.launch /home/vmagent/app/e2eaiok/e2eAIOK/DeNas/train.py \\\n",
    "    --domain asr --conf /home/vmagent/app/e2eaiok/conf/denas/asr/e2eaiok_denas_train_asr.conf --random_seed 74443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e6a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-1.12.0]",
   "language": "python",
   "name": "conda-env-pytorch-1.12.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
