{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c721aa",
   "metadata": {},
   "source": [
    "# Content\n",
    "* ### 1. [Framework](1.Framework)\n",
    "* ### 2. [Environment Setup]()\n",
    "* ### 3. [Data Preparation]()\n",
    "* ### 4. [Launch training]()\n",
    "* ### 5. [Inference & Evaluation]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac2a67",
   "metadata": {},
   "source": [
    "## 1. Framework\n",
    "\n",
    "\n",
    "Transfer Learning Kit is a general and convenient framework for transfer knowledge from pretrained model and/or source domain data to target task. Its objectives are:\n",
    "* Transfer knowledge from pretrained model with the same/different network structure, which greatly speedups training without accuracy regression.\n",
    "* Transfer knowledge from source domain data without target label.\n",
    "\n",
    "The hierarchy of Transfer Learning Kit is list below. And, there are 5 key components in our Transfer Learning Kit:\n",
    "\n",
    "1.\tBackbone Factory: creates a backbone net according to predefined backbone or user-provided backbone to make basic prediction. \n",
    "2.\tTask Finetunner: creates a pretrained finetuning schema (called “finetunner”) to transfer knowledge from a pretrained model to target model with the same network structure.\n",
    "3.\tDomain Adapter: creates a domain adaption net (called “adapter”) to transfer knowledge from source domain to target domain.\n",
    "4.\tKnowledge Distiller: creates a knowledge distillation net (called “distiller”) to transfer knowledge from teacher model to target model. \n",
    "5.\tTransferrable Model: creates a customized and transferrable model which is a wrapper of backbone, adapter and distiller.\n",
    "![Framework](doc/imgs/framework.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215cbde",
   "metadata": {},
   "source": [
    "### 1.1 Adapter\n",
    "Transfer knowledge from source domain(cheap labels) to target domain (label-free).\n",
    "\n",
    "* Direct applying pre-trained model into target domain always cannot work due to covariate shift and label shift,  while labeling could be expensive in some domains and delays the model deployment time, which make fine-tuning not working.\n",
    "* Adapter aims at reusing the transferable knowledge with the help of another labeled dataset with same learning task. That is, achieving better generalization with little labeled target dataset or achieving a competitive performance in label-free target dataset.\n",
    "![Adapter](doc/imgs/adapter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fe6b4",
   "metadata": {},
   "source": [
    "## 2. Environment Setup\n",
    "\n",
    "1. build docker image\n",
    "   ```\n",
    "   cd Dockerfile-ubuntu18.04 && docker build -t aidk-pytorch110 . -f DockerfilePytorch110 && cd .. && yes | docker container prune && yes | docker image prune\n",
    "   ```\n",
    "2. run docker\n",
    "   ```\n",
    "   docker run -it --name UDA --privileged --network host --shm-size 32g --device=/dev/dri -v /mnt/DP_disk1/yu:/home/vmagent/app/dataset -v /home/yu:/work -w /work aidk-pytorch110 /bin/bash \n",
    "   ``` \n",
    "3. install the development library\n",
    "   ```\n",
    "   source /opt/intel/oneapi/setvars.sh --ccl-configuration=cpu_icc --force\n",
    "   conda activate pytorch-1.10.0\n",
    "   cd AIDK/TransferLearningKit/src/task/medical_segmentation/\n",
    "   pip install -e .\n",
    "   ```\n",
    "4. Start the jupyter notebook service\n",
    "   ```\n",
    "   pip install jupyter\n",
    "   jupyter notebook --notebook-dir=/work --ip=0.0.0.0 --port=8989 --allow-root\n",
    "   ```\n",
    "   Now you can visit Adapter demo in `http://${hostname}:${port}/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70f725",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee25f2",
   "metadata": {},
   "source": [
    "### 3.1 Task Description\n",
    "* In this demo, we will introduce how to use domain adaptation to transfer knowledge in medical image semantic segmentation\n",
    "* Our source domain is AMOS dataset, which provides 500 CT and 100 MRI scans with voxel-level annotations of 15 abdominal organs, including the spleen, right kidney, left kidney, gallbladder, esophagus, liver, stomach, aorta, inferior vena cava, pancreas, right adrenal gland, left adrenal gland, duodenum, bladder, prostate/uterus.\n",
    "* Our target domain is KiTS dataset, which provides 300 CT scans with voxel-level annotations of kidney organs and kidney tumor.\n",
    "* Our task is to explore reliable kidney semantic segmentation methodologies with the help of labeled AMOS dataset and unlabeled KiTS dataset, evalutaion metric is kidney dice score in target domain.\n",
    "* We can see from the following picture, **even without the target label data, adapter achieve 10.67x training speedup, while keep the 93% performance ratio.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ec32c",
   "metadata": {},
   "source": [
    "![adapter_result_plot](doc/imgs/adapter_result_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e24033e",
   "metadata": {},
   "source": [
    "### 3.2 Download Data\n",
    "- Download KiTS data from [here](https://github.com/neheller/kits19)\n",
    "- Download AMOS data from [here](https://amos22.grand-challenge.org/Dataset/)\n",
    "\n",
    "- Then, setup some enviroment variables\n",
    "    - it tell the program where to read data, and where to write the output model and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa82c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['nnUNet_raw_data_base'] = \"/home/vmagent/app/dataset/nnUNet_raw_data_base\" \n",
    "os.environ['nnUNet_preprocessed'] = \"/home/vmagent/app/dataset/nnUNet_preprocessed\"\n",
    "os.environ['RESULTS_FOLDER'] = \"/home/vmagent/app/dataset/nnUNet_trained_models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b52a0f",
   "metadata": {},
   "source": [
    "- Then, We put the data in $nnUNet_raw_data_base/nnUNet_raw_data, the structure should look like (*for simlicy, we only take 5 case of each task for demostration*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09cb8421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/vmagent/app/dataset/nnUNet_raw_data_base/nnUNet_raw_data\u001b[00m\r\n",
      "├── \u001b[01;34mTask041_KiTS\u001b[00m\r\n",
      "│   ├── dataset.json\r\n",
      "│   ├── \u001b[01;34mimagesTr\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00000_0000.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00001_0000.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00002_0000.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00003_0000.nii.gz\u001b[00m\r\n",
      "│   │   └── \u001b[01;31mcase_00004_0000.nii.gz\u001b[00m\r\n",
      "│   └── \u001b[01;34mlabelsTr\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00000.nii.gz\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00001.nii.gz\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00002.nii.gz\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00003.nii.gz\u001b[00m\r\n",
      "│       └── \u001b[01;31mcase_00004.nii.gz\u001b[00m\r\n",
      "└── \u001b[01;34mTask505_AMOS\u001b[00m\r\n",
      "    ├── \u001b[01;34mimagesTr\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0001.nii.gz\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0004.nii.gz\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0005.nii.gz\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0006.nii.gz\u001b[00m\r\n",
      "    │   └── \u001b[01;31mamos_0007.nii.gz\u001b[00m\r\n",
      "    ├── \u001b[01;34mlabelsTr\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0001.nii.gz\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0004.nii.gz\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0005.nii.gz\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0006.nii.gz\u001b[00m\r\n",
      "    │   └── \u001b[01;31mamos_0007.nii.gz\u001b[00m\r\n",
      "    └── task1_dataset.json\r\n",
      "\r\n",
      "6 directories, 22 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree $nnUNet_raw_data_base/nnUNet_raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba15c2",
   "metadata": {},
   "source": [
    "### 3.3 Data Preprocessing\n",
    "\n",
    "#### 3.3.1 Data Alignment\n",
    "- In this part, we do the following thing:\n",
    "    - Keep the both data in the same axis ordering, for background knowledge, you can refer to [here](https://www.jarvis73.com/2019/06/24/Medical-Imaging-Guide/#13-%E5%9D%90%E6%A0%87%E7%B3%BB%E7%BB%9F)\n",
    "        - Axis ordering: it determines in what direction we see the medical image, it is adjustable, and something like rotation in natural images, we should make the two dataset have same perspective;\n",
    "\n",
    "    - Change the tumor annotation in KiTS to kidney, because we cannot know the tumor from source domain AMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c35ed11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/AIDK/AIDK/TransferLearningKit/src/task/medical_segmentation/nnunet\n"
     ]
    }
   ],
   "source": [
    "%cd /work/AIDK/AIDK/TransferLearningKit/src/task/medical_segmentation/nnunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991b869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python dataset_conversion/amos_convert_label.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c523c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vmagent/app/dataset/nnUNet_raw_data_base/nnUNet_raw_data/Task507_KiTS_kidney/labelsTr\n",
      "case_00003.nii.gz\n",
      "case_00000.nii.gz\n",
      "case_00001.nii.gz\n",
      "case_00002.nii.gz\n",
      "case_00004.nii.gz\n",
      "case_00002_0000.nii.gz\n",
      "('R', 'A', 'S')\n",
      "case_00003_0000.nii.gz\n",
      "('R', 'A', 'S')\n",
      "case_00001_0000.nii.gz\n",
      "('R', 'A', 'S')\n",
      "case_00000_0000.nii.gz\n",
      "('R', 'A', 'S')\n",
      "case_00004_0000.nii.gz\n",
      "('R', 'A', 'S')\n"
     ]
    }
   ],
   "source": [
    "!python dataset_conversion/kits_convert_label.py basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff48141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/vmagent/app/dataset/nnUNet_raw_data_base/nnUNet_raw_data\u001b[00m\r\n",
      "├── \u001b[01;34mTask041_KiTS\u001b[00m\r\n",
      "│   ├── dataset.json\r\n",
      "│   ├── \u001b[01;34mimagesTr\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00000_0000.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00001_0000.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00002_0000.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00003_0000.nii.gz\u001b[00m\r\n",
      "│   │   └── \u001b[01;31mcase_00004_0000.nii.gz\u001b[00m\r\n",
      "│   └── \u001b[01;34mlabelsTr\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00000.nii.gz\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00001.nii.gz\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00002.nii.gz\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00003.nii.gz\u001b[00m\r\n",
      "│       └── \u001b[01;31mcase_00004.nii.gz\u001b[00m\r\n",
      "├── \u001b[01;34mTask505_AMOS\u001b[00m\r\n",
      "│   ├── \u001b[01;34mimagesTr\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mamos_0001.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mamos_0004.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mamos_0005.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mamos_0006.nii.gz\u001b[00m\r\n",
      "│   │   └── \u001b[01;31mamos_0007.nii.gz\u001b[00m\r\n",
      "│   ├── \u001b[01;34mlabelsTr\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mamos_0001.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mamos_0004.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mamos_0005.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mamos_0006.nii.gz\u001b[00m\r\n",
      "│   │   └── \u001b[01;31mamos_0007.nii.gz\u001b[00m\r\n",
      "│   └── task1_dataset.json\r\n",
      "├── \u001b[01;34mTask507_KiTS_kidney\u001b[00m\r\n",
      "│   ├── dataset.json\r\n",
      "│   ├── \u001b[01;34mimagesTr\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00000_0000.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00001_0000.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00002_0000.nii.gz\u001b[00m\r\n",
      "│   │   ├── \u001b[01;31mcase_00003_0000.nii.gz\u001b[00m\r\n",
      "│   │   └── \u001b[01;31mcase_00004_0000.nii.gz\u001b[00m\r\n",
      "│   └── \u001b[01;34mlabelsTr\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00000.nii.gz\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00001.nii.gz\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00002.nii.gz\u001b[00m\r\n",
      "│       ├── \u001b[01;31mcase_00003.nii.gz\u001b[00m\r\n",
      "│       └── \u001b[01;31mcase_00004.nii.gz\u001b[00m\r\n",
      "└── \u001b[01;34mTask508_AMOS_kidney\u001b[00m\r\n",
      "    ├── dataset.json\r\n",
      "    ├── \u001b[01;34mimagesTr\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0001_0000.nii.gz\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0004_0000.nii.gz\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0005_0000.nii.gz\u001b[00m\r\n",
      "    │   ├── \u001b[01;31mamos_0006_0000.nii.gz\u001b[00m\r\n",
      "    │   └── \u001b[01;31mamos_0007_0000.nii.gz\u001b[00m\r\n",
      "    └── \u001b[01;34mlabelsTr\u001b[00m\r\n",
      "        ├── \u001b[01;31mamos_0001.nii.gz\u001b[00m\r\n",
      "        ├── \u001b[01;31mamos_0004.nii.gz\u001b[00m\r\n",
      "        ├── \u001b[01;31mamos_0005.nii.gz\u001b[00m\r\n",
      "        ├── \u001b[01;31mamos_0006.nii.gz\u001b[00m\r\n",
      "        └── \u001b[01;31mamos_0007.nii.gz\u001b[00m\r\n",
      "\r\n",
      "12 directories, 44 files\r\n"
     ]
    }
   ],
   "source": [
    "# now your raw dataset directory structure should look like:\n",
    "!tree $nnUNet_raw_data_base/nnUNet_raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a311ab04",
   "metadata": {},
   "source": [
    "#### 3.3.2 Dataset Verification\n",
    "- Before going any further, verify that the data is present and labels and data matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "288f18c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training set\n",
      "checking case case_00000\n",
      "checking case case_00001\n",
      "checking case case_00002\n",
      "checking case case_00003\n",
      "checking case case_00004\n",
      "Verifying label values\n",
      "Expected label values are [0, 1]\n",
      "Labels OK\n",
      "Dataset OK\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_plan_and_preprocess -t 507 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7613c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training set\n",
      "checking case amos_0001\n",
      "checking case amos_0004\n",
      "checking case amos_0005\n",
      "checking case amos_0006\n",
      "checking case amos_0007\n",
      "Verifying label values\n",
      "Expected label values are [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Labels OK\n",
      "Dataset OK\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_plan_and_preprocess -t 508 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f5deb",
   "metadata": {},
   "source": [
    "#### 3.3.3 Data Target Apacing Sample & Normalization\n",
    "- We need to perform same target spacing sample && normalization in both domains, and saves it into the \"nnUNet_preprocessed\" folder.\n",
    "\n",
    "    - Voxel Spacing: it is the distance between voxels, it influence the image size, we can understand it as the resolution in natural images. Every image have different voxel spacing even if they are in the exact one dataset, it is not suitable for convolution operations according to literature, so we usually doing some resampling operations to make the voxel spacing is same in every image of both dataset;\n",
    "\n",
    "    - Intensity: it is the float value of every pixel in each slice of the grey CT images, usually same organs have similar intensity distribution even if they are captured by different scanners. Currently we use the intensity mean and std from the foreground of source domain dataset to perform normalization in both datasets, since foreground of source dataset have more classes, and we need to segmentation target dataset to these classes, so target dataset executed the same normalization.\n",
    "    \n",
    "- So we first process the target domain, get the dataset characteristic, and then apply it to the source domain\n",
    "- Also some rule based parameters will be extracted in this step, such as model architecture, learning rate, batch size..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1935c266",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amos_0001\n",
      "amos_0004\n",
      "amos_0005\n",
      "amos_0006\n",
      "amos_0007\n",
      "before crop: (1, 78, 512, 512) after crop: (1, 78, 512, 512) spacing: [5.         0.78200001 0.78200001] \n",
      "\n",
      "before crop: (1, 99, 512, 512) after crop: (1, 99, 512, 512) spacing: [5.         0.83499998 0.83499998] \n",
      "\n",
      "before crop: (1, 80, 768, 768) after crop: (1, 80, 768, 768) spacing: [5.         0.56901044 0.56901044] \n",
      "\n",
      "before crop: (1, 90, 768, 768) after crop: (1, 90, 768, 768) spacing: [5.        0.5703125 0.5703125] \n",
      "\n",
      "before crop: (1, 107, 768, 768) after crop: (1, 107, 768, 768) spacing: [5.         0.51822919 0.51822919] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Task508_AMOS_kidney\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, False)])\n",
      "the median shape of the dataset is  [139.7515528  263.90122779 263.90122779]\n",
      "the max shape in the dataset is  [166.14906832 270.37037037 270.37037037]\n",
      "the min shape in the dataset is  [121.11801242 245.67902176 245.67902176]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [139.7515528  263.90122779 263.90122779]\n",
      "generating configuration for 3d_fullres\n",
      "generating configuration for 3d_lowres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 160, 160]), 'median_patient_size_in_voxels': array([140, 264, 264]), 'current_spacing': array([3.22, 1.62, 1.62]), 'original_spacing': array([3.22, 1.62, 1.62]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /home/vmagent/app/dataset/nnUNet_raw_data_base/nnUNet_cropped_data/Task508_AMOS_kidney\n",
      "output_folder: /home/vmagent/app/dataset/nnUNet_preprocessed/Task508_AMOS_kidney\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.        , 0.78200001, 0.78200001]), 'spacing_transposed': array([5.        , 0.78200001, 0.78200001]), 'data.shape (data is transposed)': (1, 78, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 121, 247, 247)} \n",
      "\n",
      "1 8301\n",
      "10 5644\n",
      "11 237\n",
      "12 330\n",
      "13 4063\n",
      "14 3405\n",
      "15 6393\n",
      "2 10000\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "3 10000\n",
      "4 2170\n",
      "5 707\n",
      "6 10000\n",
      "7 10000\n",
      "8 5404\n",
      "9 7776\n",
      "saving:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task508_AMOS_kidney/nnUNetData_plans_v2.1_trgSp_kits19_stage0/amos_0004.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.        , 0.83499998, 0.83499998]), 'spacing_transposed': array([5.        , 0.83499998, 0.83499998]), 'data.shape (data is transposed)': (1, 99, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 154, 264, 264)} \n",
      "\n",
      "1 10000\n",
      "10 7610\n",
      "11 321\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "12 434\n",
      "13 10000\n",
      "14 10000\n",
      "15 4170\n",
      "2 10000\n",
      "3 10000\n",
      "4 7332\n",
      "5 1936\n",
      "6 10000\n",
      "7 10000\n",
      "8 10000\n",
      "9 9651\n",
      "saving:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task508_AMOS_kidney/nnUNetData_plans_v2.1_trgSp_kits19_stage0/amos_0006.npz\n",
      "before: {'spacing': array([5.        , 0.56901044, 0.56901044]), 'spacing_transposed': array([5.        , 0.56901044, 0.56901044]), 'data.shape (data is transposed)': (1, 80, 768, 768)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 124, 270, 270)} \n",
      "\n",
      "1 10000\n",
      "10 3353\n",
      "11 269\n",
      "12 104\n",
      "13 9263\n",
      "14 3961\n",
      "15 7045\n",
      "2 10000\n",
      "3 10000\n",
      "4 5030\n",
      "5 819\n",
      "6 10000\n",
      "7 10000\n",
      "8 10000\n",
      "9 4041\n",
      "saving:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task508_AMOS_kidney/nnUNetData_plans_v2.1_trgSp_kits19_stage0/amos_0005.npz\n",
      "before: {'spacing': array([5.       , 0.5703125, 0.5703125]), 'spacing_transposed': array([5.       , 0.5703125, 0.5703125]), 'data.shape (data is transposed)': (1, 90, 768, 768)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 140, 270, 270)} \n",
      "\n",
      "1 10000\n",
      "10 4298\n",
      "11 309\n",
      "12 642\n",
      "13 4293\n",
      "14 8132\n",
      "15 4689\n",
      "2 10000\n",
      "3 10000\n",
      "4 1112\n",
      "5 1443\n",
      "6 10000\n",
      "7 10000\n",
      "8 10000\n",
      "9 8188\n",
      "saving:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task508_AMOS_kidney/nnUNetData_plans_v2.1_trgSp_kits19_stage0/amos_0001.npz\n",
      "before: {'spacing': array([5.        , 0.51822919, 0.51822919]), 'spacing_transposed': array([5.        , 0.51822919, 0.51822919]), 'data.shape (data is transposed)': (1, 107, 768, 768)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 166, 246, 246)} \n",
      "\n",
      "1 10000\n",
      "10 10000\n",
      "11 330\n",
      "12 584\n",
      "13 4551\n",
      "14 4802\n",
      "15 4111\n",
      "2 10000\n",
      "3 10000\n",
      "4 1764\n",
      "5 1578\n",
      "6 10000\n",
      "7 10000\n",
      "8 10000\n",
      "9 7699\n",
      "saving:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task508_AMOS_kidney/nnUNetData_plans_v2.1_trgSp_kits19_stage0/amos_0007.npz\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_plan_and_preprocess -t 508 -pl2d None -pl3d ExperimentPlanner3D_v21_customTargetSpacing_kits19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2a25674",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_00000\n",
      "case_00001\n",
      "case_00002\n",
      "case_00003\n",
      "case_00004\n",
      "before crop: (1, 64, 512, 512) after crop: (1, 64, 512, 512) spacing: [4.        0.9765625 0.9765625] \n",
      "\n",
      "before crop: (1, 261, 512, 512) after crop: (1, 261, 512, 512) spacing: [1.         0.93945312 0.93945312] \n",
      "\n",
      "before crop: (1, 270, 512, 512) after crop: (1, 270, 512, 512) spacing: [1.         0.85546875 0.85546875] \n",
      "\n",
      "before crop: (1, 611, 512, 512) after crop: (1, 611, 512, 512) spacing: [0.5        0.91992188 0.91992188] \n",
      "\n",
      "before crop: (1, 602, 512, 512) after crop: (1, 602, 512, 512) spacing: [0.5        0.79882812 0.79882812] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Task507_KiTS_kidney\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, False)])\n",
      "the median shape of the dataset is  [ 83.85093168 290.74074074 290.74074074]\n",
      "the max shape in the dataset is  [ 94.8757764  308.64197531 308.64197531]\n",
      "the min shape in the dataset is  [ 79.50310559 252.4691358  252.4691358 ]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [ 83.85093168 290.74074074 290.74074074]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 84, 291, 291]), 'current_spacing': array([3.22, 1.62, 1.62]), 'original_spacing': array([3.22, 1.62, 1.62]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_plan_and_preprocess -t 507 -pl2d None -pl3d ExperimentPlanner3D_v21_customTargetSpacing_kits19 -no_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2420fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before changing...\r\n",
      "mean: 105.65725708007812\r\n",
      "std: 74.52706146240234\r\n",
      "percentile_99_5: 251.0\r\n",
      "percentile_00_5: -88.0\r\n",
      "after changing...\r\n",
      "mean: 32.562679290771484\r\n",
      "std: 131.16937255859375\r\n",
      "percentile_99_5: 252.0\r\n",
      "percentile_00_5: -979.0\r\n"
     ]
    }
   ],
   "source": [
    "!python dataset_conversion/kits_convert_label.py intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29df971b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_00000\n",
      "case_00001\n",
      "case_00002\n",
      "case_00003\n",
      "case_00004\n",
      "\n",
      "\n",
      "\n",
      " Task507_KiTS_kidney\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "Initializing to run preprocessing\n",
      "npz folder: /home/vmagent/app/dataset/nnUNet_raw_data_base/nnUNet_cropped_data/Task507_KiTS_kidney\n",
      "output_folder: /home/vmagent/app/dataset/nnUNet_preprocessed/Task507_KiTS_kidney\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([4.       , 0.9765625, 0.9765625]), 'spacing_transposed': array([4.       , 0.9765625, 0.9765625]), 'data.shape (data is transposed)': (1, 64, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 80, 309, 309)} \n",
      "\n",
      "1 10000\n",
      "saving:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task507_KiTS_kidney/nnUNetData_plans_v2.1_trgSp_kits19_stage0/case_00004.npz\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([1.        , 0.85546875, 0.85546875]), 'spacing_transposed': array([1.        , 0.85546875, 0.85546875]), 'data.shape (data is transposed)': (1, 270, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 84, 270, 270)} \n",
      "\n",
      "before: {'spacing': array([1.        , 0.93945312, 0.93945312]), 'spacing_transposed': array([1.        , 0.93945312, 0.93945312]), 'data.shape (data is transposed)': (1, 261, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 81, 297, 297)} \n",
      "\n",
      "1 10000\n",
      "saving:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task507_KiTS_kidney/nnUNetData_plans_v2.1_trgSp_kits19_stage0/case_00003.npz\n",
      "1 10000\n",
      "saving:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task507_KiTS_kidney/nnUNetData_plans_v2.1_trgSp_kits19_stage0/case_00002.npz\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([0.5       , 0.79882812, 0.79882812]), 'spacing_transposed': array([0.5       , 0.79882812, 0.79882812]), 'data.shape (data is transposed)': (1, 602, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 93, 252, 252)} \n",
      "\n",
      "1 10000\n",
      "saving:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task507_KiTS_kidney/nnUNetData_plans_v2.1_trgSp_kits19_stage0/case_00001.npz\n",
      "before: {'spacing': array([0.5       , 0.91992188, 0.91992188]), 'spacing_transposed': array([0.5       , 0.91992188, 0.91992188]), 'data.shape (data is transposed)': (1, 611, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 95, 291, 291)} \n",
      "\n",
      "1 10000\n",
      "saving:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task507_KiTS_kidney/nnUNetData_plans_v2.1_trgSp_kits19_stage0/case_00000.npz\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_plan_and_preprocess -t 507 -pl2d None -pl3d ExperimentPlanner3D_v21_customTargetSpacing_kits19 -no_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b432200",
   "metadata": {},
   "source": [
    "## 4. Lauch training\n",
    "\n",
    "### 4.1 pre-trained target domain\n",
    "- We will first pre-train model in AMOS dataset, and use this pre-trained model later for prameter initialization for domain adaptation\n",
    "- We use [3D-UNet](https://arxiv.org/abs/1606.06650) to train the model\n",
    "- *For demostration, we only train 1 epochs:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0bbca0b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  15\n",
      "modalities:  {0: 'CT'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 160, 160]), 'median_patient_size_in_voxels': array([140, 264, 264]), 'current_spacing': array([3.22, 1.62, 1.62]), 'original_spacing': array([3.22, 1.62, 1.62]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task508_AMOS_kidney/nnUNetData_plans_v2.1_trgSp_kits19\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2022-10-14 05:44:12.861702: Using splits from existing split file: /home/vmagent/app/dataset/nnUNet_preprocessed/Task508_AMOS_kidney/splits_final.pkl\n",
      "2022-10-14 05:44:12.862126: The split file contains 5 splits.\n",
      "2022-10-14 05:44:12.862187: Desired fold for training: 1\n",
      "2022-10-14 05:44:12.862242: This split has 4 training and 1 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2022-10-14 05:44:13.567890: lr: 0.01\n",
      "2022-10-14 05:44:13.623358: WARNING!!! You are attempting to run training on a CPU (torch.cuda.is_available() is False). This can be VERY slow!\n",
      "2022-10-14 05:44:27.096203: Unable to plot network architecture:\n",
      "2022-10-14 05:44:27.097273: No module named 'hiddenlayer'\n",
      "2022-10-14 05:44:27.097450: \n",
      "printing the network instead:\n",
      "\n",
      "2022-10-14 05:44:27.097556: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(480, 240, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(240, 240, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(240, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(120, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(60, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(1, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(30, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(60, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(120, 240, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(240, 240, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(240, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(320, 240, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(240, 120, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(120, 60, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(60, 30, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(240, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(120, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(60, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(30, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2022-10-14 05:44:27.105795: \n",
      "\n",
      "2022-10-14 05:44:27.106746: \n",
      "epoch:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-14 06:36:18.362553: train loss : 0.5081\n",
      "2022-10-14 06:39:48.485496: validation loss: 0.3403\n",
      "2022-10-14 06:39:48.486991: Average global foreground Dice: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2022-10-14 06:39:48.487164: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-10-14 06:39:48.979372: lr: 0.009991\n",
      "2022-10-14 06:39:48.979655: This epoch took 3321.872497 s\n",
      "\n",
      "2022-10-14 06:39:48.980681: saving checkpoint...\n",
      "2022-10-14 06:39:49.231418: done, saving took 0.25 seconds\n",
      "amos_0007 (2, 166, 246, 246)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 166, 246, 246)\n",
      "patch size: [ 80 160 160]\n",
      "steps (x, y, and z): [[0, 29, 57, 86], [0, 43, 86], [0, 43, 86]]\n",
      "number of tiles: 36\n",
      "computing Gaussian\n",
      "done\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "separate z: True lowres axis [0]\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "^C\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-33:\n",
      "Process ForkPoolWorker-34:\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/intel/oneapi/intelpython/latest/envs/pytorch-1.10.0/bin/nnUNet_train\", line 33, in <module>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/AIDK/AIDK/TransferLearningKit/src/task/medical_segmentation/nnunet/run/run_training.py\", line 194, in main\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "    trainer.validate(save_softmax=args.npz, validation_folder_name=val_folder,\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/work/AIDK/AIDK/TransferLearningKit/src/task/medical_segmentation/nnunet/training/network_training/nnUNetTrainerV2.py\", line 192, in validate\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/queues.py\", line 366, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "    ret = super().validate(do_mirroring=do_mirroring, use_sliding_window=use_sliding_window, step_size=step_size,\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/work/AIDK/AIDK/TransferLearningKit/src/task/medical_segmentation/nnunet/training/network_training/nnUNetTrainer.py\", line 648, in validate\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "    _ = [i.get() for i in results]\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/work/AIDK/AIDK/TransferLearningKit/src/task/medical_segmentation/nnunet/training/network_training/nnUNetTrainer.py\", line 648, in <listcomp>\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "    _ = [i.get() for i in results]\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/pool.py\", line 765, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/multiprocessing/pool.py\", line 762, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/threading.py\", line 574, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/opt/intel/oneapi/pytorch/latest/lib/python3.9/threading.py\", line 312, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 508 1 --epochs 1 -p nnUNetPlansv2.1_trgSp_kits19 --disable_postprocessing_on_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67fdf64",
   "metadata": {},
   "source": [
    "### 4.2 domain adaptation from AMOS to KiTS\n",
    "- Now we apply domain adaptation algorithm to transfer knowledge from AMOS dataset to KiTS dataset\n",
    "- We use a DANN-like model architecture, the DANN algorithm is illustrated as follows:\n",
    "![dann](doc/imgs/dann.png)\n",
    "- Notice: \n",
    "    - we donot use **any label** from target domain KiTS, we only use label from source domain AMOS for training\n",
    "    - *For demostration, we only train 1 epochs:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ea13eb9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################\n",
      "For that I will be using the following source data configuration:\n",
      "num_classes:  15\n",
      "modalities:  {0: 'CT'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 160, 160]), 'median_patient_size_in_voxels': array([140, 264, 264]), 'current_spacing': array([3.22, 1.62, 1.62]), 'original_spacing': array([3.22, 1.62, 1.62]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "\n",
      "I am using source data from this folder:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task508_AMOS_kidney/nnUNetData_plans_v2.1_trgSp_kits19\n",
      "###############################################\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainer_DA_V2.nnUNetTrainer_DA_V2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 84, 291, 291]), 'current_spacing': array([3.22, 1.62, 1.62]), 'original_spacing': array([3.22, 1.62, 1.62]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task507_KiTS_kidney/nnUNetData_plans_v2.1_trgSp_kits19\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2022-10-14 07:07:07.833856: Using splits from existing split file: /home/vmagent/app/dataset/nnUNet_preprocessed/Task507_KiTS_kidney/splits_final.pkl\n",
      "2022-10-14 07:07:07.834207: The split file contains 5 splits.\n",
      "2022-10-14 07:07:07.834274: Desired fold for training: 1\n",
      "2022-10-14 07:07:07.834334: This split has 4 training and 1 validation cases.\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "################### Loading pretrained weights from file  /home/vmagent/app/dataset/nnUNet_trained_models/nnUNet/3d_fullres/Task508_AMOS_kidney/nnUNetTrainerV2__nnUNetPlansv2.1_trgSp_kits19/fold_1/model_final_checkpoint.model ###################\n",
      "################### Done ###################\n",
      "2022-10-14 07:07:09.178776: lr index 0: 0.002\n",
      "2022-10-14 07:07:09.179135: lr index 1: 0.01\n",
      "2022-10-14 07:07:09.190930: WARNING!!! You are attempting to run training on a CPU (torch.cuda.is_available() is False). This can be VERY slow!\n",
      "2022-10-14 07:07:12.011414: Unable to plot network architecture:\n",
      "2022-10-14 07:07:12.012101: No module named 'hiddenlayer'\n",
      "2022-10-14 07:07:12.012269: \n",
      "printing the network instead:\n",
      "\n",
      "2022-10-14 07:07:12.012412: Generic_UNet_DA_V2(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(480, 240, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(240, 240, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(240, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(120, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(60, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(1, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(30, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(60, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(120, 240, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(240, 240, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(240, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(320, 240, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(240, 120, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(120, 60, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(60, 30, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(240, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(120, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(60, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(30, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2022-10-14 07:07:12.019301: \n",
      "\n",
      "2022-10-14 07:07:12.020003: \n",
      "epoch:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-14 08:03:19.386149: train loss : 1.0404\n",
      "2022-10-14 08:05:40.979750: validation loss: 0.0087\n",
      "2022-10-14 08:05:40.981636: Average global foreground Dice: [0.0]\n",
      "2022-10-14 08:05:40.981980: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-10-14 08:05:41.279021: lr index 0: 0.001982\n",
      "2022-10-14 08:05:41.279208: lr index 1: 0.00991\n",
      "2022-10-14 08:05:41.279391: This epoch took 3509.259070 s\n",
      "\n",
      "2022-10-14 08:05:41.280476: saving checkpoint...\n",
      "2022-10-14 08:05:41.633380: done, saving took 0.35 seconds\n",
      "case_00004 (2, 80, 309, 309)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 80, 309, 309)\n",
      "patch size: [ 80 160 160]\n",
      "steps (x, y, and z): [[0], [0, 74, 149], [0, 74, 149]]\n",
      "number of tiles: 9\n",
      "computing Gaussian\n",
      "done\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "separate z: True lowres axis [0]\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2022-10-14 08:07:06.740799: finished prediction\n",
      "2022-10-14 08:07:06.742050: evaluation of raw predictions\n",
      "/work/AIDK/AIDK/TransferLearningKit/src/task/medical_segmentation/nnunet/evaluation/evaluator.py:381: RuntimeWarning: Mean of empty slice\n",
      "  all_scores[\"mean\"][label][score] = float(np.nanmean(all_scores[\"mean\"][label][score]))\n",
      "2022-10-14 08:07:07.743454: mean dice score is: 0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train_da 3d_fullres nnUNetTrainer_DA_V2 508 507 1 \\\n",
    "    -p nnUNetPlansv2.1_trgSp_kits19 \\\n",
    "    -sp nnUNetPlansv2.1_trgSp_kits19 \\\n",
    "    --epochs 1 --loss_weights 1 0 1 0 0 \\\n",
    "    -pretrained_weights /home/vmagent/app/dataset/nnUNet_trained_models/nnUNet/3d_fullres/Task508_AMOS_kidney/nnUNetTrainerV2__nnUNetPlansv2.1_trgSp_kits19/fold_1/model_final_checkpoint.model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c5aac5",
   "metadata": {},
   "source": [
    "## 5. Inference & Evaluation\n",
    "\n",
    "### 5.1 Inference on KiTS dataset with adapted model\n",
    "- Now we use the model trained from 4.2 to perferm inference on KiTS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e91f989",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model stored in  /home/vmagent/app/dataset/nnUNet_trained_models/nnUNet/3d_fullres/Task507_KiTS_kidney/nnUNetTrainer_DA_V2__nnUNetPlansv2.1_trgSp_kits19\n",
      "This model expects 1 input modalities for each image\n",
      "Found 5 unique case ids, here are some examples: ['case_00000' 'case_00000' 'case_00003' 'case_00003' 'case_00002']\n",
      "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
      "number of cases: 5\n",
      "number of cases that still need to be predicted: 5\n",
      "emptying cuda cache\n",
      "loading parameters for folds, [1]\n",
      "using the following model files:  ['/home/vmagent/app/dataset/nnUNet_trained_models/nnUNet/3d_fullres/Task507_KiTS_kidney/nnUNetTrainer_DA_V2__nnUNetPlansv2.1_trgSp_kits19/fold_1/model_final_checkpoint.model']\n",
      "starting preprocessing generator\n",
      "starting prediction...\n",
      "preprocessing /home/vmagent/app/dataset/prediction/case_00000.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "preprocessing /home/vmagent/app/dataset/prediction/case_00001.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "preprocessing /home/vmagent/app/dataset/prediction/case_00002.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "preprocessing /home/vmagent/app/dataset/prediction/case_00003.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "preprocessing /home/vmagent/app/dataset/prediction/case_00004.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "before crop: (1, 64, 512, 512) after crop: (1, 64, 512, 512) spacing: [4.        0.9765625 0.9765625] \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([4.       , 0.9765625, 0.9765625]), 'spacing_transposed': array([4.       , 0.9765625, 0.9765625]), 'data.shape (data is transposed)': (1, 64, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 80, 309, 309)} \n",
      "\n",
      "(1, 80, 309, 309)\n",
      "This worker has ended successfully, no errors to report\n",
      "predicting /home/vmagent/app/dataset/prediction/case_00004.nii.gz\n",
      "/opt/intel/oneapi/pytorch/latest/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "/opt/intel/oneapi/pytorch/latest/lib/python3.9/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (1, 80, 309, 309)\n",
      "patch size: [ 80 160 160]\n",
      "steps (x, y, and z): [[0], [0, 74, 149], [0, 74, 149]]\n",
      "number of tiles: 9\n",
      "computing Gaussian\n",
      "done\n",
      "before crop: (1, 261, 512, 512) after crop: (1, 261, 512, 512) spacing: [1.         0.93945312 0.93945312] \n",
      "\n",
      "before crop: (1, 270, 512, 512) after crop: (1, 270, 512, 512) spacing: [1.         0.85546875 0.85546875] \n",
      "\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 1\n",
      "before crop: (1, 611, 512, 512) after crop: (1, 611, 512, 512) spacing: [0.5        0.91992188 0.91992188] \n",
      "\n",
      "before crop: (1, 602, 512, 512) after crop: (1, 602, 512, 512) spacing: [0.5        0.79882812 0.79882812] \n",
      "\n",
      "no separate z, order 1\n",
      "prediction done\n",
      "before: {'spacing': array([1.        , 0.93945312, 0.93945312]), 'spacing_transposed': array([1.        , 0.93945312, 0.93945312]), 'data.shape (data is transposed)': (1, 261, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 81, 297, 297)} \n",
      "\n",
      "(1, 81, 297, 297)\n",
      "This worker has ended successfully, no errors to report\n",
      "predicting /home/vmagent/app/dataset/prediction/case_00002.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (1, 81, 297, 297)\n",
      "patch size: [ 80 160 160]\n",
      "steps (x, y, and z): [[0, 1], [0, 68, 137], [0, 68, 137]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "no separate z, order 3\n",
      "force_separate_z: None interpolation order: 1\n",
      "separate z: True lowres axis [0]\n",
      "no separate z, order 3\n",
      "before: {'spacing': array([1.        , 0.85546875, 0.85546875]), 'spacing_transposed': array([1.        , 0.85546875, 0.85546875]), 'data.shape (data is transposed)': (1, 270, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 84, 270, 270)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "(1, 84, 270, 270)\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([0.5       , 0.79882812, 0.79882812]), 'spacing_transposed': array([0.5       , 0.79882812, 0.79882812]), 'data.shape (data is transposed)': (1, 602, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 93, 252, 252)} \n",
      "\n",
      "(1, 93, 252, 252)\n",
      "before: {'spacing': array([0.5       , 0.91992188, 0.91992188]), 'spacing_transposed': array([0.5       , 0.91992188, 0.91992188]), 'data.shape (data is transposed)': (1, 611, 512, 512)} \n",
      "after:  {'spacing': array([3.22, 1.62, 1.62]), 'data.shape (data is resampled)': (1, 95, 291, 291)} \n",
      "\n",
      "(1, 95, 291, 291)\n",
      "prediction done\n",
      "predicting /home/vmagent/app/dataset/prediction/case_00003.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (1, 84, 270, 270)\n",
      "patch size: [ 80 160 160]\n",
      "steps (x, y, and z): [[0, 4], [0, 55, 110], [0, 55, 110]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "force_separate_z: None interpolation order: 1\n",
      "separate z: False lowres axis None\n",
      "no separate z, order 1\n",
      "prediction done\n",
      "predicting /home/vmagent/app/dataset/prediction/case_00001.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (1, 93, 252, 252)\n",
      "patch size: [ 80 160 160]\n",
      "steps (x, y, and z): [[0, 13], [0, 46, 92], [0, 46, 92]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "force_separate_z: None interpolation order: 1\n",
      "separate z: False lowres axis None\n",
      "no separate z, order 1\n",
      "prediction done\n",
      "This worker has ended successfully, no errors to report\n",
      "predicting /home/vmagent/app/dataset/prediction/case_00000.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (1, 95, 291, 291)\n",
      "patch size: [ 80 160 160]\n",
      "steps (x, y, and z): [[0, 15], [0, 66, 131], [0, 66, 131]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "This worker has ended successfully, no errors to report\n",
      "This worker has ended successfully, no errors to report\n",
      "inference done. Now waiting for the segmentation export to finish...\n",
      "force_separate_z: None interpolation order: 1\n",
      "separate z: False lowres axis None\n",
      "no separate z, order 1\n",
      "force_separate_z: None interpolation order: 1\n",
      "separate z: False lowres axis None\n",
      "no separate z, order 1\n",
      "WARNING! Cannot run postprocessing because the postprocessing file is missing. Make sure to run consolidate_folds in the output folder of the model first!\n",
      "The folder you need to run this in is /home/vmagent/app/dataset/nnUNet_trained_models/nnUNet/3d_fullres/Task507_KiTS_kidney/nnUNetTrainer_DA_V2__nnUNetPlansv2.1_trgSp_kits19\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_predict \\\n",
    "    -i ${nnUNet_raw_data_base}/nnUNet_raw_data/Task507_KiTS_kidney/imagesTr/ \\\n",
    "    -o /home/vmagent/app/dataset/prediction \\\n",
    "    -f 1 \\\n",
    "    -t 507 -m 3d_fullres -p nnUNetPlansv2.1_trgSp_kits19 \\\n",
    "    --disable_tta \\\n",
    "    -tr nnUNetTrainer_DA_V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c36d4",
   "metadata": {},
   "source": [
    "### 5.2 Evaluate the prediction on KiTS using the given label\n",
    "- Note: \n",
    "    - the label is not used in training, it is only used in this evaluation step\n",
    "    - In practical, if you donnot have any label, you can just skip this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef6bc1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/AIDK/AIDK/TransferLearningKit/src/task/medical_segmentation/nnunet/evaluation/evaluator.py:381: RuntimeWarning: Mean of empty slice\r\n",
      "  all_scores[\"mean\"][label][score] = float(np.nanmean(all_scores[\"mean\"][label][score]))\r\n",
      "0.0\r\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_evaluate_folder \\\n",
    "    -ref ${nnUNet_raw_data_base}/nnUNet_raw_data/Task507_KiTS_kidney/labelsTr \\\n",
    "    -pred /home/vmagent/app/dataset/prediction \\\n",
    "    -l 1 \\\n",
    "    --common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba19a5d",
   "metadata": {
    "id": "LetWZXletANY"
   },
   "source": [
    "### 5.3 Visualization of Data and Segmentations\n",
    "- Download files from server:\n",
    "\n",
    "   - Images from: ```${nnUNet_raw_data_base}/nnUNet_raw_data/Task507_KiTS_kidney/imagesTr/```\n",
    "\n",
    "   - Segmentations from: ```${nnUNet_raw_data_base}/nnUNet_raw_data/Task507_KiTS_kidney/labelsTr/```\n",
    "\n",
    "   - predictions from: ```/home/vmagent/app/dataset/prediction```\n",
    "\n",
    "\n",
    "- After downloading these files you can visualize them with any volumetric visualization program.\n",
    "For this we would advise to use [MITK](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK)) which already has some great [tutorials](https://www.mitk.org/wiki/Tutorials). \n",
    "    - If you have not already downloaded it, here is the [MITK Download Link](https://www.mitk.org/wiki/Downloads)\n",
    "    \n",
    "- Here is a demostration of visualization result from MITK on KiTS dataset\n",
    "![KiTS_visualization](doc/imgs/KiTS_visualization.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154aa11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e903885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea70a4a880de7dd18912b56eedd122a3d55dbeaaf358005a17bc85157b93ab53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
