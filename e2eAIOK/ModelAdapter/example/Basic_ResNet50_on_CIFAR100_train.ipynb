{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf11f116",
   "metadata": {},
   "source": [
    "# Train ResNet50 on CIFAR100\n",
    "In this notebook we will show a basic pipeline to train a ResNet50 model on CIFAR100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ad345",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21507528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms,datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6502c5f4",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66290cf3",
   "metadata": {},
   "source": [
    "### Define Data Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5ab12af",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343) # mean for 3 channels\n",
    "CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)  # std for 3 channels\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "  transforms.RandomCrop(32, padding=4),\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(CIFAR100_TRAIN_MEAN, CIFAR100_TRAIN_STD)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "  transforms.RandomCrop(32, padding=4),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(CIFAR100_TRAIN_MEAN, CIFAR100_TRAIN_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198903f5",
   "metadata": {},
   "source": [
    "### Prepare dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f17bfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_workers = 1 # data worker\n",
    "data_folder='./dataset' # dataset location\n",
    "train_set = datasets.CIFAR100(root=data_folder, train=True, download=True, transform=train_transform)\n",
    "test_set = datasets.CIFAR100(root=data_folder, train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=1, drop_last=False)\n",
    "validate_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a22f4a5",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "043a86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = timm.create_model('resnet18', pretrained=False, num_classes=100).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7300bebf",
   "metadata": {},
   "source": [
    "## create optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4f7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# create optimizer #################\n",
    "init_lr = 0.01\n",
    "weight_decay = 0.005\n",
    "momentum = 0.9\n",
    "optimizer = optim.SGD(model.parameters(),lr=init_lr, weight_decay=weight_decay,momentum=momentum)\n",
    "################# create scheduler #################\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25db44",
   "metadata": {},
   "source": [
    "## Create Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b9bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "max_epoch = 1 # max 1 epoch\n",
    "print_interval = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8890b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output,label):\n",
    "    pred = output.data.cpu().max(1)[1]\n",
    "    label = label.data.cpu()\n",
    "    if label.shape == output.shape:\n",
    "        label = label.max(1)[1]\n",
    "    return torch.mean((pred == label).float())\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, scheduler):\n",
    "        self._model = model\n",
    "        self._optimizer = optimizer\n",
    "        self._scheduler = scheduler\n",
    "        \n",
    "    def train(self, train_dataloader, valid_dataloader, max_epoch):\n",
    "        ''' \n",
    "        :param train_dataloader: train dataloader\n",
    "        :param valid_dataloader: validation dataloader\n",
    "        :param max_epoch: steps per epoch\n",
    "        '''\n",
    "        for epoch in range(0, max_epoch):\n",
    "            ################## train #####################\n",
    "            model.train()  # set training flag\n",
    "            for (cur_step,(data, label)) in enumerate(train_dataloader):\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss_value = loss_fn(output, label)\n",
    "                loss_value.backward()       \n",
    "                if cur_step%print_interval == 0:\n",
    "                    batch_acc = accuracy(output,label)\n",
    "                    dt = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') # date time\n",
    "                    print(\"[{}] epoch {} step {} : training batch loss {:.4f}, training batch acc {:.4f}\".format(\n",
    "                      dt, epoch, cur_step, loss_value.item(), batch_acc.item()))\n",
    "                self._optimizer.step()\n",
    "            self._scheduler.step()\n",
    "            ################## evaluate ######################\n",
    "            self.evaluate(model, valid_dataloader, epoch)\n",
    "            \n",
    "def evaluate(self, model, valid_dataloader, epoch):\n",
    "    with torch.no_grad():\n",
    "        model.eval()  \n",
    "        loss_cum = 0.0\n",
    "        sample_num = 0\n",
    "        acc_cum = 0.0\n",
    "        for (cur_step,(data, label)) in enumerate(valid_dataloader):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(data)\n",
    "            batch_size = data.size(0)\n",
    "            sample_num += batch_size\n",
    "            loss_cum += loss_fn(output, label).item() * batch_size\n",
    "            acc_cum += accuracy(output, label).item() * batch_size\n",
    "        dt = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') # date time\n",
    "        if sample_num > 0:\n",
    "            loss_value = loss_cum/sample_num\n",
    "            acc_value = acc_cum/sample_num\n",
    "        else:\n",
    "            loss_value = 0.0\n",
    "            acc_value = 0.0\n",
    "\n",
    "        print(\"[{}] epoch {} : evaluation loss {:.4f}, evaluation acc {:.4f}\".format(\n",
    "            dt, epoch, loss_value, acc_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b229e4",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80fe155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-14 09:01:23] epoch 0 step 0 : training batch loss 4.6888, training batch acc 0.0078\n",
      "[2022-11-14 09:01:44] epoch 0 step 100 : training batch loss 4.5396, training batch acc 0.0547\n",
      "[2022-11-14 09:02:02] epoch 0 step 200 : training batch loss 4.5376, training batch acc 0.0234\n",
      "[2022-11-14 09:02:21] epoch 0 step 300 : training batch loss 4.4733, training batch acc 0.0391\n",
      "[2022-11-14 09:02:42] epoch 0 : evaluation loss 4.3469, evaluation acc 0.0437\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, optimizer, scheduler)\n",
    "trainer.train(train_loader,validate_loader,max_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
