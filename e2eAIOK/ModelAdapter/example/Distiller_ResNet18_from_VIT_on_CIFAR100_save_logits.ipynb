{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb2bd5d",
   "metadata": {},
   "source": [
    "# Save logits from VIT with Distiller on CIFAR100\n",
    "Distiller can transfer knowledge from a heavy model (teacher) to a light one (student) with different structure.\n",
    "\n",
    "* Teacher is a large model pretrained on specific dataset, which contains sufficient knowledge for this task, while the student model has much smaller structure. Distiller trains the student not only on the dataset, but also with the help of teacherâ€™s knowledge.\n",
    "* Distiller can take use of the knowledge from the existing pretrained large models but use much less training time. It can also significantly improve the converge  speed and predicting accuracy of a small model, which is very helpful for inference.\n",
    "![Distiller](../doc/imgs/distiller.png)\n",
    "\n",
    "However, during the distillation process, teacher forwarding usually takes a lot of time. We can use logits saving function in distiller to save predictions from teacher in adavance, then lots of time can be saved during student training.\n",
    "\n",
    "## Notebook Content\n",
    "In this notebook, we will show how to use logits saving function, and here we still take VIT as an example.\n",
    "\n",
    "To enable saving logits function, we just need to add two steps in original pipeline:\n",
    "- Wrap train_dataset with DataWrapper\n",
    "- Call prepare_logits() in Distiller and exit\n",
    "\n",
    "Note: We need to save all the data without any sampling, make sure you have disable \"channel_last\" or \"sampler\" in dataloader, which can avoid data lossing in later logits using process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51d390c",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f878badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms,datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "import transformers\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc00450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/vmagent/app/e2eAIOK/e2eAIOK/ModelAdapter/\")\n",
    "from ModelAdapter.engine_core.transferrable_model import make_transferrable_with_knowledge_distillation\n",
    "from ModelAdapter.engine_core.distiller import KD\n",
    "from ModelAdapter.engine_core.distiller.utils import logits_wrap_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec28cbf4",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "### Define Data Preprocessor for teacher\n",
    "For teacher, as pretrained model is trained on large imgage size, scale 32x32 to 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c016312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343) # mean for 3 channels\n",
    "CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)  # std for 3 channels\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "  transforms.RandomCrop(32, padding=4),\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.Resize(224), \n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(CIFAR100_TRAIN_MEAN, CIFAR100_TRAIN_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85fb033",
   "metadata": {},
   "source": [
    "### Prepare and warp dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69896736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_workers = 1 # data worker\n",
    "data_folder='./dataset' # dataset location\n",
    "train_set = datasets.CIFAR100(root=data_folder, train=True, download=True, transform=train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ccda0",
   "metadata": {},
   "source": [
    "Warp train dataset with DataWrapper, which helps to save data augmentation information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b46a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_path = './logits1' # path to save the logits\n",
    "save_logits = True # save logits\n",
    "train_set = logits_wrap_dataset(train_set, logits_path=logits_path, num_classes=100, save_logits=save_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210a1e2",
   "metadata": {},
   "source": [
    "Create dataloader with new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232dee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481901ed",
   "metadata": {},
   "source": [
    "## Create Distiller and save logits\n",
    "When define distiller, we need to define teacher_type with a name start with \"huggingface\" if the teacher model comes from hugging face. Otherwise, don't need to set it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17413057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.05 s, sys: 353 ms, total: 3.4 s\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "teacher_model = transformers.ViTForImageClassification.from_pretrained('edumunozsala/vit_base-224-in21k-ft-cifar100')\n",
    "distiller= KD(teacher_model,teacher_type=\"huggingface_vit_base-224-in21k-ft-cifar100\") #if model from huggingface, set teacher_type, otherwise no need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9cedb3",
   "metadata": {},
   "source": [
    "Call prepare_logits() to save the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15548288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 took 3.130923271179199 seconds\n",
      "CPU times: user 1min 43s, sys: 21.3 s, total: 2min 4s\n",
      "Wall time: 3.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_epoch = 1\n",
    "distiller.prepare_logits(train_loader, max_epoch, device = \"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
