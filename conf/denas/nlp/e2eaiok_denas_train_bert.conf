# conf for Bert-based DE-NAS
domain: bert
task_name: squad1
data_set: SQuADv1.1
num_train_examples: 87599
best_model_structure: /home/vmagent/app/e2eaiok/e2eAIOK/DeNas/best_model_structure.txt
model: /home/vmagent/app/dataset/bert-base-uncased/
model_dir: /home/vmagent/app/dataset/bert-base-uncased/
data_dir: /home/vmagent/app/dataset/SQuAD/
output_dir: /home/vmagent/app/e2eaiok/e2eAIOK/DeNas/nlp/
dist_backend: gloo
gradient_accumulation_steps: 1
warmup_proportion: 0.1
learning_rate: 0.00006
weight_decay: 0.01
train_epochs: 2
max_seq_length: 384
doc_stride: 128
train_batch_size: 32
eval_batch_size: 8
eval_step: 500
n_best_size: 20
max_answer_length: 30
max_query_length: 64
criterion: "CrossEntropyQALoss"
optimizer: "BertAdam"
lr_scheduler: "warmup_linear"
version_2_with_negative: 0
null_score_diff_threshold: 0.0
num_labels: 2
num_workers: 1
pin_mem: True
verbose_logging: False
no_cuda: True
do_lower_case: True
profile_flops: True
metric_threshold: None
eval_metric: "qa_f1"
# conf for ModelAdaptor
num_classes: 768
is_tl: False
is_saving_logits: False
logits_dir: /home/vmagent/app/dataset/SQuAD/logits_dir/
teacher_model: /home/vmagent/app/dataset/bert-base-squad/
teacher_model_structure: /home/vmagent/app/e2eaiok/e2eAIOK/DeNas/teacher_model_structure.txt