experiment:
  project: "distiller"
  tag: "cifar100_kd_res50PretrainI21k_save89.29"
  strategy: "OnlyDistillationStrategy"

output_dir: "/home/vmagent/app/data/model"
train_epochs: 80

### dataset
data_set: "cifar100"
data_path:  "/home/vmagent/app/data/dataset/cifar"
num_workers: 4
input_size: 112

### model
model_type: "resnet18_cifar"

# loss
loss_weight:
    backbone: 0.1
    distiller: 0.9

distiller:
    type: "kd"
    teacher: 
        type: "resnet50"
        pretrain: "/home/vmagent/app/data/model/finetuner/cifar100_res50PretrainI21k/cifar100_res50_pretrain_imagenet21k_89.29.pth"
    save_logits: True
    logits_path: "/home/vmagent/app/data/model/distiller/cifar100_kd_res50PretrainI21k/logits_89.29"
    logits_topk: 0

## optimizer
optimizer: "SGD"
learning_rate: 0.08
weight_decay: 0.0001
momentum: 0.9

### scheduler
lr_scheduler: "ReduceLROnPlateau"
lr_scheduler_config:
    decay_rate: 0.2
    decay_patience: 3

