{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "start = time.time()\n",
    "very_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client, wait, LocalCluster\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7feb716b0c10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(n_workers=8, \n",
    "                       threads_per_worker=10,\n",
    "                       memory_limit='45GB',ip='10.1.0.xxx)\n",
    "dask.config.set(shuffle='disk')\n",
    "dask.config.set({'temporary_directory': '/path/to/dask_tmp'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "CPU times: user 68.3 ms, sys: 12.7 ms, total: 81 ms\n",
      "Wall time: 72.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = '/path/to/all_data_10_raw_with_text_fe/'\n",
    "files = os.listdir(path)\n",
    "train = dd.read_parquet(f'{path}/*.parquet')#,dtypes=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'text_tokens', 'hashtags', 'present_media', 'present_links',\n",
       "       'present_domains', 'tweet_type', 'language', 'tweet_timestamp',\n",
       "       'engaged_with_user_id', 'engaged_with_user_follower_count',\n",
       "       'engaged_with_user_following_count', 'engaged_with_user_is_verified',\n",
       "       'engaged_with_user_account_creation', 'enaging_user_id',\n",
       "       'enaging_user_follower_count', 'enaging_user_following_count',\n",
       "       'enaging_user_is_verified', 'enaging_user_account_creation',\n",
       "       'engagee_follows_engager', 'reply_timestamp', 'retweet_timestamp',\n",
       "       'retweet_with_comment_timestamp', 'like_timestamp', 'len_hashtags',\n",
       "       'len_domains', 'len_links', 'engage_time', 'dt_dow', 'dt_hour',\n",
       "       'dt_minute', 'dt_second', 'tweet', 'tweet_nortsign', 'count_words',\n",
       "       'count_char', 'tw_uhash', 'tw_hash', 'count_ats', 'hash0', 'hash1',\n",
       "       'tw_freq_hash', 'tw_first_word', 'tw_second_word', 'tw_last_word',\n",
       "       'tw_llast_word', 'tw_len'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 ms, sys: 2.63 ms, total: 14 ms\n",
      "Wall time: 12.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# DROP UNUSED COLUMNS\n",
    "cols_drop = ['text_tokens']\n",
    "train = train.drop(cols_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'> (Delayed('int-3337961c-2a03-4468-a256-e7dd4edd7ce3'), 46)\n",
      "CPU times: user 27.4 ms, sys: 2.67 ms, total: 30.1 ms\n",
      "Wall time: 28.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, = dask.persist(train)\n",
    "print(type(train), train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'> (Delayed('int-1a16b6af-8434-49df-b5ae-5c70d049125e'), 46)\n",
      "CPU times: user 18.6 ms, sys: 9.17 ms, total: 27.7 ms\n",
      "Wall time: 18.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = train.repartition(npartitions=8)\n",
    "train, = dask.persist(train)\n",
    "print(type(train), train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                               int32\n",
       "hashtags                               int32\n",
       "present_media                          int32\n",
       "present_links                          int32\n",
       "present_domains                        int32\n",
       "tweet_type                             int32\n",
       "language                               int32\n",
       "tweet_timestamp                        int32\n",
       "engaged_with_user_id                   int32\n",
       "engaged_with_user_follower_count       int32\n",
       "engaged_with_user_following_count      int32\n",
       "engaged_with_user_is_verified           bool\n",
       "engaged_with_user_account_creation     int32\n",
       "enaging_user_id                        int32\n",
       "enaging_user_follower_count            int32\n",
       "enaging_user_following_count           int32\n",
       "enaging_user_is_verified                bool\n",
       "enaging_user_account_creation          int32\n",
       "engagee_follows_engager                 bool\n",
       "reply_timestamp                        int32\n",
       "retweet_timestamp                      int32\n",
       "retweet_with_comment_timestamp         int32\n",
       "like_timestamp                         int32\n",
       "len_hashtags                           int32\n",
       "len_domains                            int32\n",
       "len_links                              int32\n",
       "engage_time                            int32\n",
       "dt_dow                                 int32\n",
       "dt_hour                                int32\n",
       "dt_minute                              int32\n",
       "dt_second                              int32\n",
       "tweet                                 object\n",
       "tweet_nortsign                        object\n",
       "count_words                           object\n",
       "count_char                            object\n",
       "tw_uhash                               int32\n",
       "tw_hash                                int32\n",
       "count_ats                             object\n",
       "hash0                                  int32\n",
       "hash1                                  int32\n",
       "tw_freq_hash                           int32\n",
       "tw_first_word                          int32\n",
       "tw_second_word                         int32\n",
       "tw_last_word                           int32\n",
       "tw_llast_word                          int32\n",
       "tw_len                                 int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,p in enumerate(train.partitions):\n",
    "#    print(i,len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['reply_timestamp', 'retweet_timestamp', 'retweet_with_comment_timestamp', 'like_timestamp']\n",
    "for col in train.columns:\n",
    "    if col in label_names:\n",
    "        train[col] = train[col].astype('float32')\n",
    "    elif train[col].dtype=='int64':\n",
    "        train[col] = train[col].astype('int32')\n",
    "    elif train[col].dtype=='int16':\n",
    "        train[col] = train[col].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 ms, sys: 1.96 ms, total: 13.6 ms\n",
      "Wall time: 10.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Delayed('int-dbea8e3d-ad2f-456c-8938-3482c35515f6'), 46)\n",
      "CPU times: user 6.46 ms, sys: 2.08 ms, total: 8.54 ms\n",
      "Wall time: 7.14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, = dask.persist(train)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 ms, sys: 4.65 ms, total: 25.1 ms\n",
      "Wall time: 18.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ELAPSED TIME\n",
    "for col in ['engage_time','tweet_timestamp']:\n",
    "    train[col] = train[col].astype('int64')/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'> (Delayed('int-bdfe6cca-d846-45a3-b54a-624c1491b16e'), 46)\n",
      "CPU times: user 4.9 ms, sys: 2.38 ms, total: 7.28 ms\n",
      "Wall time: 5.52 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, = dask.persist(train)\n",
    "print(type(train), train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nan(ds):\n",
    "    mask = ds == 0\n",
    "    ds.loc[mask] = np.nan\n",
    "    return ds\n",
    "train['engage_time'] = train['engage_time'].map_partitions(set_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['elapsed_time'] = train['engage_time'] - train['tweet_timestamp']\n",
    "train['elapsed_time'] = train.elapsed_time.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 ms, sys: 3.92 ms, total: 25.4 ms\n",
      "Wall time: 19.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TRAIN FIRST 5 DAYS. VALIDATE LAST 2 DAYS\n",
    "VALID_DOW = [1, 2]# order is [3, 4, 5, 6, 0, 1, 2]\n",
    "valid = train[train['dt_dow'].isin(VALID_DOW)].reset_index(drop=True)\n",
    "train = train[~train['dt_dow'].isin(VALID_DOW)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'> (Delayed('int-8fe6a423-9353-44a7-9626-0844b8ee4852'), 47) (Delayed('int-39dc6880-d328-4882-aa91-8495cfb909eb'), 47)\n",
      "CPU times: user 34.6 ms, sys: 3.33 ms, total: 37.9 ms\n",
      "Wall time: 34.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train,valid = dask.persist(train,valid)\n",
    "print(type(train), train.shape, valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.99 s, sys: 873 ms, total: 7.87 s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = train.set_index('tweet_timestamp')\n",
    "valid = valid.set_index('tweet_timestamp')\n",
    "train,valid = dask.persist(train,valid)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.6 ms, sys: 4.79 ms, total: 39.4 ms\n",
      "Wall time: 31.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = train.reset_index()\n",
    "valid = valid.reset_index()\n",
    "train,valid = dask.persist(train,valid)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,p in enumerate(train.partitions):\n",
    "#    print(i,len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,p in enumerate(valid.partitions):\n",
    "#    print(i,len(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTE_one_shot:\n",
    "    \n",
    "    def __init__(self, folds, smooth, seed=42):\n",
    "        self.folds = folds\n",
    "        self.seed = seed\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def fit_transform(self, train, x_col, y_col, y_mean=None, out_col = None, out_dtype=None):\n",
    "        \n",
    "        self.y_col = y_col\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        if 'fold' not in train.columns:\n",
    "            fsize = len(train)//self.folds\n",
    "            train['fold'] = 1\n",
    "            train['fold'] = train['fold'].cumsum()\n",
    "            train['fold'] = train['fold']//fsize\n",
    "            train['fold'] = train['fold']%self.folds\n",
    "        \n",
    "        if out_col is None:\n",
    "            tag = x_col if isinstance(x_col,str) else '_'.join(x_col)\n",
    "            out_col = f'TE_{tag}_{self.y_col}'\n",
    "        \n",
    "        if y_mean is None:\n",
    "            y_mean = train[y_col].mean()#.compute().astype('float32')\n",
    "        self.mean = y_mean\n",
    "        \n",
    "        cols = ['fold',x_col] if isinstance(x_col,str) else ['fold']+x_col\n",
    "        \n",
    "        agg_each_fold = train.groupby(cols).agg({y_col:['count','sum']}).reset_index()\n",
    "        agg_each_fold.columns = cols + ['count_y','sum_y']\n",
    "        \n",
    "        agg_all = agg_each_fold.groupby(x_col).agg({'count_y':'sum','sum_y':'sum'}).reset_index()\n",
    "        cols = [x_col] if isinstance(x_col,str) else x_col\n",
    "        agg_all.columns = cols + ['count_y_all','sum_y_all']\n",
    "        \n",
    "        agg_each_fold = agg_each_fold.merge(agg_all,on=x_col,how='left')\n",
    "        agg_each_fold['count_y_all'] = agg_each_fold['count_y_all'] - agg_each_fold['count_y']\n",
    "        agg_each_fold['sum_y_all'] = agg_each_fold['sum_y_all'] - agg_each_fold['sum_y']\n",
    "        agg_each_fold[out_col] = (agg_each_fold['sum_y_all']+self.smooth*self.mean)/(agg_each_fold['count_y_all']+self.smooth)\n",
    "        agg_each_fold = agg_each_fold.drop(['count_y_all','count_y','sum_y_all','sum_y'],axis=1)\n",
    "        \n",
    "        agg_all[out_col] = (agg_all['sum_y_all']+self.smooth*self.mean)/(agg_all['count_y_all']+self.smooth)\n",
    "        agg_all = agg_all.drop(['count_y_all','sum_y_all'],axis=1)\n",
    "        self.agg_all = agg_all\n",
    "        \n",
    "        train.columns\n",
    "        cols = ['fold',x_col] if isinstance(x_col,str) else ['fold']+x_col\n",
    "        train = train.merge(agg_each_fold,on=cols,how='left')\n",
    "        del agg_each_fold\n",
    "        #self.agg_each_fold = agg_each_fold\n",
    "        #train[out_col] = train.map_partitions(lambda cudf_df: cudf_df[out_col].nans_to_nulls())\n",
    "        train[out_col] = train[out_col].fillna(self.mean)\n",
    "        \n",
    "        if out_dtype is not None:\n",
    "            train[out_col] = train[out_col].astype(out_dtype)\n",
    "        return train\n",
    "    \n",
    "    def transform(self, test, x_col, out_col = None, out_dtype=None):\n",
    "        if out_col is None:\n",
    "            tag = x_col if isinstance(x_col,str) else '_'.join(x_col)\n",
    "            out_col = f'TE_{tag}_{self.y_col}'\n",
    "        test = test.merge(self.agg_all,on=x_col,how='left')\n",
    "        test[out_col] = test[out_col].fillna(self.mean)\n",
    "        if out_dtype is not None:\n",
    "            test[out_col] = test[out_col].astype(out_dtype)\n",
    "        return test\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_timestamp', 'tweet_id', 'hashtags', 'present_media',\n",
       "       'present_links', 'present_domains', 'tweet_type', 'language',\n",
       "       'engaged_with_user_id', 'engaged_with_user_follower_count',\n",
       "       'engaged_with_user_following_count', 'engaged_with_user_is_verified',\n",
       "       'engaged_with_user_account_creation', 'enaging_user_id',\n",
       "       'enaging_user_follower_count', 'enaging_user_following_count',\n",
       "       'enaging_user_is_verified', 'enaging_user_account_creation',\n",
       "       'engagee_follows_engager', 'reply_timestamp', 'retweet_timestamp',\n",
       "       'retweet_with_comment_timestamp', 'like_timestamp', 'len_hashtags',\n",
       "       'len_domains', 'len_links', 'engage_time', 'dt_dow', 'dt_hour',\n",
       "       'dt_minute', 'dt_second', 'tweet', 'tweet_nortsign', 'count_words',\n",
       "       'count_char', 'tw_uhash', 'tw_hash', 'count_ats', 'hash0', 'hash1',\n",
       "       'tw_freq_hash', 'tw_first_word', 'tw_second_word', 'tw_last_word',\n",
       "       'tw_llast_word', 'tw_len', 'elapsed_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TE_media_reply 17.8 seconds<br>\n",
    "TE_tweet_type_reply 27.1 seconds<br>\n",
    "TE_language_reply 52.5 seconds<br>\n",
    "TE_a_user_id_reply 180.0 seconds<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TE_present_media_reply_timestamp 98.6 seconds\n",
      "TE_tweet_type_reply_timestamp 109.2 seconds\n",
      "TE_language_reply_timestamp 120.6 seconds\n",
      "TE_engaged_with_user_id_reply_timestamp 148.4 seconds\n",
      "TE_enaging_user_id_reply_timestamp 185.5 seconds\n",
      "TE_present_media_retweet_timestamp 12.2 seconds\n",
      "TE_tweet_type_retweet_timestamp 23.6 seconds\n",
      "TE_language_retweet_timestamp 35.0 seconds\n",
      "TE_engaged_with_user_id_retweet_timestamp 62.7 seconds\n",
      "TE_enaging_user_id_retweet_timestamp 100.3 seconds\n",
      "TE_present_media_retweet_with_comment_timestamp 12.3 seconds\n",
      "TE_tweet_type_retweet_with_comment_timestamp 23.6 seconds\n",
      "TE_language_retweet_with_comment_timestamp 34.6 seconds\n",
      "TE_engaged_with_user_id_retweet_with_comment_timestamp 63.1 seconds\n",
      "TE_enaging_user_id_retweet_with_comment_timestamp 101.5 seconds\n",
      "TE_present_media_like_timestamp 12.8 seconds\n",
      "TE_tweet_type_like_timestamp 24.5 seconds\n",
      "TE_language_like_timestamp 35.7 seconds\n",
      "TE_engaged_with_user_id_like_timestamp 65.1 seconds\n",
      "TE_enaging_user_id_like_timestamp 102.1 seconds\n",
      "CPU times: user 49.8 s, sys: 5.84 s, total: 55.6 s\n",
      "Wall time: 8min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cuDF TE ENCODING IS SUPER FAST!!\n",
    "idx = 0; cols = []\n",
    "start = time.time()\n",
    "for t in ['reply_timestamp', 'retweet_timestamp', 'retweet_with_comment_timestamp', 'like_timestamp']:\n",
    "    start = time.time()\n",
    "    for c in ['present_media', 'tweet_type', 'language', 'engaged_with_user_id', 'enaging_user_id']:\n",
    "        out_col = f'TE_{c}_{t}'\n",
    "        encoder = MTE_one_shot(folds=5,smooth=20)\n",
    "        train = encoder.fit_transform(train, c, t, out_col=out_col, out_dtype='float32')\n",
    "        valid = encoder.transform(valid, c, out_col=out_col, out_dtype='float32')\n",
    "        cols.append(out_col)\n",
    "        train,valid = dask.persist(train,valid)\n",
    "        del encoder\n",
    "        #train.head()\n",
    "        wait(train)\n",
    "        wait(valid)\n",
    "        print(out_col,\"%.1f seconds\"%(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_timestamp', 'tweet_id', 'hashtags', 'present_media',\n",
       "       'present_links', 'present_domains', 'tweet_type', 'language',\n",
       "       'engaged_with_user_id', 'engaged_with_user_follower_count',\n",
       "       'engaged_with_user_following_count', 'engaged_with_user_is_verified',\n",
       "       'engaged_with_user_account_creation', 'enaging_user_id',\n",
       "       'enaging_user_follower_count', 'enaging_user_following_count',\n",
       "       'enaging_user_is_verified', 'enaging_user_account_creation',\n",
       "       'engagee_follows_engager', 'reply_timestamp', 'retweet_timestamp',\n",
       "       'retweet_with_comment_timestamp', 'like_timestamp', 'len_hashtags',\n",
       "       'len_domains', 'len_links', 'engage_time', 'dt_dow', 'dt_hour',\n",
       "       'dt_minute', 'dt_second', 'tweet', 'tweet_nortsign', 'count_words',\n",
       "       'count_char', 'tw_uhash', 'tw_hash', 'count_ats', 'hash0', 'hash1',\n",
       "       'tw_freq_hash', 'tw_first_word', 'tw_second_word', 'tw_last_word',\n",
       "       'tw_llast_word', 'tw_len', 'elapsed_time', 'fold',\n",
       "       'TE_present_media_reply_timestamp', 'TE_tweet_type_reply_timestamp',\n",
       "       'TE_language_reply_timestamp',\n",
       "       'TE_engaged_with_user_id_reply_timestamp',\n",
       "       'TE_enaging_user_id_reply_timestamp',\n",
       "       'TE_present_media_retweet_timestamp', 'TE_tweet_type_retweet_timestamp',\n",
       "       'TE_language_retweet_timestamp',\n",
       "       'TE_engaged_with_user_id_retweet_timestamp',\n",
       "       'TE_enaging_user_id_retweet_timestamp',\n",
       "       'TE_present_media_retweet_with_comment_timestamp',\n",
       "       'TE_tweet_type_retweet_with_comment_timestamp',\n",
       "       'TE_language_retweet_with_comment_timestamp',\n",
       "       'TE_engaged_with_user_id_retweet_with_comment_timestamp',\n",
       "       'TE_enaging_user_id_retweet_with_comment_timestamp',\n",
       "       'TE_present_media_like_timestamp', 'TE_tweet_type_like_timestamp',\n",
       "       'TE_language_like_timestamp', 'TE_engaged_with_user_id_like_timestamp',\n",
       "       'TE_enaging_user_id_like_timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Column Target Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TE_present_domains_language_engagee_follows_engager_tweet_type_present_media_engaged_with_user_is_verified_reply_timestamp\n",
      "TE_present_domains_language_engagee_follows_engager_tweet_type_present_media_engaged_with_user_is_verified_reply_timestamp 15.1 seconds\n",
      "TE_engaged_with_user_id_tweet_type_language_reply_timestamp\n",
      "TE_engaged_with_user_id_tweet_type_language_reply_timestamp 39.7 seconds\n",
      "TE_tw_first_word_tweet_type_language_reply_timestamp\n",
      "TE_tw_first_word_tweet_type_language_reply_timestamp 34.3 seconds\n",
      "TE_tw_last_word_tweet_type_language_reply_timestamp\n",
      "TE_tw_last_word_tweet_type_language_reply_timestamp 14.5 seconds\n",
      "TE_hash0_tweet_type_language_reply_timestamp\n",
      "TE_hash0_tweet_type_language_reply_timestamp 20.0 seconds\n",
      "TE_hash1_tweet_type_language_reply_timestamp\n",
      "TE_hash1_tweet_type_language_reply_timestamp 14.3 seconds\n",
      "TE_tw_uhash_tweet_type_language_reply_timestamp\n",
      "TE_tw_uhash_tweet_type_language_reply_timestamp 20.5 seconds\n",
      "TE_tw_hash_reply_timestamp\n",
      "TE_tw_hash_reply_timestamp 49.3 seconds\n",
      "TE_tw_freq_hash_reply_timestamp\n",
      "TE_tw_freq_hash_reply_timestamp 49.6 seconds\n",
      "TE_present_media_tweet_type_language_engaged_with_user_is_verified_enaging_user_is_verified_engagee_follows_engager_reply_timestamp\n",
      "TE_present_media_tweet_type_language_engaged_with_user_is_verified_enaging_user_is_verified_engagee_follows_engager_reply_timestamp 14.4 seconds\n",
      "TE_present_domains_present_media_tweet_type_language_reply_timestamp\n",
      "TE_present_domains_present_media_tweet_type_language_reply_timestamp 14.7 seconds\n",
      "TE_present_links_present_media_tweet_type_language_reply_timestamp\n",
      "TE_present_links_present_media_tweet_type_language_reply_timestamp 17.5 seconds\n",
      "TE_hashtags_present_media_tweet_type_language_reply_timestamp\n",
      "TE_hashtags_present_media_tweet_type_language_reply_timestamp 16.4 seconds\n",
      "TE_present_domains_language_engagee_follows_engager_tweet_type_present_media_engaged_with_user_is_verified_retweet_timestamp\n",
      "TE_present_domains_language_engagee_follows_engager_tweet_type_present_media_engaged_with_user_is_verified_retweet_timestamp 15.4 seconds\n",
      "TE_engaged_with_user_id_tweet_type_language_retweet_timestamp\n",
      "TE_engaged_with_user_id_tweet_type_language_retweet_timestamp 41.7 seconds\n",
      "TE_tw_first_word_tweet_type_language_retweet_timestamp\n",
      "TE_tw_first_word_tweet_type_language_retweet_timestamp 37.1 seconds\n",
      "TE_tw_last_word_tweet_type_language_retweet_timestamp\n",
      "TE_tw_last_word_tweet_type_language_retweet_timestamp 15.8 seconds\n",
      "TE_hash0_tweet_type_language_retweet_timestamp\n",
      "TE_hash0_tweet_type_language_retweet_timestamp 21.2 seconds\n",
      "TE_hash1_tweet_type_language_retweet_timestamp\n",
      "TE_hash1_tweet_type_language_retweet_timestamp 13.7 seconds\n",
      "TE_tw_uhash_tweet_type_language_retweet_timestamp\n",
      "TE_tw_uhash_tweet_type_language_retweet_timestamp 20.9 seconds\n",
      "TE_tw_hash_retweet_timestamp\n",
      "TE_tw_hash_retweet_timestamp 49.4 seconds\n",
      "TE_tw_freq_hash_retweet_timestamp\n",
      "TE_tw_freq_hash_retweet_timestamp 50.5 seconds\n",
      "TE_present_media_tweet_type_language_engaged_with_user_is_verified_enaging_user_is_verified_engagee_follows_engager_retweet_timestamp\n",
      "TE_present_media_tweet_type_language_engaged_with_user_is_verified_enaging_user_is_verified_engagee_follows_engager_retweet_timestamp 15.7 seconds\n",
      "TE_present_domains_present_media_tweet_type_language_retweet_timestamp\n",
      "TE_present_domains_present_media_tweet_type_language_retweet_timestamp 15.7 seconds\n",
      "TE_present_links_present_media_tweet_type_language_retweet_timestamp\n",
      "TE_present_links_present_media_tweet_type_language_retweet_timestamp 19.3 seconds\n",
      "TE_hashtags_present_media_tweet_type_language_retweet_timestamp\n",
      "TE_hashtags_present_media_tweet_type_language_retweet_timestamp 17.6 seconds\n",
      "TE_present_domains_language_engagee_follows_engager_tweet_type_present_media_engaged_with_user_is_verified_retweet_with_comment_timestamp\n",
      "TE_present_domains_language_engagee_follows_engager_tweet_type_present_media_engaged_with_user_is_verified_retweet_with_comment_timestamp 16.8 seconds\n",
      "TE_engaged_with_user_id_tweet_type_language_retweet_with_comment_timestamp\n",
      "TE_engaged_with_user_id_tweet_type_language_retweet_with_comment_timestamp 42.3 seconds\n",
      "TE_tw_first_word_tweet_type_language_retweet_with_comment_timestamp\n",
      "TE_tw_first_word_tweet_type_language_retweet_with_comment_timestamp 36.7 seconds\n",
      "TE_tw_last_word_tweet_type_language_retweet_with_comment_timestamp\n",
      "TE_tw_last_word_tweet_type_language_retweet_with_comment_timestamp 16.9 seconds\n",
      "TE_hash0_tweet_type_language_retweet_with_comment_timestamp\n",
      "TE_hash0_tweet_type_language_retweet_with_comment_timestamp 21.6 seconds\n",
      "TE_hash1_tweet_type_language_retweet_with_comment_timestamp\n",
      "TE_hash1_tweet_type_language_retweet_with_comment_timestamp 15.4 seconds\n",
      "TE_tw_uhash_tweet_type_language_retweet_with_comment_timestamp\n",
      "TE_tw_uhash_tweet_type_language_retweet_with_comment_timestamp 21.6 seconds\n",
      "TE_tw_hash_retweet_with_comment_timestamp\n",
      "TE_tw_hash_retweet_with_comment_timestamp 48.5 seconds\n",
      "TE_tw_freq_hash_retweet_with_comment_timestamp\n",
      "TE_tw_freq_hash_retweet_with_comment_timestamp 50.8 seconds\n",
      "TE_present_media_tweet_type_language_engaged_with_user_is_verified_enaging_user_is_verified_engagee_follows_engager_retweet_with_comment_timestamp\n",
      "TE_present_media_tweet_type_language_engaged_with_user_is_verified_enaging_user_is_verified_engagee_follows_engager_retweet_with_comment_timestamp 16.0 seconds\n",
      "TE_present_domains_present_media_tweet_type_language_retweet_with_comment_timestamp\n",
      "TE_present_domains_present_media_tweet_type_language_retweet_with_comment_timestamp 16.2 seconds\n",
      "TE_present_links_present_media_tweet_type_language_retweet_with_comment_timestamp\n",
      "TE_present_links_present_media_tweet_type_language_retweet_with_comment_timestamp 18.8 seconds\n",
      "TE_hashtags_present_media_tweet_type_language_retweet_with_comment_timestamp\n",
      "TE_hashtags_present_media_tweet_type_language_retweet_with_comment_timestamp 17.8 seconds\n",
      "TE_present_domains_language_engagee_follows_engager_tweet_type_present_media_engaged_with_user_is_verified_like_timestamp\n",
      "TE_present_domains_language_engagee_follows_engager_tweet_type_present_media_engaged_with_user_is_verified_like_timestamp 17.4 seconds\n",
      "TE_engaged_with_user_id_tweet_type_language_like_timestamp\n",
      "TE_engaged_with_user_id_tweet_type_language_like_timestamp 43.1 seconds\n",
      "TE_tw_first_word_tweet_type_language_like_timestamp\n",
      "TE_tw_first_word_tweet_type_language_like_timestamp 37.8 seconds\n",
      "TE_tw_last_word_tweet_type_language_like_timestamp\n",
      "TE_tw_last_word_tweet_type_language_like_timestamp 16.6 seconds\n",
      "TE_hash0_tweet_type_language_like_timestamp\n",
      "TE_hash0_tweet_type_language_like_timestamp 22.0 seconds\n",
      "TE_hash1_tweet_type_language_like_timestamp\n",
      "TE_hash1_tweet_type_language_like_timestamp 16.1 seconds\n",
      "TE_tw_uhash_tweet_type_language_like_timestamp\n",
      "TE_tw_uhash_tweet_type_language_like_timestamp 22.3 seconds\n",
      "TE_tw_hash_like_timestamp\n",
      "TE_tw_hash_like_timestamp 51.2 seconds\n",
      "TE_tw_freq_hash_like_timestamp\n",
      "TE_tw_freq_hash_like_timestamp 50.6 seconds\n",
      "TE_present_media_tweet_type_language_engaged_with_user_is_verified_enaging_user_is_verified_engagee_follows_engager_like_timestamp\n",
      "TE_present_media_tweet_type_language_engaged_with_user_is_verified_enaging_user_is_verified_engagee_follows_engager_like_timestamp 16.3 seconds\n",
      "TE_present_domains_present_media_tweet_type_language_like_timestamp\n",
      "TE_present_domains_present_media_tweet_type_language_like_timestamp 16.6 seconds\n",
      "TE_present_links_present_media_tweet_type_language_like_timestamp\n",
      "TE_present_links_present_media_tweet_type_language_like_timestamp 19.5 seconds\n",
      "TE_hashtags_present_media_tweet_type_language_like_timestamp\n",
      "TE_hashtags_present_media_tweet_type_language_like_timestamp 18.6 seconds\n",
      "CPU times: user 2min 16s, sys: 15.7 s, total: 2min 32s\n",
      "Wall time: 22min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cuDF TE ENCODING IS SUPER FAST!!\n",
    "idx = 0; cols=[]\n",
    "\n",
    "for t in ['reply_timestamp', 'retweet_timestamp', 'retweet_with_comment_timestamp', 'like_timestamp']:\n",
    "    for c in [\n",
    "        ['present_domains','language','engagee_follows_engager','tweet_type','present_media','engaged_with_user_is_verified'],\n",
    "        ['engaged_with_user_id','tweet_type','language'],\n",
    "        ['tw_first_word','tweet_type','language'],\n",
    "        ['tw_last_word','tweet_type','language'],\n",
    "        ['hash0','tweet_type','language'],\n",
    "        ['hash1','tweet_type','language'],\n",
    "        ['tw_uhash','tweet_type','language'],\n",
    "        ['tw_hash'],\n",
    "        ['tw_freq_hash'],\n",
    "        ['present_media','tweet_type','language','engaged_with_user_is_verified','enaging_user_is_verified','engagee_follows_engager'],\n",
    "        ['present_domains','present_media','tweet_type','language'],\n",
    "        ['present_links','present_media','tweet_type','language'],\n",
    "        ['hashtags','present_media','tweet_type','language'],\n",
    "        ]:\n",
    "        start = time.time()\n",
    "        out_col = 'TE_'+'_'.join(c)+'_'+t\n",
    "        print(out_col)\n",
    "        encoder = MTE_one_shot(folds=5,smooth=20)\n",
    "        train = encoder.fit_transform(train, c, t, out_col=out_col, out_dtype='float32')\n",
    "        valid = encoder.transform(valid, c, out_col=out_col, out_dtype='float32')\n",
    "        cols.append(out_col)\n",
    "        train,valid = dask.persist(train,valid)\n",
    "        del encoder\n",
    "        wait(train)\n",
    "        wait(valid)\n",
    "        print(out_col,\"%.1f seconds\"%(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.6 ms, sys: 3.54 ms, total: 24.2 ms\n",
      "Wall time: 17.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DoneAndNotDoneFutures(done={<Future: finished, type: pandas.DataFrame, key: ('assign-b1ec71164db1528c812475c2c3c8d4e9', 5)>, <Future: finished, type: pandas.DataFrame, key: ('assign-b1ec71164db1528c812475c2c3c8d4e9', 2)>, <Future: finished, type: pandas.DataFrame, key: ('assign-b1ec71164db1528c812475c2c3c8d4e9', 6)>, <Future: finished, type: pandas.DataFrame, key: ('assign-b1ec71164db1528c812475c2c3c8d4e9', 7)>, <Future: finished, type: pandas.DataFrame, key: ('assign-b1ec71164db1528c812475c2c3c8d4e9', 3)>, <Future: finished, type: pandas.DataFrame, key: ('assign-b1ec71164db1528c812475c2c3c8d4e9', 1)>, <Future: finished, type: pandas.DataFrame, key: ('assign-b1ec71164db1528c812475c2c3c8d4e9', 0)>, <Future: finished, type: pandas.DataFrame, key: ('assign-b1ec71164db1528c812475c2c3c8d4e9', 4)>}, not_done=set())"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train,valid = dask.persist(train,valid)\n",
    "wait(train)\n",
    "wait(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed Time Target Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TE_present_media_elapsed_time 0.2 seconds\n",
      "TE_tweet_type_elapsed_time 0.4 seconds\n",
      "TE_language_elapsed_time 0.5 seconds\n",
      "CPU times: user 573 ms, sys: 58 ms, total: 631 ms\n",
      "Wall time: 513 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cuDF TE ENCODING IS SUPER FAST!!\n",
    "start = time.time()\n",
    "idx = 0; cols = []\n",
    "for c in ['present_media', 'tweet_type', 'language']:#, 'a_user_id', 'b_user_id']:\n",
    "    for t in ['elapsed_time']:\n",
    "        out_col = f'TE_{c}_{t}'\n",
    "        encoder = MTE_one_shot(folds=5,smooth=20)\n",
    "        train = encoder.fit_transform(train, c, t, out_col=out_col)\n",
    "        out_dtype='float32' #if 'user_id' in c else None\n",
    "        valid = encoder.transform(valid, c, out_col=out_col, out_dtype=out_dtype)\n",
    "        cols.append(out_col)\n",
    "        print(out_col,\"%.1f seconds\"%(time.time()-start))\n",
    "        #del encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.31 s, sys: 447 ms, total: 4.76 s\n",
      "Wall time: 40.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DoneAndNotDoneFutures(done={<Future: finished, type: pandas.DataFrame, key: ('assign-ea2d4510f3129f596f86efc66236f544', 4)>, <Future: finished, type: pandas.DataFrame, key: ('assign-ea2d4510f3129f596f86efc66236f544', 1)>, <Future: finished, type: pandas.DataFrame, key: ('assign-ea2d4510f3129f596f86efc66236f544', 5)>, <Future: finished, type: pandas.DataFrame, key: ('assign-ea2d4510f3129f596f86efc66236f544', 2)>, <Future: finished, type: pandas.DataFrame, key: ('assign-ea2d4510f3129f596f86efc66236f544', 0)>, <Future: finished, type: pandas.DataFrame, key: ('assign-ea2d4510f3129f596f86efc66236f544', 7)>, <Future: finished, type: pandas.DataFrame, key: ('assign-ea2d4510f3129f596f86efc66236f544', 3)>, <Future: finished, type: pandas.DataFrame, key: ('assign-ea2d4510f3129f596f86efc66236f544', 6)>}, not_done=set())"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train,valid = dask.persist(train,valid)\n",
    "wait(train)\n",
    "wait(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyEncoder:\n",
    "    \n",
    "    def __init__(self, seed=42):\n",
    "        self.seed = seed\n",
    "        \n",
    "    def fit_transform(self, train, x_col, c_col=None, out_col = None):\n",
    "        np.random.seed(self.seed)\n",
    "        if c_col is None or c_col not in train.columns:\n",
    "            c_col = 'dummy'\n",
    "            train[c_col] = 1\n",
    "            drop = True\n",
    "        else:\n",
    "            drop = False\n",
    "            \n",
    "        if out_col is None:\n",
    "            tag = x_col if isinstance(x_col,str) else '_'.join(x_col)\n",
    "            out_col = f'CE_{tag}_norm'\n",
    "            \n",
    "        cols = [x_col] if isinstance(x_col,str) else x_col\n",
    "        agg_all = train.groupby(cols).agg({c_col:'count'}).reset_index()\n",
    "        if drop:\n",
    "            train = train.drop(c_col,axis=1)\n",
    "        agg_all.columns = cols + [out_col]\n",
    "        agg_all[out_col] = agg_all[out_col].astype('int32')\n",
    "        agg_all[out_col] = agg_all[out_col]*1.0/len(train)\n",
    "        agg_all[out_col] = agg_all[out_col].astype('float32')\n",
    "    \n",
    "        train = train.merge(agg_all,on=cols,how='left')\n",
    "        del agg_all\n",
    "        #print(train.columns)\n",
    "        #train[out_col] = train.map_partitions(lambda cudf_df: cudf_df[out_col].nans_to_nulls())\n",
    "        return train\n",
    "    \n",
    "    def transform(self, test, x_col, c_col=None, out_col = None):\n",
    "        return self.fit_transform(test, x_col, c_col, out_col)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountEncoder:\n",
    "    \n",
    "    def __init__(self, seed=42):\n",
    "        self.seed = seed\n",
    "        \n",
    "    def fit_transform(self, train, test, x_col, out_col = None):\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        common_cols = [i for i in train.columns if i in test.columns and i!=x_col]\n",
    "\n",
    "        if len(common_cols):\n",
    "            c_col = common_cols[0]\n",
    "            drop = False\n",
    "        else:\n",
    "            c_col = 'dummy'\n",
    "            train[c_col] = 1\n",
    "            test[c_col]=1\n",
    "            drop = True\n",
    "            \n",
    "        if out_col is None:\n",
    "            tag = x_col if isinstance(x_col,str) else '_'.join(x_col)\n",
    "            out_col = f'CE_{tag}_norm'\n",
    "            \n",
    "        cols = [x_col] if isinstance(x_col,str) else x_col\n",
    "        agg_all = train.groupby(cols).agg({c_col:'count'}).reset_index()\n",
    "        agg_all.columns = cols + [out_col]\n",
    "        \n",
    "        agg_test = test.groupby(cols).agg({c_col:'count'}).reset_index()\n",
    "        agg_test.columns = cols + [out_col+'_test']\n",
    "        agg_all = agg_all.merge(agg_test,on=cols,how='left')\n",
    "        agg_all[out_col+'_test'] = agg_all[out_col+'_test'].fillna(0)\n",
    "        agg_all[out_col] = agg_all[out_col] + agg_all[out_col+'_test']\n",
    "        agg_all = agg_all.drop(out_col+'_test', axis=1)\n",
    "        del agg_test\n",
    "            \n",
    "        if drop:\n",
    "            train = train.drop(c_col,axis=1)\n",
    "            test = test.drop(c_col,axis=1)\n",
    "        train = train.merge(agg_all,on=cols,how='left')\n",
    "        test = test.merge(agg_all,on=cols,how='left')\n",
    "        del agg_all\n",
    "        return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE_present_media 11.1 seconds\n",
      "CE_tweet_type 23.5 seconds\n",
      "CE_language 35.7 seconds\n",
      "CE_engaged_with_user_id 54.1 seconds\n",
      "CE_enaging_user_id 75.2 seconds\n",
      "CPU times: user 7.6 s, sys: 898 ms, total: 8.5 s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cuDF CE ENCODING IS SUPER FAST!!\n",
    "start = time.time()\n",
    "idx = 0; cols = []\n",
    "for c in ['present_media', 'tweet_type', 'language', 'engaged_with_user_id', 'enaging_user_id']:\n",
    "    encoder = CountEncoder()\n",
    "    out_col = f'CE_{c}'\n",
    "    train,valid = encoder.fit_transform(train, valid, c, out_col=out_col)\n",
    "    print\n",
    "    del encoder\n",
    "    train,valid = dask.persist(train,valid)\n",
    "    wait(train)\n",
    "    wait(valid)\n",
    "    print(out_col,\"%.1f seconds\"%(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE_present_media_norm 15.0 seconds\n",
      "CE_tweet_type_norm 29.6 seconds\n",
      "CE_language_norm 44.5 seconds\n",
      "CE_engaged_with_user_id_norm 62.1 seconds\n",
      "CE_enaging_user_id_norm 82.0 seconds\n",
      "CPU times: user 9.78 s, sys: 1.13 s, total: 10.9 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cuDF CE ENCODING IS SUPER FAST!!\n",
    "idx = 0; cols = []\n",
    "start = time.time()\n",
    "for c in ['present_media', 'tweet_type', 'language', 'engaged_with_user_id', 'enaging_user_id']:\n",
    "    encoder = FrequencyEncoder()\n",
    "    out_col = f'CE_{c}_norm'\n",
    "    train = encoder.fit_transform(train, c, c_col='tweet_id', out_col=out_col)\n",
    "    valid = encoder.transform(valid, c, c_col='tweet_id', out_col=out_col)\n",
    "    cols.append(out_col)\n",
    "    del encoder\n",
    "    train,valid = dask.persist(train,valid)\n",
    "    wait(train)\n",
    "    wait(valid)\n",
    "    print(out_col,\"%.1f seconds\"%(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference Encode (Lag Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_encode_cudf_v1(train,col,tar,sft=1):\n",
    "    train[col+'_sft'] = train[col].shift(sft)\n",
    "    train[tar+'_sft'] = traiclass FrequencyEncoder:\n",
    "    \n",
    "    def __init__(self, seed=42):\n",
    "        self.seed = seed\n",
    "        \n",
    "    def fit_transform(self, train, x_col, c_col=None, out_col = None):\n",
    "        np.random.seed(self.seed)\n",
    "        if c_col is None or c_col not in train.columns:\n",
    "            c_col = 'dummy'\n",
    "            train[c_col] = 1\n",
    "            drop = True\n",
    "        else:\n",
    "            drop = False\n",
    "            \n",
    "        if out_col is None:\n",
    "            tag = x_col if isinstance(x_col,str) else '_'.join(x_col)\n",
    "            out_col = f'CE_{tag}_norm'\n",
    "            \n",
    "        cols = [x_col] if isinstance(x_col,str) else x_col\n",
    "        agg_all = train.groupby(cols).agg({c_col:'count'}).reset_index()\n",
    "        if drop:\n",
    "            train = train.drop(c_col,axis=1)\n",
    "        agg_all.columns = cols + [out_col]\n",
    "        agg_all[out_col] = agg_all[out_col].astype('int32')\n",
    "        agg_all[out_col] = agg_all[out_col]*1.0/len(train)\n",
    "        agg_all[out_col] = agg_all[out_col].astype('float32')\n",
    "    \n",
    "        train = train.merge(agg_all,on=cols,how='left')\n",
    "        del agg_all\n",
    "        #print(train.columns)\n",
    "        #train[out_col] = train.map_partitions(lambda cudf_df: cudf_df[out_col].nans_to_nulls())\n",
    "        return train\n",
    "    \n",
    "    def transform(self, test, x_col, c_col=None, out_col = None):\n",
    "        return self.fit_transform(test, x_col, c_col, out_col)\n",
    " n[tar].shift(sft)\n",
    "    out_col = f'DE_{col}_{tar}_{sft}'\n",
    "    train[out_col] = train[tar]-train[tar+'_sft']\n",
    "    mask = '__MASK__'\n",
    "    train[mask] = train[col] == train[col+'_sft']\n",
    "    train = train.drop([col+'_sft',tar+'_sft'],axis=1)\n",
    "    train[out_col] = train[out_col]*train[mask]\n",
    "    train = train.drop(mask,axis=1)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE enaging_user_id enaging_user_following_count 1 7.6 seconds\n",
      "DE enaging_user_id enaging_user_following_count -1 6.0 seconds\n",
      "DE enaging_user_id enaging_user_following_count 1 6.4 seconds\n",
      "DE enaging_user_id enaging_user_following_count -1 7.1 seconds\n",
      "DE enaging_user_id language 1 6.5 seconds\n",
      "DE enaging_user_id language -1 6.1 seconds\n",
      "CPU times: user 6.56 s, sys: 570 ms, total: 7.13 s\n",
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "# cuDF DE ENCODING IS FAST!!\n",
    "idx = 0; cols = []; sc = 'tweet_timestamp'\n",
    "for c in ['enaging_user_id']:\n",
    "    for t in ['enaging_user_following_count','enaging_user_following_count','language']:\n",
    "        for s in [1,-1]:\n",
    "            start = time.time()\n",
    "            train = diff_encode_cudf_v1(train, col=c, tar=t, sft=s)\n",
    "            valid = diff_encode_cudf_v1(valid, col=c, tar=t, sft=s)\n",
    "            train,valid = dask.persist(train,valid)\n",
    "            wait(train)\n",
    "            wait(valid)\n",
    "            end = time.time(); idx += 1\n",
    "            print('DE',c,t,s,'%.1f seconds'%(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diff Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lang = train[['engaged_with_user_id', 'language', 'tweet_id']].drop_duplicates()\n",
    "valid_lang = valid[['engaged_with_user_id', 'language', 'tweet_id']].drop_duplicates()\n",
    "train_lang_count = train_lang.groupby(['engaged_with_user_id', 'language']).agg({'tweet_id':'count'}).reset_index()\n",
    "valid_lang_count = valid_lang.groupby(['engaged_with_user_id', 'language']).agg({'tweet_id':'count'}).reset_index()\n",
    "train_lang_count,valid_lang_count = dask.persist(train_lang_count,valid_lang_count)\n",
    "# train_lang_count.head()\n",
    "del train_lang,valid_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.2 ms, sys: 4.56 ms, total: 62.7 ms\n",
      "Wall time: 51.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_lang_count = train_lang_count.merge(valid_lang_count,on=['engaged_with_user_id', 'language'],how='left')\n",
    "train_lang_count['tweet_id_y'] = train_lang_count['tweet_id_y'].fillna(0)\n",
    "train_lang_count['tweet_id_x'] = train_lang_count['tweet_id_x'] + train_lang_count['tweet_id_y']\n",
    "train_lang_count = train_lang_count.drop('tweet_id_y',axis=1)\n",
    "train_lang_count.columns = ['engaged_with_user_id', 'top_language', 'language_count']\n",
    "train_lang_count, = dask.persist(train_lang_count)\n",
    "# train_lang_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 ms, sys: 7.31 ms, total: 38.9 ms\n",
      "Wall time: 33.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#train_lang_count = train_lang_count.sort_values(['engaged_with_user_id', 'language_count'])\n",
    "train_lang_count['engaged_with_user_shifted'] = train_lang_count['engaged_with_user_id'].shift(1)\n",
    "train_lang_count = train_lang_count[train_lang_count['engaged_with_user_id']!=train_lang_count['engaged_with_user_shifted']]\n",
    "train_lang_count = train_lang_count.drop(['engaged_with_user_shifted','language_count'],axis=1)\n",
    "train_lang_count.columns = ['engaged_with_user_id','top_language']\n",
    "train_lang_count, = dask.persist(train_lang_count)\n",
    "# train_lang_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_language(df,df_lang_count):\n",
    "    df = df.merge(df_lang_count,how='left', left_on='enaging_user_id', right_on='engaged_with_user_id')\n",
    "    df['nan_language'] = df['top_language'].isnull()\n",
    "    df['same_language'] = df['language'] == df['top_language']\n",
    "    df['diff_language'] = df['language'] != df['top_language']\n",
    "    df['same_language'] = df['same_language']*(1-df['nan_language'])\n",
    "    df['diff_language'] = df['diff_language']*(1-df['nan_language'])\n",
    "    df = df.drop('top_language',axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#train = diff_language(train,train_lang_count)\n",
    "#valid = diff_language(valid,train_lang_count)\n",
    "#train,valid = dask.persist(train,valid)\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 117 ms, sys: 11.3 ms, total: 128 ms\n",
      "Wall time: 118 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# follow rate feature\n",
    "train['a_ff_rate'] = (train['engaged_with_user_following_count'] / train['engaged_with_user_follower_count']).astype('float32')\n",
    "train['b_ff_rate'] = (train['enaging_user_follower_count']  / train['enaging_user_following_count']).astype('float32')\n",
    "valid['a_ff_rate']  = (valid['engaged_with_user_following_count'] / valid['engaged_with_user_follower_count']).astype('float32')\n",
    "valid['b_ff_rate']  = (valid['enaging_user_follower_count']  / valid['enaging_user_following_count']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,valid = dask.persist(train,valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoneAndNotDoneFutures(done={<Future: finished, type: pandas.DataFrame, key: ('assign-0a5c015311656606ded3cf17af343870', 0)>, <Future: finished, type: pandas.DataFrame, key: ('assign-0a5c015311656606ded3cf17af343870', 1)>, <Future: finished, type: pandas.DataFrame, key: ('assign-0a5c015311656606ded3cf17af343870', 2)>, <Future: finished, type: pandas.DataFrame, key: ('assign-0a5c015311656606ded3cf17af343870', 6)>, <Future: finished, type: pandas.DataFrame, key: ('assign-0a5c015311656606ded3cf17af343870', 4)>, <Future: finished, type: pandas.DataFrame, key: ('assign-0a5c015311656606ded3cf17af343870', 3)>, <Future: finished, type: pandas.DataFrame, key: ('assign-0a5c015311656606ded3cf17af343870', 5)>, <Future: finished, type: pandas.DataFrame, key: ('assign-0a5c015311656606ded3cf17af343870', 7)>}, not_done=set())"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wait(train)\n",
    "wait(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hashtags', 'present_media', 'tweet_type', 'language',\n",
       "       'engaged_with_user_follower_count', 'engaged_with_user_following_count',\n",
       "       'engaged_with_user_is_verified', 'enaging_user_follower_count',\n",
       "       'enaging_user_following_count', 'enaging_user_is_verified',\n",
       "       ...\n",
       "       'CE_tweet_type_norm', 'CE_language_norm',\n",
       "       'CE_engaged_with_user_id_norm', 'CE_enaging_user_id_norm',\n",
       "       'DE_enaging_user_id_enaging_user_following_count_1',\n",
       "       'DE_enaging_user_id_enaging_user_following_count_-1',\n",
       "       'DE_enaging_user_id_language_1', 'DE_enaging_user_id_language_-1',\n",
       "       'a_ff_rate', 'b_ff_rate'],\n",
       "      dtype='object', length=127)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 347 s, sys: 0 ns, total: 347 s\n",
      "Wall time: 347 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "label_names = ['reply_timestamp', 'retweet_timestamp', 'retweet_with_comment_timestamp', 'like_timestamp']\n",
    "DONT_USE = ['tweet_id','tweet_timestamp','engaged_with_user_account_creation','enaging_user_account_creation','engage_time',\n",
    "            'fold','enaging_user_id','engaged_with_user_id', 'dt_dow',\n",
    "            'engaged_with_user_account_creation', 'enaging_user_account_creation', 'elapsed_time',\n",
    "             'present_links','present_domains']\n",
    "DONT_USE += label_names\n",
    "features = [c for c in train.columns if c not in DONT_USE]\n",
    "\n",
    "RMV = [c for c in DONT_USE if c in train.columns and c not in label_names]\n",
    "RMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 s, sys: 1 s, total: 8 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for col in RMV:\n",
    "    #print(col, col in train.columns)\n",
    "    if col in train.columns:\n",
    "        train = train.drop(col,axis=1)\n",
    "        train, = dask.persist(train)\n",
    "#         train.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 s, sys: 1 s, total: 8 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for col in RMV:\n",
    "    #print(col, col in valid.columns)\n",
    "    if col in valid.columns:\n",
    "        valid = valid.drop(col,axis=1)\n",
    "        valid, = dask.persist(valid,)\n",
    "#         valid.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet('/mnt/DP_disk3/bin/dask_tmp/train_10_raw')\n",
    "valid.to_parquet('/mnt/DP_disk3/bin/dask_tmp/valid_10_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:2200.7121801376343\n"
     ]
    }
   ],
   "source": [
    "very_end = time.time()\n",
    "print(F\"Total time:{very_end - very_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
